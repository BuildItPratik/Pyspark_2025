/mnt/c/pyspark_stack/spark-apps/cron/run_sales.sh: 1: ---: not found
Triggering sales_etl_job.py for 2025-01-01...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/11/18 06:00:10 INFO SparkContext: Running Spark version 3.2.1
25/11/18 06:00:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/11/18 06:00:11 INFO ResourceUtils: ==============================================================
25/11/18 06:00:11 INFO ResourceUtils: No custom resources configured for spark.driver.
25/11/18 06:00:11 INFO ResourceUtils: ==============================================================
25/11/18 06:00:11 INFO SparkContext: Submitted application: SalesETLJob
25/11/18 06:00:11 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/11/18 06:00:11 INFO ResourceProfile: Limiting resource is cpu
25/11/18 06:00:11 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/11/18 06:00:11 INFO SecurityManager: Changing view acls to: spark
25/11/18 06:00:11 INFO SecurityManager: Changing modify acls to: spark
25/11/18 06:00:11 INFO SecurityManager: Changing view acls groups to: 
25/11/18 06:00:11 INFO SecurityManager: Changing modify acls groups to: 
25/11/18 06:00:11 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
25/11/18 06:00:11 INFO Utils: Successfully started service 'sparkDriver' on port 35361.
25/11/18 06:00:11 INFO SparkEnv: Registering MapOutputTracker
25/11/18 06:00:11 INFO SparkEnv: Registering BlockManagerMaster
25/11/18 06:00:11 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/11/18 06:00:11 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/11/18 06:00:11 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/11/18 06:00:11 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c2a90ae3-b7db-4e53-a056-4d574fca07a3
25/11/18 06:00:11 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/11/18 06:00:11 INFO SparkEnv: Registering OutputCommitCoordinator
25/11/18 06:00:12 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/11/18 06:00:12 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://6b05748f7bac:4040
25/11/18 06:00:12 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/11/18 06:00:12 INFO TransportClientFactory: Successfully created connection to spark-master/172.20.0.3:7077 after 45 ms (0 ms spent in bootstraps)
25/11/18 06:00:13 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20251118060013-0000
25/11/18 06:00:13 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46405.
25/11/18 06:00:13 INFO NettyBlockTransferService: Server created on 6b05748f7bac:46405
25/11/18 06:00:13 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/11/18 06:00:13 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 6b05748f7bac, 46405, None)
25/11/18 06:00:13 INFO BlockManagerMasterEndpoint: Registering block manager 6b05748f7bac:46405 with 366.3 MiB RAM, BlockManagerId(driver, 6b05748f7bac, 46405, None)
25/11/18 06:00:13 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 6b05748f7bac, 46405, None)
25/11/18 06:00:13 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 6b05748f7bac, 46405, None)
25/11/18 06:00:13 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251118060013-0000/0 on worker-20251118055626-172.20.0.6-38023 (172.20.0.6:38023) with 12 core(s)
25/11/18 06:00:13 INFO StandaloneSchedulerBackend: Granted executor ID app-20251118060013-0000/0 on hostPort 172.20.0.6:38023 with 12 core(s), 1024.0 MiB RAM
25/11/18 06:00:13 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251118060013-0000/0 is now RUNNING
25/11/18 06:00:13 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/11/18 06:00:14 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/11/18 06:00:14 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
25/11/18 06:00:20 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.6:33780) with ID 0,  ResourceProfileId 0
25/11/18 06:00:20 INFO BlockManagerMasterEndpoint: Registering block manager 172.20.0.6:45223 with 366.3 MiB RAM, BlockManagerId(0, 172.20.0.6, 45223, None)
25/11/18 06:00:20 INFO InMemoryFileIndex: It took 195 ms to list leaf files for 1 paths.
25/11/18 06:00:20 INFO InMemoryFileIndex: It took 12 ms to list leaf files for 1 paths.
25/11/18 06:00:24 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:00:24 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/11/18 06:00:24 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:00:25 INFO CodeGenerator: Code generated in 298.005089 ms
25/11/18 06:00:25 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 338.3 KiB, free 366.0 MiB)
25/11/18 06:00:25 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.9 MiB)
25/11/18 06:00:25 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 6b05748f7bac:46405 (size: 32.4 KiB, free: 366.3 MiB)
25/11/18 06:00:25 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:00:25 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:00:25 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/11/18 06:00:25 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:00:25 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/11/18 06:00:25 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:00:25 INFO DAGScheduler: Missing parents: List()
25/11/18 06:00:25 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:00:26 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/11/18 06:00:26 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/11/18 06:00:26 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 6b05748f7bac:46405 (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:00:26 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/11/18 06:00:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:00:26 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/11/18 06:00:26 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:00:26 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.0.6:45223 (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:00:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.0.6:45223 (size: 32.4 KiB, free: 366.3 MiB)
25/11/18 06:00:29 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 3615 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:00:29 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/11/18 06:00:29 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 3.760 s
25/11/18 06:00:29 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:00:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/11/18 06:00:29 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 3.836738 s
25/11/18 06:00:29 INFO CodeGenerator: Code generated in 15.530435 ms
25/11/18 06:00:29 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:00:29 INFO FileSourceStrategy: Post-Scan Filters: 
25/11/18 06:00:29 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:00:29 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 338.3 KiB, free 365.6 MiB)
25/11/18 06:00:29 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.6 MiB)
25/11/18 06:00:29 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 6b05748f7bac:46405 (size: 32.4 KiB, free: 366.2 MiB)
25/11/18 06:00:29 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:00:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:00:30 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
25/11/18 06:00:30 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
25/11/18 06:00:30 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:00:30 INFO FileSourceStrategy: Post-Scan Filters: 
25/11/18 06:00:30 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:00:30 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 338.1 KiB, free 365.2 MiB)
25/11/18 06:00:30 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.2 MiB)
25/11/18 06:00:30 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 6b05748f7bac:46405 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:00:30 INFO SparkContext: Created broadcast 3 from json at NativeMethodAccessorImpl.java:0
25/11/18 06:00:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:00:30 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
25/11/18 06:00:30 INFO DAGScheduler: Got job 1 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:00:30 INFO DAGScheduler: Final stage: ResultStage 1 (json at NativeMethodAccessorImpl.java:0)
25/11/18 06:00:30 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:00:30 INFO DAGScheduler: Missing parents: List()
25/11/18 06:00:30 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:00:30 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 12.4 KiB, free 365.2 MiB)
25/11/18 06:00:30 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 365.2 MiB)
25/11/18 06:00:30 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 6b05748f7bac:46405 (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:00:30 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/11/18 06:00:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:00:30 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/11/18 06:00:30 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:00:30 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.0.6:45223 (size: 6.5 KiB, free: 366.3 MiB)
25/11/18 06:00:30 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.0.6:45223 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:00:30 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 246 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:00:30 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/11/18 06:00:30 INFO DAGScheduler: ResultStage 1 (json at NativeMethodAccessorImpl.java:0) finished in 0.282 s
25/11/18 06:00:30 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:00:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/11/18 06:00:30 INFO DAGScheduler: Job 1 finished: json at NativeMethodAccessorImpl.java:0, took 0.292494 s
25/11/18 06:00:31 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/11/18 06:00:31 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/11/18 06:00:31 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/11/18 06:00:31 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:00:31 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:00:31 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:00:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:00:31 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:00:31 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
25/11/18 06:00:31 INFO CodeGenerator: Code generated in 40.195272 ms
25/11/18 06:00:31 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 338.2 KiB, free 364.8 MiB)
25/11/18 06:00:31 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 364.8 MiB)
25/11/18 06:00:31 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 6b05748f7bac:46405 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:00:31 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:00:31 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:00:31 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:00:31 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/11/18 06:00:31 INFO DAGScheduler: Final stage: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/11/18 06:00:31 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:00:31 INFO DAGScheduler: Missing parents: List()
25/11/18 06:00:31 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/11/18 06:00:31 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 14.4 KiB, free 364.8 MiB)
25/11/18 06:00:31 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 364.8 MiB)
25/11/18 06:00:31 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 6b05748f7bac:46405 (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:00:31 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/11/18 06:00:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/11/18 06:00:31 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/11/18 06:00:31 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:00:31 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.20.0.6:45223 (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:00:31 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.20.0.6:45223 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:00:32 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 308 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:00:32 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/11/18 06:00:32 INFO DAGScheduler: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.335 s
25/11/18 06:00:32 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:00:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/11/18 06:00:32 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.341277 s
25/11/18 06:00:32 INFO CodeGenerator: Code generated in 25.916247 ms
25/11/18 06:00:32 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 1025.0 KiB, free 363.8 MiB)
25/11/18 06:00:32 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 250.0 B, free 363.8 MiB)
25/11/18 06:00:32 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 6b05748f7bac:46405 (size: 250.0 B, free: 366.2 MiB)
25/11/18 06:00:32 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:00:32 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:00:32 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:00:32 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:00:32 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 6b05748f7bac:46405 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/11/18 06:00:32 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.0.6:45223 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/11/18 06:00:32 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 6b05748f7bac:46405 in memory (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:00:32 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.20.0.6:45223 in memory (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:00:32 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 6b05748f7bac:46405 in memory (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:00:32 INFO CodeGenerator: Code generated in 40.521853 ms
25/11/18 06:00:32 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.20.0.6:45223 in memory (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:00:32 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 338.0 KiB, free 363.9 MiB)
25/11/18 06:00:32 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 6b05748f7bac:46405 in memory (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:00:32 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.20.0.6:45223 in memory (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:00:32 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 363.9 MiB)
25/11/18 06:00:32 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 6b05748f7bac:46405 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:00:32 INFO SparkContext: Created broadcast 8 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:00:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:00:32 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/11/18 06:00:32 INFO DAGScheduler: Got job 3 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:00:32 INFO DAGScheduler: Final stage: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0)
25/11/18 06:00:32 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:00:32 INFO DAGScheduler: Missing parents: List()
25/11/18 06:00:32 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:00:32 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 211.3 KiB, free 363.6 MiB)
25/11/18 06:00:32 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 75.9 KiB, free 363.6 MiB)
25/11/18 06:00:32 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 6b05748f7bac:46405 (size: 75.9 KiB, free: 366.1 MiB)
25/11/18 06:00:32 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/11/18 06:00:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:00:32 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/11/18 06:00:32 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:00:32 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.20.0.6:45223 (size: 75.9 KiB, free: 366.2 MiB)
25/11/18 06:00:32 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.20.0.6:45223 (size: 250.0 B, free: 366.2 MiB)
25/11/18 06:00:32 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.20.0.6:45223 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:00:33 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 1191 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:00:33 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/11/18 06:00:33 INFO DAGScheduler: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0) finished in 1.223 s
25/11/18 06:00:33 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:00:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/11/18 06:00:33 INFO DAGScheduler: Job 3 finished: csv at NativeMethodAccessorImpl.java:0, took 1.231568 s
25/11/18 06:00:33 INFO FileFormatWriter: Start to commit write Job 9572ef22-68dc-431b-87a1-866ffae861c2.
25/11/18 06:00:33 INFO FileFormatWriter: Write Job 9572ef22-68dc-431b-87a1-866ffae861c2 committed. Elapsed time: 108 ms.
25/11/18 06:00:33 INFO FileFormatWriter: Finished processing stats for write job 9572ef22-68dc-431b-87a1-866ffae861c2.
25/11/18 06:00:33 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/11/18 06:00:33 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/11/18 06:00:33 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/11/18 06:00:33 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:00:33 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:00:33 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:00:34 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:00:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:00:34 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:00:34 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:00:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:00:34 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:00:34 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:00:34 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 338.2 KiB, free 363.2 MiB)
25/11/18 06:00:34 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 363.2 MiB)
25/11/18 06:00:34 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 6b05748f7bac:46405 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:00:34 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:00:34 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:00:34 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:00:34 INFO DAGScheduler: Got job 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/11/18 06:00:34 INFO DAGScheduler: Final stage: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/11/18 06:00:34 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:00:34 INFO DAGScheduler: Missing parents: List()
25/11/18 06:00:34 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/11/18 06:00:34 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 14.4 KiB, free 363.2 MiB)
25/11/18 06:00:34 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 363.2 MiB)
25/11/18 06:00:34 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 6b05748f7bac:46405 (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:00:34 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/11/18 06:00:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/11/18 06:00:34 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/11/18 06:00:34 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:00:34 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.20.0.6:45223 (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:00:34 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.20.0.6:45223 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:00:34 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 115 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:00:34 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/11/18 06:00:34 INFO DAGScheduler: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.133 s
25/11/18 06:00:34 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:00:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/11/18 06:00:34 INFO DAGScheduler: Job 4 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.140589 s
25/11/18 06:00:34 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 1025.0 KiB, free 362.2 MiB)
25/11/18 06:00:34 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 250.0 B, free 362.2 MiB)
25/11/18 06:00:34 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 6b05748f7bac:46405 (size: 250.0 B, free: 366.1 MiB)
25/11/18 06:00:34 INFO SparkContext: Created broadcast 12 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:00:34 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:00:34 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:00:34 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:00:34 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 338.0 KiB, free 361.9 MiB)
25/11/18 06:00:34 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 361.8 MiB)
25/11/18 06:00:34 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 6b05748f7bac:46405 (size: 32.5 KiB, free: 366.0 MiB)
25/11/18 06:00:34 INFO SparkContext: Created broadcast 13 from parquet at NativeMethodAccessorImpl.java:0
25/11/18 06:00:34 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:00:34 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
25/11/18 06:00:34 INFO DAGScheduler: Got job 5 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:00:34 INFO DAGScheduler: Final stage: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0)
25/11/18 06:00:34 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:00:34 INFO DAGScheduler: Missing parents: List()
25/11/18 06:00:34 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:00:34 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 211.3 KiB, free 361.6 MiB)
25/11/18 06:00:34 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 76.0 KiB, free 361.5 MiB)
25/11/18 06:00:34 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 6b05748f7bac:46405 (size: 76.0 KiB, free: 366.0 MiB)
25/11/18 06:00:34 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/11/18 06:00:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:00:34 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/11/18 06:00:34 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:00:34 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.20.0.6:45223 (size: 76.0 KiB, free: 366.0 MiB)
25/11/18 06:00:34 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.20.0.6:45223 (size: 250.0 B, free: 366.0 MiB)
25/11/18 06:00:35 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.20.0.6:45223 (size: 32.5 KiB, free: 366.0 MiB)
25/11/18 06:00:35 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 1433 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:00:35 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/11/18 06:00:35 INFO DAGScheduler: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0) finished in 1.460 s
25/11/18 06:00:35 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:00:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/11/18 06:00:35 INFO DAGScheduler: Job 5 finished: parquet at NativeMethodAccessorImpl.java:0, took 1.465747 s
25/11/18 06:00:35 INFO FileFormatWriter: Start to commit write Job 9d1f7bf5-7445-40b8-8233-b32a5ed58589.
25/11/18 06:00:35 INFO FileFormatWriter: Write Job 9d1f7bf5-7445-40b8-8233-b32a5ed58589 committed. Elapsed time: 35 ms.
25/11/18 06:00:35 INFO FileFormatWriter: Finished processing stats for write job 9d1f7bf5-7445-40b8-8233-b32a5ed58589.
Job completed for 2025-01-01
25/11/18 06:00:35 INFO SparkUI: Stopped Spark web UI at http://6b05748f7bac:4040
25/11/18 06:00:35 INFO StandaloneSchedulerBackend: Shutting down all executors
25/11/18 06:00:35 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/11/18 06:00:35 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/11/18 06:00:36 INFO MemoryStore: MemoryStore cleared
25/11/18 06:00:36 INFO BlockManager: BlockManager stopped
25/11/18 06:00:36 INFO BlockManagerMaster: BlockManagerMaster stopped
25/11/18 06:00:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/11/18 06:00:36 INFO SparkContext: Successfully stopped SparkContext
25/11/18 06:00:36 INFO ShutdownHookManager: Shutdown hook called
25/11/18 06:00:36 INFO ShutdownHookManager: Deleting directory /tmp/spark-102b8668-7384-4cd3-bf5d-92ec38259cb2/pyspark-35bbced8-3b43-43ad-93ba-a39408b164dd
25/11/18 06:00:36 INFO ShutdownHookManager: Deleting directory /tmp/spark-102b8668-7384-4cd3-bf5d-92ec38259cb2
25/11/18 06:00:36 INFO ShutdownHookManager: Deleting directory /tmp/spark-82259d17-57d8-4b99-83cc-f2506d408b7f
Job completed for 2025-01-01
/mnt/c/pyspark_stack/spark-apps/cron/run_sales.sh: 1: ---: not found
Triggering sales_etl_job.py for 2025-01-01...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/11/18 06:01:08 INFO SparkContext: Running Spark version 3.2.1
25/11/18 06:01:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/11/18 06:01:08 INFO ResourceUtils: ==============================================================
25/11/18 06:01:08 INFO ResourceUtils: No custom resources configured for spark.driver.
25/11/18 06:01:08 INFO ResourceUtils: ==============================================================
25/11/18 06:01:08 INFO SparkContext: Submitted application: SalesETLJob
25/11/18 06:01:08 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/11/18 06:01:08 INFO ResourceProfile: Limiting resource is cpu
25/11/18 06:01:08 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/11/18 06:01:08 INFO SecurityManager: Changing view acls to: spark
25/11/18 06:01:08 INFO SecurityManager: Changing modify acls to: spark
25/11/18 06:01:08 INFO SecurityManager: Changing view acls groups to: 
25/11/18 06:01:08 INFO SecurityManager: Changing modify acls groups to: 
25/11/18 06:01:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
25/11/18 06:01:09 INFO Utils: Successfully started service 'sparkDriver' on port 35221.
25/11/18 06:01:09 INFO SparkEnv: Registering MapOutputTracker
25/11/18 06:01:09 INFO SparkEnv: Registering BlockManagerMaster
25/11/18 06:01:09 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/11/18 06:01:09 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/11/18 06:01:09 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/11/18 06:01:09 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-b5395b3f-1cbb-4b95-8462-040c4fe0b674
25/11/18 06:01:09 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/11/18 06:01:09 INFO SparkEnv: Registering OutputCommitCoordinator
25/11/18 06:01:09 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/11/18 06:01:10 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://6b05748f7bac:4040
25/11/18 06:01:10 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/11/18 06:01:10 INFO TransportClientFactory: Successfully created connection to spark-master/172.20.0.3:7077 after 51 ms (0 ms spent in bootstraps)
25/11/18 06:01:10 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20251118060110-0001
25/11/18 06:01:10 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251118060110-0001/0 on worker-20251118055626-172.20.0.6-38023 (172.20.0.6:38023) with 12 core(s)
25/11/18 06:01:10 INFO StandaloneSchedulerBackend: Granted executor ID app-20251118060110-0001/0 on hostPort 172.20.0.6:38023 with 12 core(s), 1024.0 MiB RAM
25/11/18 06:01:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42759.
25/11/18 06:01:10 INFO NettyBlockTransferService: Server created on 6b05748f7bac:42759
25/11/18 06:01:10 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/11/18 06:01:10 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 6b05748f7bac, 42759, None)
25/11/18 06:01:10 INFO BlockManagerMasterEndpoint: Registering block manager 6b05748f7bac:42759 with 366.3 MiB RAM, BlockManagerId(driver, 6b05748f7bac, 42759, None)
25/11/18 06:01:10 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 6b05748f7bac, 42759, None)
25/11/18 06:01:10 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 6b05748f7bac, 42759, None)
25/11/18 06:01:10 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251118060110-0001/0 is now RUNNING
25/11/18 06:01:11 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/11/18 06:01:11 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/11/18 06:01:11 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
25/11/18 06:01:13 INFO InMemoryFileIndex: It took 131 ms to list leaf files for 1 paths.
25/11/18 06:01:14 INFO InMemoryFileIndex: It took 15 ms to list leaf files for 1 paths.
25/11/18 06:01:14 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.6:34500) with ID 0,  ResourceProfileId 0
25/11/18 06:01:14 INFO BlockManagerMasterEndpoint: Registering block manager 172.20.0.6:39459 with 366.3 MiB RAM, BlockManagerId(0, 172.20.0.6, 39459, None)
25/11/18 06:01:17 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:01:17 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/11/18 06:01:17 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:01:18 INFO CodeGenerator: Code generated in 273.701186 ms
25/11/18 06:01:18 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 338.3 KiB, free 366.0 MiB)
25/11/18 06:01:18 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.9 MiB)
25/11/18 06:01:18 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 6b05748f7bac:42759 (size: 32.4 KiB, free: 366.3 MiB)
25/11/18 06:01:18 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:01:18 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:01:19 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/11/18 06:01:19 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:01:19 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/11/18 06:01:19 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:01:19 INFO DAGScheduler: Missing parents: List()
25/11/18 06:01:19 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:01:19 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/11/18 06:01:19 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/11/18 06:01:19 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 6b05748f7bac:42759 (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:01:19 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/11/18 06:01:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:01:19 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/11/18 06:01:19 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:01:19 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.0.6:39459 (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:01:21 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.0.6:39459 (size: 32.4 KiB, free: 366.3 MiB)
25/11/18 06:01:25 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 5960 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:01:25 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/11/18 06:01:25 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 6.106 s
25/11/18 06:01:25 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:01:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/11/18 06:01:25 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 3.488339 s
25/11/18 06:01:25 INFO CodeGenerator: Code generated in 22.186877 ms
25/11/18 06:01:25 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:01:25 INFO FileSourceStrategy: Post-Scan Filters: 
25/11/18 06:01:25 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:01:25 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 338.3 KiB, free 365.6 MiB)
25/11/18 06:01:25 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.6 MiB)
25/11/18 06:01:25 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 6b05748f7bac:42759 (size: 32.4 KiB, free: 366.2 MiB)
25/11/18 06:01:25 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:01:25 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:01:25 INFO InMemoryFileIndex: It took 14 ms to list leaf files for 1 paths.
25/11/18 06:01:25 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
25/11/18 06:01:25 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:01:25 INFO FileSourceStrategy: Post-Scan Filters: 
25/11/18 06:01:25 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:01:25 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 338.1 KiB, free 365.2 MiB)
25/11/18 06:01:25 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.2 MiB)
25/11/18 06:01:25 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 6b05748f7bac:42759 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:01:25 INFO SparkContext: Created broadcast 3 from json at NativeMethodAccessorImpl.java:0
25/11/18 06:01:25 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:01:25 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
25/11/18 06:01:25 INFO DAGScheduler: Got job 1 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:01:25 INFO DAGScheduler: Final stage: ResultStage 1 (json at NativeMethodAccessorImpl.java:0)
25/11/18 06:01:25 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:01:25 INFO DAGScheduler: Missing parents: List()
25/11/18 06:01:25 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:01:25 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 12.4 KiB, free 365.2 MiB)
25/11/18 06:01:25 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 365.2 MiB)
25/11/18 06:01:25 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 6b05748f7bac:42759 (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:01:25 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/11/18 06:01:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:01:25 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/11/18 06:01:25 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:01:25 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.0.6:39459 (size: 6.5 KiB, free: 366.3 MiB)
25/11/18 06:01:26 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.0.6:39459 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:01:26 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 303 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:01:26 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/11/18 06:01:26 INFO DAGScheduler: ResultStage 1 (json at NativeMethodAccessorImpl.java:0) finished in 0.344 s
25/11/18 06:01:26 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:01:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/11/18 06:01:26 INFO DAGScheduler: Job 1 finished: json at NativeMethodAccessorImpl.java:0, took 0.354705 s
25/11/18 06:01:26 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/11/18 06:01:26 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/11/18 06:01:26 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/11/18 06:01:26 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:01:26 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:01:26 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:01:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:01:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:01:27 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
25/11/18 06:01:27 INFO CodeGenerator: Code generated in 33.464484 ms
25/11/18 06:01:27 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 338.2 KiB, free 364.8 MiB)
25/11/18 06:01:27 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 364.8 MiB)
25/11/18 06:01:27 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 6b05748f7bac:42759 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:01:27 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:01:27 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:01:27 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:01:27 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/11/18 06:01:27 INFO DAGScheduler: Final stage: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/11/18 06:01:27 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:01:27 INFO DAGScheduler: Missing parents: List()
25/11/18 06:01:27 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/11/18 06:01:27 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 14.4 KiB, free 364.8 MiB)
25/11/18 06:01:27 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 364.8 MiB)
25/11/18 06:01:27 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 6b05748f7bac:42759 (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:01:27 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/11/18 06:01:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/11/18 06:01:27 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/11/18 06:01:27 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:01:27 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.20.0.6:39459 (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:01:27 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.20.0.6:39459 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:01:27 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 330 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:01:27 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/11/18 06:01:27 INFO DAGScheduler: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.357 s
25/11/18 06:01:27 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:01:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/11/18 06:01:27 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.365379 s
25/11/18 06:01:27 INFO CodeGenerator: Code generated in 18.483792 ms
25/11/18 06:01:27 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 1025.0 KiB, free 363.8 MiB)
25/11/18 06:01:27 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 250.0 B, free 363.8 MiB)
25/11/18 06:01:27 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 6b05748f7bac:42759 (size: 250.0 B, free: 366.2 MiB)
25/11/18 06:01:27 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:01:27 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:01:27 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:01:27 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:01:28 INFO CodeGenerator: Code generated in 44.70636 ms
25/11/18 06:01:28 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 338.0 KiB, free 363.5 MiB)
25/11/18 06:01:28 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 363.4 MiB)
25/11/18 06:01:28 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 6b05748f7bac:42759 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:01:28 INFO SparkContext: Created broadcast 8 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:01:28 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:01:28 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/11/18 06:01:28 INFO DAGScheduler: Got job 3 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:01:28 INFO DAGScheduler: Final stage: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0)
25/11/18 06:01:28 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:01:28 INFO DAGScheduler: Missing parents: List()
25/11/18 06:01:28 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:01:28 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 211.3 KiB, free 363.2 MiB)
25/11/18 06:01:28 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 75.9 KiB, free 363.2 MiB)
25/11/18 06:01:28 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 6b05748f7bac:42759 (size: 75.9 KiB, free: 366.0 MiB)
25/11/18 06:01:28 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/11/18 06:01:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:01:28 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/11/18 06:01:28 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:01:28 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 6b05748f7bac:42759 in memory (size: 6.5 KiB, free: 366.1 MiB)
25/11/18 06:01:28 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.20.0.6:39459 in memory (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:01:28 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.20.0.6:39459 (size: 75.9 KiB, free: 366.1 MiB)
25/11/18 06:01:28 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 6b05748f7bac:42759 in memory (size: 5.8 KiB, free: 366.1 MiB)
25/11/18 06:01:28 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.0.6:39459 in memory (size: 5.8 KiB, free: 366.1 MiB)
25/11/18 06:01:28 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 6b05748f7bac:42759 in memory (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:01:28 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.20.0.6:39459 in memory (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:01:28 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 6b05748f7bac:42759 in memory (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:01:28 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.20.0.6:39459 in memory (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:01:28 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.20.0.6:39459 (size: 250.0 B, free: 366.2 MiB)
25/11/18 06:01:28 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.20.0.6:39459 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:01:28 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 615 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:01:28 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/11/18 06:01:28 INFO DAGScheduler: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0) finished in 0.725 s
25/11/18 06:01:28 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:01:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/11/18 06:01:28 INFO DAGScheduler: Job 3 finished: csv at NativeMethodAccessorImpl.java:0, took 0.733638 s
25/11/18 06:01:28 INFO FileFormatWriter: Start to commit write Job 34298b3b-f040-4ed3-ba28-4b159377f893.
25/11/18 06:01:28 INFO FileFormatWriter: Write Job 34298b3b-f040-4ed3-ba28-4b159377f893 committed. Elapsed time: 91 ms.
25/11/18 06:01:28 INFO FileFormatWriter: Finished processing stats for write job 34298b3b-f040-4ed3-ba28-4b159377f893.
25/11/18 06:01:29 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/11/18 06:01:29 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/11/18 06:01:29 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/11/18 06:01:29 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:01:29 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:01:29 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:01:29 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:01:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:01:29 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:01:29 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:01:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:01:29 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:01:29 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:01:29 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 338.2 KiB, free 363.2 MiB)
25/11/18 06:01:29 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 363.2 MiB)
25/11/18 06:01:29 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 6b05748f7bac:42759 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:01:29 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:01:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:01:29 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:01:29 INFO DAGScheduler: Got job 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/11/18 06:01:29 INFO DAGScheduler: Final stage: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/11/18 06:01:29 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:01:29 INFO DAGScheduler: Missing parents: List()
25/11/18 06:01:29 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/11/18 06:01:29 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 14.4 KiB, free 363.2 MiB)
25/11/18 06:01:29 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 363.2 MiB)
25/11/18 06:01:29 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 6b05748f7bac:42759 (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:01:29 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/11/18 06:01:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/11/18 06:01:29 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/11/18 06:01:29 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:01:29 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.20.0.6:39459 (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:01:29 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.20.0.6:39459 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:01:29 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 93 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:01:29 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/11/18 06:01:29 INFO DAGScheduler: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.105 s
25/11/18 06:01:29 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:01:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/11/18 06:01:29 INFO DAGScheduler: Job 4 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.111782 s
25/11/18 06:01:29 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 1025.0 KiB, free 362.2 MiB)
25/11/18 06:01:29 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 250.0 B, free 362.2 MiB)
25/11/18 06:01:29 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 6b05748f7bac:42759 (size: 250.0 B, free: 366.1 MiB)
25/11/18 06:01:29 INFO SparkContext: Created broadcast 12 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:01:29 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:01:29 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:01:29 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:01:29 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 338.0 KiB, free 361.9 MiB)
25/11/18 06:01:29 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 361.8 MiB)
25/11/18 06:01:29 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 6b05748f7bac:42759 (size: 32.5 KiB, free: 366.0 MiB)
25/11/18 06:01:29 INFO SparkContext: Created broadcast 13 from parquet at NativeMethodAccessorImpl.java:0
25/11/18 06:01:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:01:29 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
25/11/18 06:01:29 INFO DAGScheduler: Got job 5 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:01:29 INFO DAGScheduler: Final stage: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0)
25/11/18 06:01:29 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:01:29 INFO DAGScheduler: Missing parents: List()
25/11/18 06:01:29 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:01:29 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 211.3 KiB, free 361.6 MiB)
25/11/18 06:01:29 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 76.0 KiB, free 361.5 MiB)
25/11/18 06:01:29 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 6b05748f7bac:42759 (size: 76.0 KiB, free: 366.0 MiB)
25/11/18 06:01:29 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/11/18 06:01:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:01:29 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/11/18 06:01:29 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:01:29 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.20.0.6:39459 (size: 76.0 KiB, free: 366.0 MiB)
25/11/18 06:01:29 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.20.0.6:39459 (size: 250.0 B, free: 366.0 MiB)
25/11/18 06:01:30 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.20.0.6:39459 (size: 32.5 KiB, free: 366.0 MiB)
25/11/18 06:01:30 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 1120 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:01:30 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/11/18 06:01:30 INFO DAGScheduler: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0) finished in 1.152 s
25/11/18 06:01:30 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:01:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/11/18 06:01:30 INFO DAGScheduler: Job 5 finished: parquet at NativeMethodAccessorImpl.java:0, took 1.157100 s
25/11/18 06:01:30 INFO FileFormatWriter: Start to commit write Job 6404b907-fadd-49cd-927a-4294dda9a9d9.
25/11/18 06:01:30 INFO FileFormatWriter: Write Job 6404b907-fadd-49cd-927a-4294dda9a9d9 committed. Elapsed time: 31 ms.
25/11/18 06:01:30 INFO FileFormatWriter: Finished processing stats for write job 6404b907-fadd-49cd-927a-4294dda9a9d9.
Job completed for 2025-01-01
25/11/18 06:01:30 INFO SparkUI: Stopped Spark web UI at http://6b05748f7bac:4040
25/11/18 06:01:30 INFO StandaloneSchedulerBackend: Shutting down all executors
25/11/18 06:01:30 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/11/18 06:01:30 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/11/18 06:01:30 INFO MemoryStore: MemoryStore cleared
25/11/18 06:01:30 INFO BlockManager: BlockManager stopped
25/11/18 06:01:30 INFO BlockManagerMaster: BlockManagerMaster stopped
25/11/18 06:01:30 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/11/18 06:01:30 INFO SparkContext: Successfully stopped SparkContext
25/11/18 06:01:30 INFO ShutdownHookManager: Shutdown hook called
25/11/18 06:01:30 INFO ShutdownHookManager: Deleting directory /tmp/spark-6863bd89-101c-47bc-bc4f-53c8787936d1
25/11/18 06:01:30 INFO ShutdownHookManager: Deleting directory /tmp/spark-6863bd89-101c-47bc-bc4f-53c8787936d1/pyspark-4180780d-f020-4f54-b4c5-76523f5147da
25/11/18 06:01:30 INFO ShutdownHookManager: Deleting directory /tmp/spark-7587591c-34cf-49ec-9e6c-7a7442f2bba5
Job completed for 2025-01-01
/mnt/c/pyspark_stack/spark-apps/cron/run_sales.sh: 1: ---: not found
Triggering sales_etl_job.py for 2025-01-01...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/11/18 06:02:08 INFO SparkContext: Running Spark version 3.2.1
25/11/18 06:02:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/11/18 06:02:08 INFO ResourceUtils: ==============================================================
25/11/18 06:02:08 INFO ResourceUtils: No custom resources configured for spark.driver.
25/11/18 06:02:08 INFO ResourceUtils: ==============================================================
25/11/18 06:02:08 INFO SparkContext: Submitted application: SalesETLJob
25/11/18 06:02:08 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/11/18 06:02:08 INFO ResourceProfile: Limiting resource is cpu
25/11/18 06:02:08 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/11/18 06:02:08 INFO SecurityManager: Changing view acls to: spark
25/11/18 06:02:08 INFO SecurityManager: Changing modify acls to: spark
25/11/18 06:02:08 INFO SecurityManager: Changing view acls groups to: 
25/11/18 06:02:08 INFO SecurityManager: Changing modify acls groups to: 
25/11/18 06:02:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
25/11/18 06:02:09 INFO Utils: Successfully started service 'sparkDriver' on port 43407.
25/11/18 06:02:09 INFO SparkEnv: Registering MapOutputTracker
25/11/18 06:02:09 INFO SparkEnv: Registering BlockManagerMaster
25/11/18 06:02:09 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/11/18 06:02:09 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/11/18 06:02:09 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/11/18 06:02:09 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c35c26e4-83c3-40c2-84d1-8467622c3e9e
25/11/18 06:02:09 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/11/18 06:02:09 INFO SparkEnv: Registering OutputCommitCoordinator
25/11/18 06:02:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/11/18 06:02:10 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://6b05748f7bac:4040
25/11/18 06:02:11 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/11/18 06:02:11 INFO TransportClientFactory: Successfully created connection to spark-master/172.20.0.3:7077 after 64 ms (0 ms spent in bootstraps)
25/11/18 06:02:11 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20251118060211-0002
25/11/18 06:02:11 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251118060211-0002/0 on worker-20251118055626-172.20.0.6-38023 (172.20.0.6:38023) with 12 core(s)
25/11/18 06:02:11 INFO StandaloneSchedulerBackend: Granted executor ID app-20251118060211-0002/0 on hostPort 172.20.0.6:38023 with 12 core(s), 1024.0 MiB RAM
25/11/18 06:02:11 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36763.
25/11/18 06:02:11 INFO NettyBlockTransferService: Server created on 6b05748f7bac:36763
25/11/18 06:02:11 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/11/18 06:02:11 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 6b05748f7bac, 36763, None)
25/11/18 06:02:11 INFO BlockManagerMasterEndpoint: Registering block manager 6b05748f7bac:36763 with 366.3 MiB RAM, BlockManagerId(driver, 6b05748f7bac, 36763, None)
25/11/18 06:02:11 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 6b05748f7bac, 36763, None)
25/11/18 06:02:11 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 6b05748f7bac, 36763, None)
25/11/18 06:02:11 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251118060211-0002/0 is now RUNNING
25/11/18 06:02:12 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/11/18 06:02:12 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/11/18 06:02:12 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
25/11/18 06:02:16 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.6:43034) with ID 0,  ResourceProfileId 0
25/11/18 06:02:16 INFO InMemoryFileIndex: It took 209 ms to list leaf files for 1 paths.
25/11/18 06:02:16 INFO InMemoryFileIndex: It took 16 ms to list leaf files for 1 paths.
25/11/18 06:02:17 INFO BlockManagerMasterEndpoint: Registering block manager 172.20.0.6:33921 with 366.3 MiB RAM, BlockManagerId(0, 172.20.0.6, 33921, None)
25/11/18 06:02:21 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:02:21 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/11/18 06:02:21 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:02:22 INFO CodeGenerator: Code generated in 350.439848 ms
25/11/18 06:02:23 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 338.3 KiB, free 366.0 MiB)
25/11/18 06:02:23 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.9 MiB)
25/11/18 06:02:23 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 6b05748f7bac:36763 (size: 32.4 KiB, free: 366.3 MiB)
25/11/18 06:02:23 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:02:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:02:23 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/11/18 06:02:23 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:02:23 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/11/18 06:02:23 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:02:23 INFO DAGScheduler: Missing parents: List()
25/11/18 06:02:23 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:02:23 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/11/18 06:02:23 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/11/18 06:02:23 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 6b05748f7bac:36763 (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:02:23 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/11/18 06:02:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:02:23 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/11/18 06:02:23 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:02:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.0.6:33921 (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:02:26 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.0.6:33921 (size: 32.4 KiB, free: 366.3 MiB)
25/11/18 06:02:30 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7226 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:02:30 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/11/18 06:02:30 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 7.418 s
25/11/18 06:02:30 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:02:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/11/18 06:02:30 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 4.778111 s
25/11/18 06:02:31 INFO CodeGenerator: Code generated in 21.508423 ms
25/11/18 06:02:31 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:02:31 INFO FileSourceStrategy: Post-Scan Filters: 
25/11/18 06:02:31 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:02:31 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 338.3 KiB, free 365.6 MiB)
25/11/18 06:02:31 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.6 MiB)
25/11/18 06:02:31 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 6b05748f7bac:36763 (size: 32.4 KiB, free: 366.2 MiB)
25/11/18 06:02:31 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:02:31 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:02:31 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
25/11/18 06:02:31 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
25/11/18 06:02:31 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:02:31 INFO FileSourceStrategy: Post-Scan Filters: 
25/11/18 06:02:31 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:02:31 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 338.1 KiB, free 365.2 MiB)
25/11/18 06:02:31 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.2 MiB)
25/11/18 06:02:31 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 6b05748f7bac:36763 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:02:31 INFO SparkContext: Created broadcast 3 from json at NativeMethodAccessorImpl.java:0
25/11/18 06:02:31 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:02:31 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
25/11/18 06:02:31 INFO DAGScheduler: Got job 1 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:02:31 INFO DAGScheduler: Final stage: ResultStage 1 (json at NativeMethodAccessorImpl.java:0)
25/11/18 06:02:31 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:02:31 INFO DAGScheduler: Missing parents: List()
25/11/18 06:02:31 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:02:31 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 12.4 KiB, free 365.2 MiB)
25/11/18 06:02:31 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 365.2 MiB)
25/11/18 06:02:31 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 6b05748f7bac:36763 (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:02:31 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/11/18 06:02:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:02:31 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/11/18 06:02:31 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:02:31 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.0.6:33921 (size: 6.5 KiB, free: 366.3 MiB)
25/11/18 06:02:31 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.0.6:33921 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:02:31 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 301 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:02:31 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/11/18 06:02:31 INFO DAGScheduler: ResultStage 1 (json at NativeMethodAccessorImpl.java:0) finished in 0.345 s
25/11/18 06:02:31 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:02:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/11/18 06:02:31 INFO DAGScheduler: Job 1 finished: json at NativeMethodAccessorImpl.java:0, took 0.357609 s
25/11/18 06:02:32 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/11/18 06:02:32 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/11/18 06:02:32 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/11/18 06:02:32 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:02:32 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:02:32 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:02:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:02:33 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:02:33 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
25/11/18 06:02:33 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 6b05748f7bac:36763 in memory (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:02:33 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.20.0.6:33921 in memory (size: 32.5 KiB, free: 366.3 MiB)
25/11/18 06:02:33 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 6b05748f7bac:36763 in memory (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:02:33 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.20.0.6:33921 in memory (size: 6.5 KiB, free: 366.3 MiB)
25/11/18 06:02:33 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 6b05748f7bac:36763 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/11/18 06:02:33 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.0.6:33921 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:02:33 INFO CodeGenerator: Code generated in 26.760815 ms
25/11/18 06:02:33 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 338.2 KiB, free 365.2 MiB)
25/11/18 06:02:33 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.2 MiB)
25/11/18 06:02:33 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 6b05748f7bac:36763 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:02:33 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:02:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:02:33 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:02:33 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/11/18 06:02:33 INFO DAGScheduler: Final stage: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/11/18 06:02:33 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:02:33 INFO DAGScheduler: Missing parents: List()
25/11/18 06:02:33 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/11/18 06:02:33 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 14.4 KiB, free 365.2 MiB)
25/11/18 06:02:33 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 365.2 MiB)
25/11/18 06:02:33 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 6b05748f7bac:36763 (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:02:33 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/11/18 06:02:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/11/18 06:02:33 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/11/18 06:02:33 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:02:33 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.20.0.6:33921 (size: 7.2 KiB, free: 366.3 MiB)
25/11/18 06:02:33 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.20.0.6:33921 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:02:33 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 369 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:02:33 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/11/18 06:02:33 INFO DAGScheduler: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.389 s
25/11/18 06:02:33 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:02:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/11/18 06:02:33 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.396673 s
25/11/18 06:02:33 INFO CodeGenerator: Code generated in 18.612443 ms
25/11/18 06:02:33 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 1025.0 KiB, free 364.2 MiB)
25/11/18 06:02:33 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 250.0 B, free 364.2 MiB)
25/11/18 06:02:33 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 6b05748f7bac:36763 (size: 250.0 B, free: 366.2 MiB)
25/11/18 06:02:33 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:02:33 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:02:33 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:02:33 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:02:34 INFO CodeGenerator: Code generated in 36.073008 ms
25/11/18 06:02:34 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 338.0 KiB, free 363.9 MiB)
25/11/18 06:02:34 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 363.8 MiB)
25/11/18 06:02:34 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 6b05748f7bac:36763 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:02:34 INFO SparkContext: Created broadcast 8 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:02:34 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:02:34 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/11/18 06:02:34 INFO DAGScheduler: Got job 3 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:02:34 INFO DAGScheduler: Final stage: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0)
25/11/18 06:02:34 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:02:34 INFO DAGScheduler: Missing parents: List()
25/11/18 06:02:34 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:02:34 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 211.3 KiB, free 363.6 MiB)
25/11/18 06:02:34 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 75.9 KiB, free 363.5 MiB)
25/11/18 06:02:34 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 6b05748f7bac:36763 (size: 75.9 KiB, free: 366.1 MiB)
25/11/18 06:02:34 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/11/18 06:02:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:02:34 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/11/18 06:02:34 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:02:34 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.20.0.6:33921 (size: 75.9 KiB, free: 366.2 MiB)
25/11/18 06:02:34 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.20.0.6:33921 (size: 250.0 B, free: 366.2 MiB)
25/11/18 06:02:34 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.20.0.6:33921 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:02:34 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 726 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:02:34 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/11/18 06:02:34 INFO DAGScheduler: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0) finished in 0.772 s
25/11/18 06:02:34 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:02:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/11/18 06:02:34 INFO DAGScheduler: Job 3 finished: csv at NativeMethodAccessorImpl.java:0, took 0.780920 s
25/11/18 06:02:34 INFO FileFormatWriter: Start to commit write Job 76bd44ee-5f46-41b6-ab93-36b66de77f05.
25/11/18 06:02:35 INFO FileFormatWriter: Write Job 76bd44ee-5f46-41b6-ab93-36b66de77f05 committed. Elapsed time: 127 ms.
25/11/18 06:02:35 INFO FileFormatWriter: Finished processing stats for write job 76bd44ee-5f46-41b6-ab93-36b66de77f05.
25/11/18 06:02:35 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/11/18 06:02:35 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/11/18 06:02:35 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/11/18 06:02:35 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:02:35 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:02:35 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:02:35 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:02:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:02:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:02:35 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:02:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:02:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:02:35 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:02:35 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 338.2 KiB, free 363.2 MiB)
25/11/18 06:02:35 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 363.2 MiB)
25/11/18 06:02:35 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 6b05748f7bac:36763 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:02:35 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:02:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:02:35 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:02:35 INFO DAGScheduler: Got job 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/11/18 06:02:35 INFO DAGScheduler: Final stage: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/11/18 06:02:35 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:02:35 INFO DAGScheduler: Missing parents: List()
25/11/18 06:02:35 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/11/18 06:02:35 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 14.4 KiB, free 363.2 MiB)
25/11/18 06:02:35 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 363.2 MiB)
25/11/18 06:02:35 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 6b05748f7bac:36763 (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:02:35 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/11/18 06:02:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/11/18 06:02:35 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/11/18 06:02:35 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:02:35 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.20.0.6:33921 (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:02:35 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.20.0.6:33921 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:02:35 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 109 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:02:35 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/11/18 06:02:35 INFO DAGScheduler: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.129 s
25/11/18 06:02:35 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:02:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/11/18 06:02:35 INFO DAGScheduler: Job 4 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.136927 s
25/11/18 06:02:35 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 1025.0 KiB, free 362.2 MiB)
25/11/18 06:02:35 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 250.0 B, free 362.2 MiB)
25/11/18 06:02:35 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 6b05748f7bac:36763 (size: 250.0 B, free: 366.1 MiB)
25/11/18 06:02:35 INFO SparkContext: Created broadcast 12 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:02:35 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:02:35 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:02:35 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:02:35 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 338.0 KiB, free 361.8 MiB)
25/11/18 06:02:35 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 361.8 MiB)
25/11/18 06:02:35 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 6b05748f7bac:36763 (size: 32.5 KiB, free: 366.0 MiB)
25/11/18 06:02:35 INFO SparkContext: Created broadcast 13 from parquet at NativeMethodAccessorImpl.java:0
25/11/18 06:02:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:02:35 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
25/11/18 06:02:35 INFO DAGScheduler: Got job 5 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:02:35 INFO DAGScheduler: Final stage: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0)
25/11/18 06:02:35 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:02:35 INFO DAGScheduler: Missing parents: List()
25/11/18 06:02:35 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:02:35 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 211.3 KiB, free 361.6 MiB)
25/11/18 06:02:35 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 76.0 KiB, free 361.5 MiB)
25/11/18 06:02:35 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 6b05748f7bac:36763 (size: 76.0 KiB, free: 365.9 MiB)
25/11/18 06:02:35 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/11/18 06:02:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:02:35 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/11/18 06:02:35 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:02:35 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.20.0.6:33921 (size: 76.0 KiB, free: 366.0 MiB)
25/11/18 06:02:35 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.20.0.6:33921 (size: 250.0 B, free: 366.0 MiB)
25/11/18 06:02:36 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.20.0.6:33921 (size: 32.5 KiB, free: 366.0 MiB)
25/11/18 06:02:37 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 1636 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:02:37 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/11/18 06:02:37 INFO DAGScheduler: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0) finished in 1.692 s
25/11/18 06:02:37 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:02:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/11/18 06:02:37 INFO DAGScheduler: Job 5 finished: parquet at NativeMethodAccessorImpl.java:0, took 1.698614 s
25/11/18 06:02:37 INFO FileFormatWriter: Start to commit write Job 781d4fb8-dea4-4550-aa74-35074c82aff4.
25/11/18 06:02:37 INFO FileFormatWriter: Write Job 781d4fb8-dea4-4550-aa74-35074c82aff4 committed. Elapsed time: 40 ms.
25/11/18 06:02:37 INFO FileFormatWriter: Finished processing stats for write job 781d4fb8-dea4-4550-aa74-35074c82aff4.
Job completed for 2025-01-01
25/11/18 06:02:37 INFO SparkUI: Stopped Spark web UI at http://6b05748f7bac:4040
25/11/18 06:02:37 INFO StandaloneSchedulerBackend: Shutting down all executors
25/11/18 06:02:37 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/11/18 06:02:37 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/11/18 06:02:37 INFO MemoryStore: MemoryStore cleared
25/11/18 06:02:37 INFO BlockManager: BlockManager stopped
25/11/18 06:02:37 INFO BlockManagerMaster: BlockManagerMaster stopped
25/11/18 06:02:37 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/11/18 06:02:37 INFO SparkContext: Successfully stopped SparkContext
25/11/18 06:02:37 INFO ShutdownHookManager: Shutdown hook called
25/11/18 06:02:37 INFO ShutdownHookManager: Deleting directory /tmp/spark-b5b65fed-2707-4d0f-98a9-6d63986496f7/pyspark-73cbe744-676d-4349-b088-3c9f0db22df4
25/11/18 06:02:37 INFO ShutdownHookManager: Deleting directory /tmp/spark-aa48ef7a-a16d-42b7-a9e1-d44c9a5eaf55
25/11/18 06:02:37 INFO ShutdownHookManager: Deleting directory /tmp/spark-b5b65fed-2707-4d0f-98a9-6d63986496f7
Job completed for 2025-01-01
/mnt/c/pyspark_stack/spark-apps/cron/run_sales.sh: 1: ---: not found
Triggering sales_etl_job.py for 2025-01-01...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/11/18 06:03:08 INFO SparkContext: Running Spark version 3.2.1
25/11/18 06:03:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/11/18 06:03:08 INFO ResourceUtils: ==============================================================
25/11/18 06:03:08 INFO ResourceUtils: No custom resources configured for spark.driver.
25/11/18 06:03:08 INFO ResourceUtils: ==============================================================
25/11/18 06:03:08 INFO SparkContext: Submitted application: SalesETLJob
25/11/18 06:03:08 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/11/18 06:03:08 INFO ResourceProfile: Limiting resource is cpu
25/11/18 06:03:08 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/11/18 06:03:08 INFO SecurityManager: Changing view acls to: spark
25/11/18 06:03:08 INFO SecurityManager: Changing modify acls to: spark
25/11/18 06:03:08 INFO SecurityManager: Changing view acls groups to: 
25/11/18 06:03:08 INFO SecurityManager: Changing modify acls groups to: 
25/11/18 06:03:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
25/11/18 06:03:09 INFO Utils: Successfully started service 'sparkDriver' on port 35531.
25/11/18 06:03:09 INFO SparkEnv: Registering MapOutputTracker
25/11/18 06:03:09 INFO SparkEnv: Registering BlockManagerMaster
25/11/18 06:03:09 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/11/18 06:03:09 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/11/18 06:03:09 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/11/18 06:03:09 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-1ecaf9d4-7757-467b-a2c3-53dff459ffcc
25/11/18 06:03:09 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/11/18 06:03:09 INFO SparkEnv: Registering OutputCommitCoordinator
25/11/18 06:03:09 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/11/18 06:03:09 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://6b05748f7bac:4040
25/11/18 06:03:10 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/11/18 06:03:10 INFO TransportClientFactory: Successfully created connection to spark-master/172.20.0.3:7077 after 59 ms (0 ms spent in bootstraps)
25/11/18 06:03:10 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20251118060310-0003
25/11/18 06:03:10 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251118060310-0003/0 on worker-20251118055626-172.20.0.6-38023 (172.20.0.6:38023) with 12 core(s)
25/11/18 06:03:10 INFO StandaloneSchedulerBackend: Granted executor ID app-20251118060310-0003/0 on hostPort 172.20.0.6:38023 with 12 core(s), 1024.0 MiB RAM
25/11/18 06:03:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45779.
25/11/18 06:03:10 INFO NettyBlockTransferService: Server created on 6b05748f7bac:45779
25/11/18 06:03:10 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/11/18 06:03:10 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 6b05748f7bac, 45779, None)
25/11/18 06:03:10 INFO BlockManagerMasterEndpoint: Registering block manager 6b05748f7bac:45779 with 366.3 MiB RAM, BlockManagerId(driver, 6b05748f7bac, 45779, None)
25/11/18 06:03:10 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 6b05748f7bac, 45779, None)
25/11/18 06:03:10 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 6b05748f7bac, 45779, None)
25/11/18 06:03:10 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251118060310-0003/0 is now RUNNING
25/11/18 06:03:11 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/11/18 06:03:11 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/11/18 06:03:11 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
25/11/18 06:03:15 INFO InMemoryFileIndex: It took 179 ms to list leaf files for 1 paths.
25/11/18 06:03:15 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.6:42468) with ID 0,  ResourceProfileId 0
25/11/18 06:03:15 INFO InMemoryFileIndex: It took 19 ms to list leaf files for 1 paths.
25/11/18 06:03:15 INFO BlockManagerMasterEndpoint: Registering block manager 172.20.0.6:35407 with 366.3 MiB RAM, BlockManagerId(0, 172.20.0.6, 35407, None)
25/11/18 06:03:20 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:03:20 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/11/18 06:03:20 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:03:21 INFO CodeGenerator: Code generated in 354.416584 ms
25/11/18 06:03:21 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 338.3 KiB, free 366.0 MiB)
25/11/18 06:03:21 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.9 MiB)
25/11/18 06:03:21 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 6b05748f7bac:45779 (size: 32.4 KiB, free: 366.3 MiB)
25/11/18 06:03:21 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:03:21 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:03:21 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/11/18 06:03:21 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:03:21 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/11/18 06:03:21 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:03:21 INFO DAGScheduler: Missing parents: List()
25/11/18 06:03:21 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:03:22 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/11/18 06:03:22 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/11/18 06:03:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 6b05748f7bac:45779 (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:03:22 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/11/18 06:03:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:03:22 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/11/18 06:03:22 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:03:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.0.6:35407 (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:03:24 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.0.6:35407 (size: 32.4 KiB, free: 366.3 MiB)
25/11/18 06:03:26 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4217 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:03:26 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/11/18 06:03:26 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 4.416 s
25/11/18 06:03:26 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:03:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/11/18 06:03:26 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 4.496333 s
25/11/18 06:03:26 INFO CodeGenerator: Code generated in 27.014763 ms
25/11/18 06:03:26 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:03:26 INFO FileSourceStrategy: Post-Scan Filters: 
25/11/18 06:03:26 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:03:26 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 338.3 KiB, free 365.6 MiB)
25/11/18 06:03:26 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.6 MiB)
25/11/18 06:03:26 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 6b05748f7bac:45779 (size: 32.4 KiB, free: 366.2 MiB)
25/11/18 06:03:26 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:03:26 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:03:26 INFO InMemoryFileIndex: It took 9 ms to list leaf files for 1 paths.
25/11/18 06:03:26 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 1 paths.
25/11/18 06:03:26 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:03:26 INFO FileSourceStrategy: Post-Scan Filters: 
25/11/18 06:03:26 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:03:26 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 338.1 KiB, free 365.2 MiB)
25/11/18 06:03:26 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.2 MiB)
25/11/18 06:03:26 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 6b05748f7bac:45779 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:03:26 INFO SparkContext: Created broadcast 3 from json at NativeMethodAccessorImpl.java:0
25/11/18 06:03:26 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:03:27 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
25/11/18 06:03:27 INFO DAGScheduler: Got job 1 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:03:27 INFO DAGScheduler: Final stage: ResultStage 1 (json at NativeMethodAccessorImpl.java:0)
25/11/18 06:03:27 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:03:27 INFO DAGScheduler: Missing parents: List()
25/11/18 06:03:27 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:03:27 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 12.4 KiB, free 365.2 MiB)
25/11/18 06:03:27 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 365.2 MiB)
25/11/18 06:03:27 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 6b05748f7bac:45779 (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:03:27 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/11/18 06:03:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:03:27 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/11/18 06:03:27 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:03:27 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.0.6:35407 (size: 6.5 KiB, free: 366.3 MiB)
25/11/18 06:03:27 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.0.6:35407 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:03:27 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 333 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:03:27 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/11/18 06:03:27 INFO DAGScheduler: ResultStage 1 (json at NativeMethodAccessorImpl.java:0) finished in 0.421 s
25/11/18 06:03:27 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:03:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/11/18 06:03:27 INFO DAGScheduler: Job 1 finished: json at NativeMethodAccessorImpl.java:0, took 0.442558 s
25/11/18 06:03:28 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/11/18 06:03:28 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/11/18 06:03:28 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/11/18 06:03:28 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:03:28 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:03:28 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:03:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:03:28 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:03:28 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
25/11/18 06:03:28 INFO CodeGenerator: Code generated in 35.681781 ms
25/11/18 06:03:28 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 338.2 KiB, free 364.8 MiB)
25/11/18 06:03:28 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 364.8 MiB)
25/11/18 06:03:28 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 6b05748f7bac:45779 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:03:28 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:03:28 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:03:28 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:03:28 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/11/18 06:03:28 INFO DAGScheduler: Final stage: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/11/18 06:03:28 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:03:28 INFO DAGScheduler: Missing parents: List()
25/11/18 06:03:28 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/11/18 06:03:28 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 14.4 KiB, free 364.8 MiB)
25/11/18 06:03:28 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 364.8 MiB)
25/11/18 06:03:28 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 6b05748f7bac:45779 (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:03:28 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/11/18 06:03:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/11/18 06:03:28 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/11/18 06:03:28 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:03:28 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.20.0.6:35407 (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:03:29 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.20.0.6:35407 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:03:29 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 374 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:03:29 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/11/18 06:03:29 INFO DAGScheduler: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.404 s
25/11/18 06:03:29 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:03:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/11/18 06:03:29 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.412181 s
25/11/18 06:03:29 INFO CodeGenerator: Code generated in 19.902672 ms
25/11/18 06:03:29 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 1025.0 KiB, free 363.8 MiB)
25/11/18 06:03:29 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 250.0 B, free 363.8 MiB)
25/11/18 06:03:29 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 6b05748f7bac:45779 (size: 250.0 B, free: 366.2 MiB)
25/11/18 06:03:29 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:03:29 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:03:29 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:03:29 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:03:29 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 6b05748f7bac:45779 in memory (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:03:29 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.20.0.6:35407 in memory (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:03:29 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 6b05748f7bac:45779 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/11/18 06:03:29 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.0.6:35407 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/11/18 06:03:29 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 6b05748f7bac:45779 in memory (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:03:29 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.20.0.6:35407 in memory (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:03:29 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 6b05748f7bac:45779 in memory (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:03:29 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.20.0.6:35407 in memory (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:03:29 INFO CodeGenerator: Code generated in 48.537131 ms
25/11/18 06:03:29 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 338.0 KiB, free 363.9 MiB)
25/11/18 06:03:29 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 363.9 MiB)
25/11/18 06:03:29 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 6b05748f7bac:45779 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:03:29 INFO SparkContext: Created broadcast 8 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:03:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:03:29 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/11/18 06:03:29 INFO DAGScheduler: Got job 3 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:03:29 INFO DAGScheduler: Final stage: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0)
25/11/18 06:03:29 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:03:29 INFO DAGScheduler: Missing parents: List()
25/11/18 06:03:29 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:03:29 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 211.3 KiB, free 363.6 MiB)
25/11/18 06:03:29 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 75.9 KiB, free 363.6 MiB)
25/11/18 06:03:29 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 6b05748f7bac:45779 (size: 75.9 KiB, free: 366.1 MiB)
25/11/18 06:03:29 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/11/18 06:03:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:03:29 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/11/18 06:03:29 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:03:29 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.20.0.6:35407 (size: 75.9 KiB, free: 366.2 MiB)
25/11/18 06:03:30 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.20.0.6:35407 (size: 250.0 B, free: 366.2 MiB)
25/11/18 06:03:30 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.20.0.6:35407 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:03:30 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 705 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:03:30 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/11/18 06:03:30 INFO DAGScheduler: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0) finished in 0.751 s
25/11/18 06:03:30 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:03:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/11/18 06:03:30 INFO DAGScheduler: Job 3 finished: csv at NativeMethodAccessorImpl.java:0, took 0.759462 s
25/11/18 06:03:30 INFO FileFormatWriter: Start to commit write Job 9321e373-c248-4e9f-886f-efa1c8c8fc6c.
25/11/18 06:03:30 INFO FileFormatWriter: Write Job 9321e373-c248-4e9f-886f-efa1c8c8fc6c committed. Elapsed time: 115 ms.
25/11/18 06:03:30 INFO FileFormatWriter: Finished processing stats for write job 9321e373-c248-4e9f-886f-efa1c8c8fc6c.
25/11/18 06:03:30 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/11/18 06:03:30 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/11/18 06:03:30 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/11/18 06:03:30 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:03:30 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:03:30 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:03:30 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:03:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:03:30 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:03:30 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:03:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:03:30 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:03:30 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:03:30 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 338.2 KiB, free 363.2 MiB)
25/11/18 06:03:30 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 363.2 MiB)
25/11/18 06:03:30 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 6b05748f7bac:45779 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:03:30 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:03:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:03:30 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:03:30 INFO DAGScheduler: Got job 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/11/18 06:03:30 INFO DAGScheduler: Final stage: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/11/18 06:03:30 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:03:30 INFO DAGScheduler: Missing parents: List()
25/11/18 06:03:30 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/11/18 06:03:30 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 14.4 KiB, free 363.2 MiB)
25/11/18 06:03:30 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 363.2 MiB)
25/11/18 06:03:30 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 6b05748f7bac:45779 (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:03:30 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/11/18 06:03:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/11/18 06:03:30 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/11/18 06:03:30 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:03:30 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.20.0.6:35407 (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:03:31 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.20.0.6:35407 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:03:31 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 107 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:03:31 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/11/18 06:03:31 INFO DAGScheduler: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.124 s
25/11/18 06:03:31 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:03:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/11/18 06:03:31 INFO DAGScheduler: Job 4 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.131051 s
25/11/18 06:03:31 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 1025.0 KiB, free 362.2 MiB)
25/11/18 06:03:31 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 250.0 B, free 362.2 MiB)
25/11/18 06:03:31 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 6b05748f7bac:45779 (size: 250.0 B, free: 366.1 MiB)
25/11/18 06:03:31 INFO SparkContext: Created broadcast 12 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:03:31 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:03:31 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:03:31 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:03:31 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 338.0 KiB, free 361.9 MiB)
25/11/18 06:03:31 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 361.8 MiB)
25/11/18 06:03:31 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 6b05748f7bac:45779 (size: 32.5 KiB, free: 366.0 MiB)
25/11/18 06:03:31 INFO SparkContext: Created broadcast 13 from parquet at NativeMethodAccessorImpl.java:0
25/11/18 06:03:31 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:03:31 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
25/11/18 06:03:31 INFO DAGScheduler: Got job 5 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:03:31 INFO DAGScheduler: Final stage: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0)
25/11/18 06:03:31 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:03:31 INFO DAGScheduler: Missing parents: List()
25/11/18 06:03:31 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:03:31 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 211.3 KiB, free 361.6 MiB)
25/11/18 06:03:31 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 76.0 KiB, free 361.5 MiB)
25/11/18 06:03:31 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 6b05748f7bac:45779 (size: 76.0 KiB, free: 366.0 MiB)
25/11/18 06:03:31 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/11/18 06:03:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:03:31 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/11/18 06:03:31 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:03:31 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.20.0.6:35407 (size: 76.0 KiB, free: 366.0 MiB)
25/11/18 06:03:31 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.20.0.6:35407 (size: 250.0 B, free: 366.0 MiB)
25/11/18 06:03:32 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.20.0.6:35407 (size: 32.5 KiB, free: 366.0 MiB)
25/11/18 06:03:35 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 4776 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:03:35 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/11/18 06:03:35 INFO DAGScheduler: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0) finished in 4.809 s
25/11/18 06:03:35 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:03:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/11/18 06:03:35 INFO DAGScheduler: Job 5 finished: parquet at NativeMethodAccessorImpl.java:0, took 2.113430 s
25/11/18 06:03:36 INFO FileFormatWriter: Start to commit write Job b7cd410d-84db-4508-962f-7663a6b45eec.
25/11/18 06:03:36 INFO FileFormatWriter: Write Job b7cd410d-84db-4508-962f-7663a6b45eec committed. Elapsed time: 53 ms.
25/11/18 06:03:36 INFO FileFormatWriter: Finished processing stats for write job b7cd410d-84db-4508-962f-7663a6b45eec.
Job completed for 2025-01-01
25/11/18 06:03:36 INFO SparkUI: Stopped Spark web UI at http://6b05748f7bac:4040
25/11/18 06:03:36 INFO StandaloneSchedulerBackend: Shutting down all executors
25/11/18 06:03:36 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/11/18 06:03:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/11/18 06:03:36 INFO MemoryStore: MemoryStore cleared
25/11/18 06:03:36 INFO BlockManager: BlockManager stopped
25/11/18 06:03:36 INFO BlockManagerMaster: BlockManagerMaster stopped
25/11/18 06:03:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/11/18 06:03:36 INFO SparkContext: Successfully stopped SparkContext
25/11/18 06:03:36 INFO ShutdownHookManager: Shutdown hook called
25/11/18 06:03:36 INFO ShutdownHookManager: Deleting directory /tmp/spark-3a0180ed-3599-4970-9264-ec57bc6dd3bd
25/11/18 06:03:36 INFO ShutdownHookManager: Deleting directory /tmp/spark-3a0180ed-3599-4970-9264-ec57bc6dd3bd/pyspark-32cfc0f2-b6be-438f-b88f-27889cc6fb35
25/11/18 06:03:36 INFO ShutdownHookManager: Deleting directory /tmp/spark-2945ff78-43b1-4bfd-bcbc-3f46a0254220
Job completed for 2025-01-01
/mnt/c/pyspark_stack/spark-apps/cron/run_sales.sh: 1: ---: not found
Triggering sales_etl_job.py for 2025-01-01...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/11/18 06:04:08 INFO SparkContext: Running Spark version 3.2.1
25/11/18 06:04:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/11/18 06:04:09 INFO ResourceUtils: ==============================================================
25/11/18 06:04:09 INFO ResourceUtils: No custom resources configured for spark.driver.
25/11/18 06:04:09 INFO ResourceUtils: ==============================================================
25/11/18 06:04:09 INFO SparkContext: Submitted application: SalesETLJob
25/11/18 06:04:09 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/11/18 06:04:09 INFO ResourceProfile: Limiting resource is cpu
25/11/18 06:04:09 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/11/18 06:04:09 INFO SecurityManager: Changing view acls to: spark
25/11/18 06:04:09 INFO SecurityManager: Changing modify acls to: spark
25/11/18 06:04:09 INFO SecurityManager: Changing view acls groups to: 
25/11/18 06:04:09 INFO SecurityManager: Changing modify acls groups to: 
25/11/18 06:04:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
25/11/18 06:04:09 INFO Utils: Successfully started service 'sparkDriver' on port 35697.
25/11/18 06:04:09 INFO SparkEnv: Registering MapOutputTracker
25/11/18 06:04:09 INFO SparkEnv: Registering BlockManagerMaster
25/11/18 06:04:10 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/11/18 06:04:10 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/11/18 06:04:10 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/11/18 06:04:10 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-871c7763-75ad-42f6-9681-a9a2558a163c
25/11/18 06:04:10 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/11/18 06:04:10 INFO SparkEnv: Registering OutputCommitCoordinator
25/11/18 06:04:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/11/18 06:04:10 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://6b05748f7bac:4040
25/11/18 06:04:11 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/11/18 06:04:11 INFO TransportClientFactory: Successfully created connection to spark-master/172.20.0.3:7077 after 62 ms (0 ms spent in bootstraps)
25/11/18 06:04:11 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20251118060411-0004
25/11/18 06:04:11 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251118060411-0004/0 on worker-20251118055626-172.20.0.6-38023 (172.20.0.6:38023) with 12 core(s)
25/11/18 06:04:11 INFO StandaloneSchedulerBackend: Granted executor ID app-20251118060411-0004/0 on hostPort 172.20.0.6:38023 with 12 core(s), 1024.0 MiB RAM
25/11/18 06:04:11 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39177.
25/11/18 06:04:11 INFO NettyBlockTransferService: Server created on 6b05748f7bac:39177
25/11/18 06:04:11 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/11/18 06:04:11 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 6b05748f7bac, 39177, None)
25/11/18 06:04:11 INFO BlockManagerMasterEndpoint: Registering block manager 6b05748f7bac:39177 with 366.3 MiB RAM, BlockManagerId(driver, 6b05748f7bac, 39177, None)
25/11/18 06:04:11 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 6b05748f7bac, 39177, None)
25/11/18 06:04:11 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 6b05748f7bac, 39177, None)
25/11/18 06:04:11 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251118060411-0004/0 is now RUNNING
25/11/18 06:04:11 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/11/18 06:04:12 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/11/18 06:04:12 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
25/11/18 06:04:15 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.6:60270) with ID 0,  ResourceProfileId 0
25/11/18 06:04:15 INFO InMemoryFileIndex: It took 253 ms to list leaf files for 1 paths.
25/11/18 06:04:15 INFO InMemoryFileIndex: It took 26 ms to list leaf files for 1 paths.
25/11/18 06:04:16 INFO BlockManagerMasterEndpoint: Registering block manager 172.20.0.6:40197 with 366.3 MiB RAM, BlockManagerId(0, 172.20.0.6, 40197, None)
25/11/18 06:04:20 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:04:20 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/11/18 06:04:20 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:04:22 INFO CodeGenerator: Code generated in 353.487077 ms
25/11/18 06:04:22 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 338.3 KiB, free 366.0 MiB)
25/11/18 06:04:22 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.9 MiB)
25/11/18 06:04:22 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 6b05748f7bac:39177 (size: 32.4 KiB, free: 366.3 MiB)
25/11/18 06:04:22 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:04:22 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:04:22 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/11/18 06:04:22 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:04:22 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/11/18 06:04:22 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:04:22 INFO DAGScheduler: Missing parents: List()
25/11/18 06:04:22 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:04:22 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/11/18 06:04:22 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/11/18 06:04:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 6b05748f7bac:39177 (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:04:22 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/11/18 06:04:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:04:22 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/11/18 06:04:22 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:04:23 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.0.6:40197 (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:04:25 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.0.6:40197 (size: 32.4 KiB, free: 366.3 MiB)
25/11/18 06:04:27 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4546 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:04:27 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/11/18 06:04:27 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 4.755 s
25/11/18 06:04:27 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:04:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/11/18 06:04:27 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 4.853033 s
25/11/18 06:04:27 INFO CodeGenerator: Code generated in 24.943684 ms
25/11/18 06:04:27 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:04:27 INFO FileSourceStrategy: Post-Scan Filters: 
25/11/18 06:04:27 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:04:27 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 338.3 KiB, free 365.6 MiB)
25/11/18 06:04:27 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.6 MiB)
25/11/18 06:04:27 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 6b05748f7bac:39177 (size: 32.4 KiB, free: 366.2 MiB)
25/11/18 06:04:27 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:04:27 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:04:27 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 1 paths.
25/11/18 06:04:27 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
25/11/18 06:04:27 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:04:27 INFO FileSourceStrategy: Post-Scan Filters: 
25/11/18 06:04:27 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:04:28 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 338.1 KiB, free 365.2 MiB)
25/11/18 06:04:28 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.2 MiB)
25/11/18 06:04:28 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 6b05748f7bac:39177 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:04:28 INFO SparkContext: Created broadcast 3 from json at NativeMethodAccessorImpl.java:0
25/11/18 06:04:28 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:04:28 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
25/11/18 06:04:28 INFO DAGScheduler: Got job 1 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:04:28 INFO DAGScheduler: Final stage: ResultStage 1 (json at NativeMethodAccessorImpl.java:0)
25/11/18 06:04:28 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:04:28 INFO DAGScheduler: Missing parents: List()
25/11/18 06:04:28 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:04:28 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 12.4 KiB, free 365.2 MiB)
25/11/18 06:04:28 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 365.2 MiB)
25/11/18 06:04:28 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 6b05748f7bac:39177 (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:04:28 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/11/18 06:04:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:04:28 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/11/18 06:04:28 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:04:28 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.0.6:40197 (size: 6.5 KiB, free: 366.3 MiB)
25/11/18 06:04:28 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.0.6:40197 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:04:28 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 326 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:04:28 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/11/18 06:04:28 INFO DAGScheduler: ResultStage 1 (json at NativeMethodAccessorImpl.java:0) finished in 0.384 s
25/11/18 06:04:28 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:04:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/11/18 06:04:28 INFO DAGScheduler: Job 1 finished: json at NativeMethodAccessorImpl.java:0, took 0.400221 s
25/11/18 06:04:29 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/11/18 06:04:29 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/11/18 06:04:29 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/11/18 06:04:29 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:04:29 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:04:29 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:04:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:04:29 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:04:29 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
25/11/18 06:04:29 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 6b05748f7bac:39177 in memory (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:04:29 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.20.0.6:40197 in memory (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:04:29 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 6b05748f7bac:39177 in memory (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:04:29 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.20.0.6:40197 in memory (size: 32.5 KiB, free: 366.3 MiB)
25/11/18 06:04:29 INFO CodeGenerator: Code generated in 42.780818 ms
25/11/18 06:04:29 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 6b05748f7bac:39177 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/11/18 06:04:29 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 338.2 KiB, free 365.2 MiB)
25/11/18 06:04:29 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.0.6:40197 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:04:29 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.2 MiB)
25/11/18 06:04:29 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 6b05748f7bac:39177 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:04:29 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:04:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:04:29 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:04:29 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/11/18 06:04:29 INFO DAGScheduler: Final stage: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/11/18 06:04:29 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:04:29 INFO DAGScheduler: Missing parents: List()
25/11/18 06:04:29 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/11/18 06:04:29 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 14.4 KiB, free 365.2 MiB)
25/11/18 06:04:29 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 365.2 MiB)
25/11/18 06:04:29 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 6b05748f7bac:39177 (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:04:29 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/11/18 06:04:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/11/18 06:04:29 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/11/18 06:04:29 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:04:29 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.20.0.6:40197 (size: 7.2 KiB, free: 366.3 MiB)
25/11/18 06:04:30 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.20.0.6:40197 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:04:30 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 361 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:04:30 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/11/18 06:04:30 INFO DAGScheduler: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.379 s
25/11/18 06:04:30 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:04:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/11/18 06:04:30 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.387524 s
25/11/18 06:04:30 INFO CodeGenerator: Code generated in 15.400349 ms
25/11/18 06:04:30 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 1025.0 KiB, free 364.2 MiB)
25/11/18 06:04:30 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 250.0 B, free 364.2 MiB)
25/11/18 06:04:30 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 6b05748f7bac:39177 (size: 250.0 B, free: 366.2 MiB)
25/11/18 06:04:30 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:04:30 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:04:30 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:04:30 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:04:30 INFO CodeGenerator: Code generated in 35.243059 ms
25/11/18 06:04:30 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 338.0 KiB, free 363.9 MiB)
25/11/18 06:04:30 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 363.8 MiB)
25/11/18 06:04:30 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 6b05748f7bac:39177 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:04:30 INFO SparkContext: Created broadcast 8 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:04:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:04:30 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/11/18 06:04:30 INFO DAGScheduler: Got job 3 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:04:30 INFO DAGScheduler: Final stage: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0)
25/11/18 06:04:30 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:04:30 INFO DAGScheduler: Missing parents: List()
25/11/18 06:04:30 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:04:30 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 211.3 KiB, free 363.6 MiB)
25/11/18 06:04:30 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 75.9 KiB, free 363.5 MiB)
25/11/18 06:04:30 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 6b05748f7bac:39177 (size: 75.9 KiB, free: 366.1 MiB)
25/11/18 06:04:30 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/11/18 06:04:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:04:30 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/11/18 06:04:30 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:04:30 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.20.0.6:40197 (size: 75.9 KiB, free: 366.2 MiB)
25/11/18 06:04:30 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.20.0.6:40197 (size: 250.0 B, free: 366.2 MiB)
25/11/18 06:04:31 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.20.0.6:40197 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:04:31 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 754 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:04:31 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/11/18 06:04:31 INFO DAGScheduler: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0) finished in 0.808 s
25/11/18 06:04:31 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:04:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/11/18 06:04:31 INFO DAGScheduler: Job 3 finished: csv at NativeMethodAccessorImpl.java:0, took 0.815926 s
25/11/18 06:04:31 INFO FileFormatWriter: Start to commit write Job 404f7373-d08d-40e2-8b90-e8c194121b82.
25/11/18 06:04:31 INFO FileFormatWriter: Write Job 404f7373-d08d-40e2-8b90-e8c194121b82 committed. Elapsed time: 109 ms.
25/11/18 06:04:31 INFO FileFormatWriter: Finished processing stats for write job 404f7373-d08d-40e2-8b90-e8c194121b82.
25/11/18 06:04:31 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/11/18 06:04:31 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/11/18 06:04:31 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/11/18 06:04:31 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:04:31 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:04:31 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:04:31 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:04:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:04:31 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:04:31 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:04:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:04:31 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:04:31 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:04:31 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 338.2 KiB, free 363.2 MiB)
25/11/18 06:04:31 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 363.2 MiB)
25/11/18 06:04:31 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 6b05748f7bac:39177 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:04:31 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:04:31 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:04:31 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:04:31 INFO DAGScheduler: Got job 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/11/18 06:04:31 INFO DAGScheduler: Final stage: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/11/18 06:04:31 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:04:31 INFO DAGScheduler: Missing parents: List()
25/11/18 06:04:31 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/11/18 06:04:31 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 14.4 KiB, free 363.2 MiB)
25/11/18 06:04:31 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 363.2 MiB)
25/11/18 06:04:31 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 6b05748f7bac:39177 (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:04:31 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/11/18 06:04:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/11/18 06:04:31 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/11/18 06:04:31 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:04:31 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.20.0.6:40197 (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:04:31 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.20.0.6:40197 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:04:31 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 113 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:04:31 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/11/18 06:04:31 INFO DAGScheduler: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.132 s
25/11/18 06:04:31 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:04:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/11/18 06:04:31 INFO DAGScheduler: Job 4 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.139738 s
25/11/18 06:04:32 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 1025.0 KiB, free 362.2 MiB)
25/11/18 06:04:32 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 250.0 B, free 362.2 MiB)
25/11/18 06:04:32 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 6b05748f7bac:39177 (size: 250.0 B, free: 366.1 MiB)
25/11/18 06:04:32 INFO SparkContext: Created broadcast 12 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:04:32 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:04:32 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:04:32 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:04:32 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 338.0 KiB, free 361.8 MiB)
25/11/18 06:04:32 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 361.8 MiB)
25/11/18 06:04:32 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 6b05748f7bac:39177 (size: 32.5 KiB, free: 366.0 MiB)
25/11/18 06:04:32 INFO SparkContext: Created broadcast 13 from parquet at NativeMethodAccessorImpl.java:0
25/11/18 06:04:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:04:32 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
25/11/18 06:04:32 INFO DAGScheduler: Got job 5 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:04:32 INFO DAGScheduler: Final stage: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0)
25/11/18 06:04:32 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:04:32 INFO DAGScheduler: Missing parents: List()
25/11/18 06:04:32 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:04:32 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 211.3 KiB, free 361.6 MiB)
25/11/18 06:04:32 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 76.0 KiB, free 361.5 MiB)
25/11/18 06:04:32 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 6b05748f7bac:39177 (size: 76.0 KiB, free: 365.9 MiB)
25/11/18 06:04:32 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/11/18 06:04:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:04:32 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/11/18 06:04:32 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:04:32 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.20.0.6:40197 (size: 76.0 KiB, free: 366.0 MiB)
25/11/18 06:04:32 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.20.0.6:40197 (size: 250.0 B, free: 366.0 MiB)
25/11/18 06:04:33 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.20.0.6:40197 (size: 32.5 KiB, free: 366.0 MiB)
25/11/18 06:04:33 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 1492 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:04:33 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/11/18 06:04:33 INFO DAGScheduler: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0) finished in 1.531 s
25/11/18 06:04:33 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:04:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/11/18 06:04:33 INFO DAGScheduler: Job 5 finished: parquet at NativeMethodAccessorImpl.java:0, took 1.537676 s
25/11/18 06:04:33 INFO FileFormatWriter: Start to commit write Job 359447f9-5e94-45f4-ae78-1a0abffa22ac.
25/11/18 06:04:33 INFO FileFormatWriter: Write Job 359447f9-5e94-45f4-ae78-1a0abffa22ac committed. Elapsed time: 41 ms.
25/11/18 06:04:33 INFO FileFormatWriter: Finished processing stats for write job 359447f9-5e94-45f4-ae78-1a0abffa22ac.
Job completed for 2025-01-01
25/11/18 06:04:33 INFO SparkUI: Stopped Spark web UI at http://6b05748f7bac:4040
25/11/18 06:04:33 INFO StandaloneSchedulerBackend: Shutting down all executors
25/11/18 06:04:33 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/11/18 06:04:33 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/11/18 06:04:33 INFO MemoryStore: MemoryStore cleared
25/11/18 06:04:33 INFO BlockManager: BlockManager stopped
25/11/18 06:04:33 INFO BlockManagerMaster: BlockManagerMaster stopped
25/11/18 06:04:33 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/11/18 06:04:33 INFO SparkContext: Successfully stopped SparkContext
25/11/18 06:04:34 INFO ShutdownHookManager: Shutdown hook called
25/11/18 06:04:34 INFO ShutdownHookManager: Deleting directory /tmp/spark-9d4b3354-8551-4b90-9d0c-90f6334b91e2
25/11/18 06:04:34 INFO ShutdownHookManager: Deleting directory /tmp/spark-84aae531-ac31-4e5b-a221-490f9edf7d37
25/11/18 06:04:34 INFO ShutdownHookManager: Deleting directory /tmp/spark-84aae531-ac31-4e5b-a221-490f9edf7d37/pyspark-c68f9120-7e45-44c4-bfc1-62a391f3a7d5
Job completed for 2025-01-01
/mnt/c/pyspark_stack/spark-apps/cron/run_sales.sh: 1: ---: not found
Triggering sales_etl_job.py for 2025-01-01...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/11/18 06:05:08 INFO SparkContext: Running Spark version 3.2.1
25/11/18 06:05:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/11/18 06:05:08 INFO ResourceUtils: ==============================================================
25/11/18 06:05:08 INFO ResourceUtils: No custom resources configured for spark.driver.
25/11/18 06:05:08 INFO ResourceUtils: ==============================================================
25/11/18 06:05:08 INFO SparkContext: Submitted application: SalesETLJob
25/11/18 06:05:08 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/11/18 06:05:08 INFO ResourceProfile: Limiting resource is cpu
25/11/18 06:05:08 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/11/18 06:05:08 INFO SecurityManager: Changing view acls to: spark
25/11/18 06:05:08 INFO SecurityManager: Changing modify acls to: spark
25/11/18 06:05:08 INFO SecurityManager: Changing view acls groups to: 
25/11/18 06:05:08 INFO SecurityManager: Changing modify acls groups to: 
25/11/18 06:05:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
25/11/18 06:05:09 INFO Utils: Successfully started service 'sparkDriver' on port 46529.
25/11/18 06:05:09 INFO SparkEnv: Registering MapOutputTracker
25/11/18 06:05:09 INFO SparkEnv: Registering BlockManagerMaster
25/11/18 06:05:09 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/11/18 06:05:09 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/11/18 06:05:09 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/11/18 06:05:09 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-4d744d7a-7a15-4dbd-80ea-550ee2cb7562
25/11/18 06:05:09 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/11/18 06:05:09 INFO SparkEnv: Registering OutputCommitCoordinator
25/11/18 06:05:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/11/18 06:05:10 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://6b05748f7bac:4040
25/11/18 06:05:10 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/11/18 06:05:10 INFO TransportClientFactory: Successfully created connection to spark-master/172.20.0.3:7077 after 64 ms (0 ms spent in bootstraps)
25/11/18 06:05:10 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20251118060510-0005
25/11/18 06:05:10 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251118060510-0005/0 on worker-20251118055626-172.20.0.6-38023 (172.20.0.6:38023) with 12 core(s)
25/11/18 06:05:10 INFO StandaloneSchedulerBackend: Granted executor ID app-20251118060510-0005/0 on hostPort 172.20.0.6:38023 with 12 core(s), 1024.0 MiB RAM
25/11/18 06:05:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37317.
25/11/18 06:05:10 INFO NettyBlockTransferService: Server created on 6b05748f7bac:37317
25/11/18 06:05:10 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/11/18 06:05:10 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 6b05748f7bac, 37317, None)
25/11/18 06:05:10 INFO BlockManagerMasterEndpoint: Registering block manager 6b05748f7bac:37317 with 366.3 MiB RAM, BlockManagerId(driver, 6b05748f7bac, 37317, None)
25/11/18 06:05:10 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 6b05748f7bac, 37317, None)
25/11/18 06:05:10 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 6b05748f7bac, 37317, None)
25/11/18 06:05:10 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251118060510-0005/0 is now RUNNING
25/11/18 06:05:14 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/11/18 06:05:14 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/11/18 06:05:14 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
25/11/18 06:05:18 INFO InMemoryFileIndex: It took 152 ms to list leaf files for 1 paths.
25/11/18 06:05:18 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.6:37200) with ID 0,  ResourceProfileId 0
25/11/18 06:05:18 INFO InMemoryFileIndex: It took 14 ms to list leaf files for 1 paths.
25/11/18 06:05:18 INFO BlockManagerMasterEndpoint: Registering block manager 172.20.0.6:34523 with 366.3 MiB RAM, BlockManagerId(0, 172.20.0.6, 34523, None)
25/11/18 06:05:23 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:05:23 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/11/18 06:05:23 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:05:24 INFO CodeGenerator: Code generated in 391.0051 ms
25/11/18 06:05:24 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 338.3 KiB, free 366.0 MiB)
25/11/18 06:05:24 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.9 MiB)
25/11/18 06:05:24 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 6b05748f7bac:37317 (size: 32.4 KiB, free: 366.3 MiB)
25/11/18 06:05:24 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:05:24 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:05:25 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/11/18 06:05:25 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:05:25 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/11/18 06:05:25 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:05:25 INFO DAGScheduler: Missing parents: List()
25/11/18 06:05:25 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:05:25 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/11/18 06:05:25 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/11/18 06:05:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 6b05748f7bac:37317 (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:05:25 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/11/18 06:05:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:05:25 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/11/18 06:05:25 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:05:26 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.0.6:34523 (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:05:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.0.6:34523 (size: 32.4 KiB, free: 366.3 MiB)
25/11/18 06:05:30 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4489 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:05:30 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/11/18 06:05:30 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 4.801 s
25/11/18 06:05:30 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:05:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/11/18 06:05:30 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 4.926621 s
25/11/18 06:05:30 INFO CodeGenerator: Code generated in 21.118727 ms
25/11/18 06:05:30 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:05:30 INFO FileSourceStrategy: Post-Scan Filters: 
25/11/18 06:05:30 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:05:30 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 338.3 KiB, free 365.6 MiB)
25/11/18 06:05:30 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.6 MiB)
25/11/18 06:05:30 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 6b05748f7bac:37317 (size: 32.4 KiB, free: 366.2 MiB)
25/11/18 06:05:30 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:05:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:05:30 INFO InMemoryFileIndex: It took 5 ms to list leaf files for 1 paths.
25/11/18 06:05:30 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
25/11/18 06:05:30 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:05:30 INFO FileSourceStrategy: Post-Scan Filters: 
25/11/18 06:05:30 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:05:30 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 338.1 KiB, free 365.2 MiB)
25/11/18 06:05:30 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.2 MiB)
25/11/18 06:05:30 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 6b05748f7bac:37317 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:05:30 INFO SparkContext: Created broadcast 3 from json at NativeMethodAccessorImpl.java:0
25/11/18 06:05:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:05:30 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
25/11/18 06:05:30 INFO DAGScheduler: Got job 1 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:05:30 INFO DAGScheduler: Final stage: ResultStage 1 (json at NativeMethodAccessorImpl.java:0)
25/11/18 06:05:30 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:05:30 INFO DAGScheduler: Missing parents: List()
25/11/18 06:05:30 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:05:30 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 12.4 KiB, free 365.2 MiB)
25/11/18 06:05:30 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 365.2 MiB)
25/11/18 06:05:30 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 6b05748f7bac:37317 (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:05:30 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/11/18 06:05:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:05:30 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/11/18 06:05:30 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:05:30 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.0.6:34523 (size: 6.5 KiB, free: 366.3 MiB)
25/11/18 06:05:30 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.0.6:34523 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:05:31 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 298 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:05:31 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/11/18 06:05:31 INFO DAGScheduler: ResultStage 1 (json at NativeMethodAccessorImpl.java:0) finished in 0.340 s
25/11/18 06:05:31 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:05:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/11/18 06:05:31 INFO DAGScheduler: Job 1 finished: json at NativeMethodAccessorImpl.java:0, took 0.351626 s
25/11/18 06:05:32 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/11/18 06:05:32 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/11/18 06:05:32 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/11/18 06:05:32 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:05:32 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:05:32 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:05:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:05:32 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:05:32 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
25/11/18 06:05:32 INFO CodeGenerator: Code generated in 33.603876 ms
25/11/18 06:05:32 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 338.2 KiB, free 364.8 MiB)
25/11/18 06:05:32 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 364.8 MiB)
25/11/18 06:05:32 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 6b05748f7bac:37317 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:05:32 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:05:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:05:32 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:05:32 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/11/18 06:05:32 INFO DAGScheduler: Final stage: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/11/18 06:05:32 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:05:32 INFO DAGScheduler: Missing parents: List()
25/11/18 06:05:32 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/11/18 06:05:32 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 14.4 KiB, free 364.8 MiB)
25/11/18 06:05:32 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 364.8 MiB)
25/11/18 06:05:32 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 6b05748f7bac:37317 (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:05:32 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/11/18 06:05:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/11/18 06:05:32 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/11/18 06:05:32 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:05:32 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.20.0.6:34523 (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:05:32 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.20.0.6:34523 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:05:33 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 371 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:05:33 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/11/18 06:05:33 INFO DAGScheduler: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.399 s
25/11/18 06:05:33 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:05:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/11/18 06:05:33 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.407640 s
25/11/18 06:05:33 INFO CodeGenerator: Code generated in 14.25887 ms
25/11/18 06:05:33 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 1025.0 KiB, free 363.8 MiB)
25/11/18 06:05:33 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 250.0 B, free 363.8 MiB)
25/11/18 06:05:33 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 6b05748f7bac:37317 in memory (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:05:33 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 6b05748f7bac:37317 (size: 250.0 B, free: 366.2 MiB)
25/11/18 06:05:33 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:05:33 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.20.0.6:34523 in memory (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:05:33 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:05:33 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:05:33 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:05:33 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 6b05748f7bac:37317 in memory (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:05:33 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.20.0.6:34523 in memory (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:05:33 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 6b05748f7bac:37317 in memory (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:05:33 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.20.0.6:34523 in memory (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:05:33 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 6b05748f7bac:37317 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/11/18 06:05:33 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.0.6:34523 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/11/18 06:05:33 INFO CodeGenerator: Code generated in 38.331154 ms
25/11/18 06:05:33 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 338.0 KiB, free 363.9 MiB)
25/11/18 06:05:33 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 363.9 MiB)
25/11/18 06:05:33 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 6b05748f7bac:37317 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:05:33 INFO SparkContext: Created broadcast 8 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:05:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:05:33 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/11/18 06:05:33 INFO DAGScheduler: Got job 3 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:05:33 INFO DAGScheduler: Final stage: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0)
25/11/18 06:05:33 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:05:33 INFO DAGScheduler: Missing parents: List()
25/11/18 06:05:33 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:05:33 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 211.3 KiB, free 363.6 MiB)
25/11/18 06:05:33 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 75.9 KiB, free 363.6 MiB)
25/11/18 06:05:33 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 6b05748f7bac:37317 (size: 75.9 KiB, free: 366.1 MiB)
25/11/18 06:05:33 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/11/18 06:05:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:05:33 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/11/18 06:05:33 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:05:33 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.20.0.6:34523 (size: 75.9 KiB, free: 366.2 MiB)
25/11/18 06:05:33 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.20.0.6:34523 (size: 250.0 B, free: 366.2 MiB)
25/11/18 06:05:34 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.20.0.6:34523 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:05:34 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 756 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:05:34 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/11/18 06:05:34 INFO DAGScheduler: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0) finished in 0.808 s
25/11/18 06:05:34 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:05:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/11/18 06:05:34 INFO DAGScheduler: Job 3 finished: csv at NativeMethodAccessorImpl.java:0, took 0.818968 s
25/11/18 06:05:34 INFO FileFormatWriter: Start to commit write Job 2f663e07-f333-46b1-8de8-70d658983c37.
25/11/18 06:05:34 INFO FileFormatWriter: Write Job 2f663e07-f333-46b1-8de8-70d658983c37 committed. Elapsed time: 129 ms.
25/11/18 06:05:34 INFO FileFormatWriter: Finished processing stats for write job 2f663e07-f333-46b1-8de8-70d658983c37.
25/11/18 06:05:34 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/11/18 06:05:34 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/11/18 06:05:34 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/11/18 06:05:34 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:05:34 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:05:34 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:05:34 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:05:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:05:34 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:05:34 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:05:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:05:34 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:05:34 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:05:34 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 338.2 KiB, free 363.2 MiB)
25/11/18 06:05:34 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 363.2 MiB)
25/11/18 06:05:34 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 6b05748f7bac:37317 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:05:34 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:05:34 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:05:34 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:05:34 INFO DAGScheduler: Got job 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/11/18 06:05:34 INFO DAGScheduler: Final stage: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/11/18 06:05:34 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:05:34 INFO DAGScheduler: Missing parents: List()
25/11/18 06:05:34 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/11/18 06:05:34 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 14.4 KiB, free 363.2 MiB)
25/11/18 06:05:34 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 363.2 MiB)
25/11/18 06:05:34 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 6b05748f7bac:37317 (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:05:34 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/11/18 06:05:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/11/18 06:05:34 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/11/18 06:05:34 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:05:34 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.20.0.6:34523 (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:05:35 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.20.0.6:34523 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:05:35 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 151 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:05:35 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/11/18 06:05:35 INFO DAGScheduler: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.177 s
25/11/18 06:05:35 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:05:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/11/18 06:05:35 INFO DAGScheduler: Job 4 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.185417 s
25/11/18 06:05:35 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 1025.0 KiB, free 362.2 MiB)
25/11/18 06:05:35 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 250.0 B, free 362.2 MiB)
25/11/18 06:05:35 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 6b05748f7bac:37317 (size: 250.0 B, free: 366.1 MiB)
25/11/18 06:05:35 INFO SparkContext: Created broadcast 12 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:05:35 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:05:35 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:05:35 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:05:35 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 338.0 KiB, free 361.9 MiB)
25/11/18 06:05:35 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 361.8 MiB)
25/11/18 06:05:35 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 6b05748f7bac:37317 (size: 32.5 KiB, free: 366.0 MiB)
25/11/18 06:05:35 INFO SparkContext: Created broadcast 13 from parquet at NativeMethodAccessorImpl.java:0
25/11/18 06:05:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:05:35 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
25/11/18 06:05:35 INFO DAGScheduler: Got job 5 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:05:35 INFO DAGScheduler: Final stage: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0)
25/11/18 06:05:35 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:05:35 INFO DAGScheduler: Missing parents: List()
25/11/18 06:05:35 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:05:35 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 211.3 KiB, free 361.6 MiB)
25/11/18 06:05:35 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 76.0 KiB, free 361.5 MiB)
25/11/18 06:05:35 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 6b05748f7bac:37317 (size: 76.0 KiB, free: 366.0 MiB)
25/11/18 06:05:35 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/11/18 06:05:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:05:35 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/11/18 06:05:35 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:05:35 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.20.0.6:34523 (size: 76.0 KiB, free: 366.0 MiB)
25/11/18 06:05:35 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.20.0.6:34523 (size: 250.0 B, free: 366.0 MiB)
25/11/18 06:05:36 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.20.0.6:34523 (size: 32.5 KiB, free: 366.0 MiB)
25/11/18 06:05:36 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 1528 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:05:36 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/11/18 06:05:36 INFO DAGScheduler: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0) finished in 1.567 s
25/11/18 06:05:36 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:05:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/11/18 06:05:36 INFO DAGScheduler: Job 5 finished: parquet at NativeMethodAccessorImpl.java:0, took 1.571493 s
25/11/18 06:05:36 INFO FileFormatWriter: Start to commit write Job 12452628-60f3-426b-b21f-2e1570b2f402.
25/11/18 06:05:36 INFO FileFormatWriter: Write Job 12452628-60f3-426b-b21f-2e1570b2f402 committed. Elapsed time: 43 ms.
25/11/18 06:05:36 INFO FileFormatWriter: Finished processing stats for write job 12452628-60f3-426b-b21f-2e1570b2f402.
Job completed for 2025-01-01
25/11/18 06:05:36 INFO SparkUI: Stopped Spark web UI at http://6b05748f7bac:4040
25/11/18 06:05:36 INFO StandaloneSchedulerBackend: Shutting down all executors
25/11/18 06:05:36 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/11/18 06:05:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/11/18 06:05:36 INFO MemoryStore: MemoryStore cleared
25/11/18 06:05:36 INFO BlockManager: BlockManager stopped
25/11/18 06:05:36 INFO BlockManagerMaster: BlockManagerMaster stopped
25/11/18 06:05:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/11/18 06:05:37 INFO SparkContext: Successfully stopped SparkContext
25/11/18 06:05:37 INFO ShutdownHookManager: Shutdown hook called
25/11/18 06:05:37 INFO ShutdownHookManager: Deleting directory /tmp/spark-2ba90c0e-0b56-46de-bb88-8bf9fea8496c
25/11/18 06:05:37 INFO ShutdownHookManager: Deleting directory /tmp/spark-2d9034dc-e4c7-4ae8-9b78-88c14dfefb3c
25/11/18 06:05:37 INFO ShutdownHookManager: Deleting directory /tmp/spark-2d9034dc-e4c7-4ae8-9b78-88c14dfefb3c/pyspark-108e70cf-d5da-4242-9280-c0e802698ba3
Job completed for 2025-01-01
/mnt/c/pyspark_stack/spark-apps/cron/run_sales.sh: 1: ---: not found
Triggering sales_etl_job.py for 2025-01-01...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/11/18 06:06:08 INFO SparkContext: Running Spark version 3.2.1
25/11/18 06:06:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/11/18 06:06:08 INFO ResourceUtils: ==============================================================
25/11/18 06:06:08 INFO ResourceUtils: No custom resources configured for spark.driver.
25/11/18 06:06:08 INFO ResourceUtils: ==============================================================
25/11/18 06:06:08 INFO SparkContext: Submitted application: SalesETLJob
25/11/18 06:06:08 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/11/18 06:06:08 INFO ResourceProfile: Limiting resource is cpu
25/11/18 06:06:08 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/11/18 06:06:09 INFO SecurityManager: Changing view acls to: spark
25/11/18 06:06:09 INFO SecurityManager: Changing modify acls to: spark
25/11/18 06:06:09 INFO SecurityManager: Changing view acls groups to: 
25/11/18 06:06:09 INFO SecurityManager: Changing modify acls groups to: 
25/11/18 06:06:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
25/11/18 06:06:09 INFO Utils: Successfully started service 'sparkDriver' on port 36013.
25/11/18 06:06:09 INFO SparkEnv: Registering MapOutputTracker
25/11/18 06:06:09 INFO SparkEnv: Registering BlockManagerMaster
25/11/18 06:06:09 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/11/18 06:06:09 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/11/18 06:06:09 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/11/18 06:06:09 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d0593d51-0630-41b3-b08a-3d68c2b79d7e
25/11/18 06:06:09 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/11/18 06:06:09 INFO SparkEnv: Registering OutputCommitCoordinator
25/11/18 06:06:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/11/18 06:06:10 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://6b05748f7bac:4040
25/11/18 06:06:10 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/11/18 06:06:10 INFO TransportClientFactory: Successfully created connection to spark-master/172.20.0.3:7077 after 61 ms (0 ms spent in bootstraps)
25/11/18 06:06:11 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20251118060611-0006
25/11/18 06:06:11 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251118060611-0006/0 on worker-20251118055626-172.20.0.6-38023 (172.20.0.6:38023) with 12 core(s)
25/11/18 06:06:11 INFO StandaloneSchedulerBackend: Granted executor ID app-20251118060611-0006/0 on hostPort 172.20.0.6:38023 with 12 core(s), 1024.0 MiB RAM
25/11/18 06:06:11 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34497.
25/11/18 06:06:11 INFO NettyBlockTransferService: Server created on 6b05748f7bac:34497
25/11/18 06:06:11 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/11/18 06:06:11 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 6b05748f7bac, 34497, None)
25/11/18 06:06:11 INFO BlockManagerMasterEndpoint: Registering block manager 6b05748f7bac:34497 with 366.3 MiB RAM, BlockManagerId(driver, 6b05748f7bac, 34497, None)
25/11/18 06:06:11 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 6b05748f7bac, 34497, None)
25/11/18 06:06:11 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 6b05748f7bac, 34497, None)
25/11/18 06:06:11 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251118060611-0006/0 is now RUNNING
25/11/18 06:06:11 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/11/18 06:06:12 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/11/18 06:06:12 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
25/11/18 06:06:15 INFO InMemoryFileIndex: It took 153 ms to list leaf files for 1 paths.
25/11/18 06:06:15 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.6:50054) with ID 0,  ResourceProfileId 0
25/11/18 06:06:15 INFO InMemoryFileIndex: It took 31 ms to list leaf files for 1 paths.
25/11/18 06:06:15 INFO BlockManagerMasterEndpoint: Registering block manager 172.20.0.6:39485 with 366.3 MiB RAM, BlockManagerId(0, 172.20.0.6, 39485, None)
25/11/18 06:06:23 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:06:23 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/11/18 06:06:23 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:06:24 INFO CodeGenerator: Code generated in 300.513331 ms
25/11/18 06:06:24 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 338.3 KiB, free 366.0 MiB)
25/11/18 06:06:24 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.9 MiB)
25/11/18 06:06:24 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 6b05748f7bac:34497 (size: 32.4 KiB, free: 366.3 MiB)
25/11/18 06:06:24 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:06:24 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:06:24 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/11/18 06:06:25 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:06:25 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/11/18 06:06:25 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:06:25 INFO DAGScheduler: Missing parents: List()
25/11/18 06:06:25 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:06:25 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/11/18 06:06:25 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/11/18 06:06:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 6b05748f7bac:34497 (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:06:25 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/11/18 06:06:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:06:25 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/11/18 06:06:25 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:06:26 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.0.6:39485 (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:06:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.0.6:39485 (size: 32.4 KiB, free: 366.3 MiB)
25/11/18 06:06:29 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4468 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:06:29 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/11/18 06:06:29 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 4.707 s
25/11/18 06:06:29 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:06:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/11/18 06:06:29 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 4.789248 s
25/11/18 06:06:29 INFO CodeGenerator: Code generated in 20.918632 ms
25/11/18 06:06:29 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:06:29 INFO FileSourceStrategy: Post-Scan Filters: 
25/11/18 06:06:29 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:06:29 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 338.3 KiB, free 365.6 MiB)
25/11/18 06:06:29 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.6 MiB)
25/11/18 06:06:29 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 6b05748f7bac:34497 (size: 32.4 KiB, free: 366.2 MiB)
25/11/18 06:06:29 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:06:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:06:30 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
25/11/18 06:06:30 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
25/11/18 06:06:30 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:06:30 INFO FileSourceStrategy: Post-Scan Filters: 
25/11/18 06:06:30 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:06:30 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 338.1 KiB, free 365.2 MiB)
25/11/18 06:06:30 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.2 MiB)
25/11/18 06:06:30 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 6b05748f7bac:34497 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:06:30 INFO SparkContext: Created broadcast 3 from json at NativeMethodAccessorImpl.java:0
25/11/18 06:06:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:06:30 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
25/11/18 06:06:30 INFO DAGScheduler: Got job 1 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:06:30 INFO DAGScheduler: Final stage: ResultStage 1 (json at NativeMethodAccessorImpl.java:0)
25/11/18 06:06:30 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:06:30 INFO DAGScheduler: Missing parents: List()
25/11/18 06:06:30 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:06:30 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 12.4 KiB, free 365.2 MiB)
25/11/18 06:06:30 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 365.2 MiB)
25/11/18 06:06:30 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 6b05748f7bac:34497 (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:06:30 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/11/18 06:06:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:06:30 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/11/18 06:06:30 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:06:30 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.0.6:39485 (size: 6.5 KiB, free: 366.3 MiB)
25/11/18 06:06:30 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.0.6:39485 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:06:30 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 319 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:06:30 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/11/18 06:06:30 INFO DAGScheduler: ResultStage 1 (json at NativeMethodAccessorImpl.java:0) finished in 0.366 s
25/11/18 06:06:30 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:06:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/11/18 06:06:30 INFO DAGScheduler: Job 1 finished: json at NativeMethodAccessorImpl.java:0, took 0.381402 s
25/11/18 06:06:31 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/11/18 06:06:31 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/11/18 06:06:31 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/11/18 06:06:31 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:06:31 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:06:31 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:06:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:06:31 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:06:31 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
25/11/18 06:06:32 INFO CodeGenerator: Code generated in 40.699781 ms
25/11/18 06:06:32 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 338.2 KiB, free 364.8 MiB)
25/11/18 06:06:32 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 364.8 MiB)
25/11/18 06:06:32 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 6b05748f7bac:34497 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:06:32 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:06:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:06:32 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:06:32 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/11/18 06:06:32 INFO DAGScheduler: Final stage: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/11/18 06:06:32 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:06:32 INFO DAGScheduler: Missing parents: List()
25/11/18 06:06:32 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/11/18 06:06:32 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 14.4 KiB, free 364.8 MiB)
25/11/18 06:06:32 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 364.8 MiB)
25/11/18 06:06:32 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 6b05748f7bac:34497 (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:06:32 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/11/18 06:06:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/11/18 06:06:32 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/11/18 06:06:32 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:06:32 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 6b05748f7bac:34497 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/11/18 06:06:32 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.0.6:39485 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/11/18 06:06:32 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.20.0.6:39485 (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:06:32 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 6b05748f7bac:34497 in memory (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:06:32 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.20.0.6:39485 in memory (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:06:32 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 6b05748f7bac:34497 in memory (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:06:32 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.20.0.6:39485 in memory (size: 32.5 KiB, free: 366.3 MiB)
25/11/18 06:06:32 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.20.0.6:39485 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:06:32 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 391 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:06:32 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/11/18 06:06:32 INFO DAGScheduler: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.423 s
25/11/18 06:06:32 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:06:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/11/18 06:06:32 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.436921 s
25/11/18 06:06:32 INFO CodeGenerator: Code generated in 23.608664 ms
25/11/18 06:06:32 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 1025.0 KiB, free 364.2 MiB)
25/11/18 06:06:32 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 250.0 B, free 364.2 MiB)
25/11/18 06:06:32 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 6b05748f7bac:34497 (size: 250.0 B, free: 366.2 MiB)
25/11/18 06:06:32 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:06:32 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:06:32 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:06:32 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:06:33 INFO CodeGenerator: Code generated in 93.302423 ms
25/11/18 06:06:33 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 338.0 KiB, free 363.9 MiB)
25/11/18 06:06:33 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 363.8 MiB)
25/11/18 06:06:33 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 6b05748f7bac:34497 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:06:33 INFO SparkContext: Created broadcast 8 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:06:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:06:33 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/11/18 06:06:33 INFO DAGScheduler: Got job 3 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:06:33 INFO DAGScheduler: Final stage: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0)
25/11/18 06:06:33 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:06:33 INFO DAGScheduler: Missing parents: List()
25/11/18 06:06:33 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:06:33 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 211.3 KiB, free 363.6 MiB)
25/11/18 06:06:33 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 75.9 KiB, free 363.5 MiB)
25/11/18 06:06:33 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 6b05748f7bac:34497 (size: 75.9 KiB, free: 366.1 MiB)
25/11/18 06:06:33 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/11/18 06:06:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:06:33 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/11/18 06:06:33 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:06:33 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.20.0.6:39485 (size: 75.9 KiB, free: 366.2 MiB)
25/11/18 06:06:33 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.20.0.6:39485 (size: 250.0 B, free: 366.2 MiB)
25/11/18 06:06:33 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.20.0.6:39485 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:06:33 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 741 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:06:33 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/11/18 06:06:33 INFO DAGScheduler: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0) finished in 0.794 s
25/11/18 06:06:33 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:06:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/11/18 06:06:33 INFO DAGScheduler: Job 3 finished: csv at NativeMethodAccessorImpl.java:0, took 0.805717 s
25/11/18 06:06:33 INFO FileFormatWriter: Start to commit write Job 3105bfc3-d258-47c2-ae37-20a67f72c536.
25/11/18 06:06:34 INFO FileFormatWriter: Write Job 3105bfc3-d258-47c2-ae37-20a67f72c536 committed. Elapsed time: 114 ms.
25/11/18 06:06:34 INFO FileFormatWriter: Finished processing stats for write job 3105bfc3-d258-47c2-ae37-20a67f72c536.
25/11/18 06:06:34 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/11/18 06:06:34 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/11/18 06:06:34 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/11/18 06:06:34 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:06:34 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:06:34 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:06:34 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:06:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:06:34 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:06:34 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:06:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:06:34 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:06:34 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:06:34 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 338.2 KiB, free 363.2 MiB)
25/11/18 06:06:34 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 363.2 MiB)
25/11/18 06:06:34 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 6b05748f7bac:34497 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:06:34 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:06:34 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:06:34 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:06:34 INFO DAGScheduler: Got job 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/11/18 06:06:34 INFO DAGScheduler: Final stage: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/11/18 06:06:34 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:06:34 INFO DAGScheduler: Missing parents: List()
25/11/18 06:06:34 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/11/18 06:06:34 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 14.4 KiB, free 363.2 MiB)
25/11/18 06:06:34 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 363.2 MiB)
25/11/18 06:06:34 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 6b05748f7bac:34497 (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:06:34 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/11/18 06:06:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/11/18 06:06:34 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/11/18 06:06:34 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:06:34 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.20.0.6:39485 (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:06:34 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.20.0.6:39485 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:06:34 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 159 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:06:34 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/11/18 06:06:34 INFO DAGScheduler: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.178 s
25/11/18 06:06:34 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:06:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/11/18 06:06:34 INFO DAGScheduler: Job 4 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.190603 s
25/11/18 06:06:34 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 1025.0 KiB, free 362.2 MiB)
25/11/18 06:06:34 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 250.0 B, free 362.2 MiB)
25/11/18 06:06:34 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 6b05748f7bac:34497 (size: 250.0 B, free: 366.1 MiB)
25/11/18 06:06:34 INFO SparkContext: Created broadcast 12 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:06:34 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:06:34 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:06:34 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:06:34 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 338.0 KiB, free 361.8 MiB)
25/11/18 06:06:34 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 361.8 MiB)
25/11/18 06:06:34 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 6b05748f7bac:34497 (size: 32.5 KiB, free: 366.0 MiB)
25/11/18 06:06:34 INFO SparkContext: Created broadcast 13 from parquet at NativeMethodAccessorImpl.java:0
25/11/18 06:06:34 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:06:34 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
25/11/18 06:06:34 INFO DAGScheduler: Got job 5 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:06:34 INFO DAGScheduler: Final stage: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0)
25/11/18 06:06:34 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:06:34 INFO DAGScheduler: Missing parents: List()
25/11/18 06:06:34 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:06:34 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 211.3 KiB, free 361.6 MiB)
25/11/18 06:06:34 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 76.0 KiB, free 361.5 MiB)
25/11/18 06:06:34 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 6b05748f7bac:34497 (size: 76.0 KiB, free: 365.9 MiB)
25/11/18 06:06:34 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/11/18 06:06:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:06:34 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/11/18 06:06:34 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:06:34 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.20.0.6:39485 (size: 76.0 KiB, free: 366.0 MiB)
25/11/18 06:06:34 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.20.0.6:39485 (size: 250.0 B, free: 366.0 MiB)
25/11/18 06:06:35 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.20.0.6:39485 (size: 32.5 KiB, free: 366.0 MiB)
25/11/18 06:06:36 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 1740 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:06:36 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/11/18 06:06:36 INFO DAGScheduler: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0) finished in 1.777 s
25/11/18 06:06:36 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:06:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/11/18 06:06:36 INFO DAGScheduler: Job 5 finished: parquet at NativeMethodAccessorImpl.java:0, took 1.782518 s
25/11/18 06:06:36 INFO FileFormatWriter: Start to commit write Job 5dd85542-24a8-4157-8320-821f9ad43b09.
25/11/18 06:06:36 INFO FileFormatWriter: Write Job 5dd85542-24a8-4157-8320-821f9ad43b09 committed. Elapsed time: 61 ms.
25/11/18 06:06:36 INFO FileFormatWriter: Finished processing stats for write job 5dd85542-24a8-4157-8320-821f9ad43b09.
Job completed for 2025-01-01
25/11/18 06:06:36 INFO SparkUI: Stopped Spark web UI at http://6b05748f7bac:4040
25/11/18 06:06:36 INFO StandaloneSchedulerBackend: Shutting down all executors
25/11/18 06:06:36 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/11/18 06:06:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/11/18 06:06:36 INFO MemoryStore: MemoryStore cleared
25/11/18 06:06:36 INFO BlockManager: BlockManager stopped
25/11/18 06:06:36 INFO BlockManagerMaster: BlockManagerMaster stopped
25/11/18 06:06:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/11/18 06:06:36 INFO SparkContext: Successfully stopped SparkContext
25/11/18 06:06:36 INFO ShutdownHookManager: Shutdown hook called
25/11/18 06:06:36 INFO ShutdownHookManager: Deleting directory /tmp/spark-17f85016-bb5a-453c-89a9-838e2a0ddc76
25/11/18 06:06:36 INFO ShutdownHookManager: Deleting directory /tmp/spark-2c8a0aba-2aa6-41a7-a868-b71fc742fad4
25/11/18 06:06:36 INFO ShutdownHookManager: Deleting directory /tmp/spark-17f85016-bb5a-453c-89a9-838e2a0ddc76/pyspark-d7a61913-6357-44dd-ba2e-b49da58c0784
Job completed for 2025-01-01
/mnt/c/pyspark_stack/spark-apps/cron/run_sales.sh: 1: ---: not found
Triggering sales_etl_job.py for 2025-01-01...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/11/18 06:07:08 INFO SparkContext: Running Spark version 3.2.1
25/11/18 06:07:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/11/18 06:07:08 INFO ResourceUtils: ==============================================================
25/11/18 06:07:08 INFO ResourceUtils: No custom resources configured for spark.driver.
25/11/18 06:07:08 INFO ResourceUtils: ==============================================================
25/11/18 06:07:08 INFO SparkContext: Submitted application: SalesETLJob
25/11/18 06:07:08 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/11/18 06:07:08 INFO ResourceProfile: Limiting resource is cpu
25/11/18 06:07:08 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/11/18 06:07:08 INFO SecurityManager: Changing view acls to: spark
25/11/18 06:07:08 INFO SecurityManager: Changing modify acls to: spark
25/11/18 06:07:08 INFO SecurityManager: Changing view acls groups to: 
25/11/18 06:07:08 INFO SecurityManager: Changing modify acls groups to: 
25/11/18 06:07:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
25/11/18 06:07:09 INFO Utils: Successfully started service 'sparkDriver' on port 33607.
25/11/18 06:07:09 INFO SparkEnv: Registering MapOutputTracker
25/11/18 06:07:09 INFO SparkEnv: Registering BlockManagerMaster
25/11/18 06:07:09 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/11/18 06:07:09 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/11/18 06:07:09 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/11/18 06:07:09 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-8e40ec7a-f36b-42fc-a176-d42684b09028
25/11/18 06:07:09 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/11/18 06:07:09 INFO SparkEnv: Registering OutputCommitCoordinator
25/11/18 06:07:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/11/18 06:07:10 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://6b05748f7bac:4040
25/11/18 06:07:10 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/11/18 06:07:10 INFO TransportClientFactory: Successfully created connection to spark-master/172.20.0.3:7077 after 60 ms (0 ms spent in bootstraps)
25/11/18 06:07:10 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20251118060710-0007
25/11/18 06:07:11 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251118060710-0007/0 on worker-20251118055626-172.20.0.6-38023 (172.20.0.6:38023) with 12 core(s)
25/11/18 06:07:11 INFO StandaloneSchedulerBackend: Granted executor ID app-20251118060710-0007/0 on hostPort 172.20.0.6:38023 with 12 core(s), 1024.0 MiB RAM
25/11/18 06:07:11 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34143.
25/11/18 06:07:11 INFO NettyBlockTransferService: Server created on 6b05748f7bac:34143
25/11/18 06:07:11 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/11/18 06:07:11 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 6b05748f7bac, 34143, None)
25/11/18 06:07:11 INFO BlockManagerMasterEndpoint: Registering block manager 6b05748f7bac:34143 with 366.3 MiB RAM, BlockManagerId(driver, 6b05748f7bac, 34143, None)
25/11/18 06:07:11 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 6b05748f7bac, 34143, None)
25/11/18 06:07:11 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 6b05748f7bac, 34143, None)
25/11/18 06:07:11 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251118060710-0007/0 is now RUNNING
25/11/18 06:07:11 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/11/18 06:07:12 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/11/18 06:07:12 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
25/11/18 06:07:15 INFO InMemoryFileIndex: It took 174 ms to list leaf files for 1 paths.
25/11/18 06:07:15 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.6:35526) with ID 0,  ResourceProfileId 0
25/11/18 06:07:15 INFO InMemoryFileIndex: It took 14 ms to list leaf files for 1 paths.
25/11/18 06:07:15 INFO BlockManagerMasterEndpoint: Registering block manager 172.20.0.6:36787 with 366.3 MiB RAM, BlockManagerId(0, 172.20.0.6, 36787, None)
25/11/18 06:07:20 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:07:20 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/11/18 06:07:20 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:07:21 INFO CodeGenerator: Code generated in 312.347614 ms
25/11/18 06:07:21 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 338.3 KiB, free 366.0 MiB)
25/11/18 06:07:21 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.9 MiB)
25/11/18 06:07:21 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 6b05748f7bac:34143 (size: 32.4 KiB, free: 366.3 MiB)
25/11/18 06:07:21 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:07:21 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:07:24 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/11/18 06:07:24 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:07:24 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/11/18 06:07:24 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:07:24 INFO DAGScheduler: Missing parents: List()
25/11/18 06:07:24 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:07:25 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/11/18 06:07:25 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/11/18 06:07:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 6b05748f7bac:34143 (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:07:25 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/11/18 06:07:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:07:25 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/11/18 06:07:25 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:07:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.0.6:36787 (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:07:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.0.6:36787 (size: 32.4 KiB, free: 366.3 MiB)
25/11/18 06:07:30 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4887 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:07:30 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/11/18 06:07:30 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 5.073 s
25/11/18 06:07:30 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:07:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/11/18 06:07:30 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 5.157138 s
25/11/18 06:07:30 INFO CodeGenerator: Code generated in 19.147173 ms
25/11/18 06:07:30 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:07:30 INFO FileSourceStrategy: Post-Scan Filters: 
25/11/18 06:07:30 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:07:30 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 338.3 KiB, free 365.6 MiB)
25/11/18 06:07:30 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.6 MiB)
25/11/18 06:07:30 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 6b05748f7bac:34143 (size: 32.4 KiB, free: 366.2 MiB)
25/11/18 06:07:30 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:07:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:07:30 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
25/11/18 06:07:30 INFO InMemoryFileIndex: It took 9 ms to list leaf files for 1 paths.
25/11/18 06:07:30 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:07:30 INFO FileSourceStrategy: Post-Scan Filters: 
25/11/18 06:07:30 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:07:30 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 338.1 KiB, free 365.2 MiB)
25/11/18 06:07:30 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.2 MiB)
25/11/18 06:07:30 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 6b05748f7bac:34143 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:07:30 INFO SparkContext: Created broadcast 3 from json at NativeMethodAccessorImpl.java:0
25/11/18 06:07:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:07:30 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
25/11/18 06:07:30 INFO DAGScheduler: Got job 1 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:07:30 INFO DAGScheduler: Final stage: ResultStage 1 (json at NativeMethodAccessorImpl.java:0)
25/11/18 06:07:30 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:07:30 INFO DAGScheduler: Missing parents: List()
25/11/18 06:07:30 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:07:30 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 12.4 KiB, free 365.2 MiB)
25/11/18 06:07:30 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 365.2 MiB)
25/11/18 06:07:30 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 6b05748f7bac:34143 (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:07:30 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/11/18 06:07:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:07:30 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/11/18 06:07:30 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:07:30 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.0.6:36787 (size: 6.5 KiB, free: 366.3 MiB)
25/11/18 06:07:30 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.0.6:36787 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:07:31 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 298 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:07:31 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/11/18 06:07:31 INFO DAGScheduler: ResultStage 1 (json at NativeMethodAccessorImpl.java:0) finished in 0.352 s
25/11/18 06:07:31 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:07:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/11/18 06:07:31 INFO DAGScheduler: Job 1 finished: json at NativeMethodAccessorImpl.java:0, took 0.363929 s
25/11/18 06:07:31 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/11/18 06:07:31 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/11/18 06:07:31 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/11/18 06:07:31 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:07:31 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:07:31 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:07:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:07:32 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:07:32 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
25/11/18 06:07:32 INFO CodeGenerator: Code generated in 37.588461 ms
25/11/18 06:07:32 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 338.2 KiB, free 364.8 MiB)
25/11/18 06:07:32 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 364.8 MiB)
25/11/18 06:07:32 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 6b05748f7bac:34143 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:07:32 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:07:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:07:32 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:07:32 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/11/18 06:07:32 INFO DAGScheduler: Final stage: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/11/18 06:07:32 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:07:32 INFO DAGScheduler: Missing parents: List()
25/11/18 06:07:32 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/11/18 06:07:32 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 14.4 KiB, free 364.8 MiB)
25/11/18 06:07:32 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 364.8 MiB)
25/11/18 06:07:32 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 6b05748f7bac:34143 (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:07:32 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/11/18 06:07:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/11/18 06:07:32 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/11/18 06:07:32 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:07:32 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.20.0.6:36787 (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:07:32 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.20.0.6:36787 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:07:33 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 415 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:07:33 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/11/18 06:07:33 INFO DAGScheduler: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.450 s
25/11/18 06:07:33 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:07:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/11/18 06:07:33 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.458425 s
25/11/18 06:07:33 INFO CodeGenerator: Code generated in 26.682465 ms
25/11/18 06:07:33 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 1025.0 KiB, free 363.8 MiB)
25/11/18 06:07:33 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 250.0 B, free 363.8 MiB)
25/11/18 06:07:33 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 6b05748f7bac:34143 (size: 250.0 B, free: 366.2 MiB)
25/11/18 06:07:33 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:07:33 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:07:33 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:07:33 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:07:33 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 6b05748f7bac:34143 in memory (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:07:33 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.20.0.6:36787 in memory (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:07:33 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 6b05748f7bac:34143 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/11/18 06:07:33 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.0.6:36787 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/11/18 06:07:33 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 6b05748f7bac:34143 in memory (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:07:33 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.20.0.6:36787 in memory (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:07:33 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 6b05748f7bac:34143 in memory (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:07:33 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.20.0.6:36787 in memory (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:07:33 INFO CodeGenerator: Code generated in 41.976711 ms
25/11/18 06:07:33 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 338.0 KiB, free 363.9 MiB)
25/11/18 06:07:33 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 363.9 MiB)
25/11/18 06:07:33 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 6b05748f7bac:34143 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:07:33 INFO SparkContext: Created broadcast 8 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:07:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:07:33 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/11/18 06:07:33 INFO DAGScheduler: Got job 3 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:07:33 INFO DAGScheduler: Final stage: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0)
25/11/18 06:07:33 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:07:33 INFO DAGScheduler: Missing parents: List()
25/11/18 06:07:33 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:07:33 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 211.3 KiB, free 363.6 MiB)
25/11/18 06:07:33 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 75.9 KiB, free 363.6 MiB)
25/11/18 06:07:33 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 6b05748f7bac:34143 (size: 75.9 KiB, free: 366.1 MiB)
25/11/18 06:07:33 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/11/18 06:07:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:07:33 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/11/18 06:07:33 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:07:33 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.20.0.6:36787 (size: 75.9 KiB, free: 366.2 MiB)
25/11/18 06:07:33 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.20.0.6:36787 (size: 250.0 B, free: 366.2 MiB)
25/11/18 06:07:34 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.20.0.6:36787 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:07:34 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 863 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:07:34 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/11/18 06:07:34 INFO DAGScheduler: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0) finished in 0.931 s
25/11/18 06:07:34 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:07:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/11/18 06:07:34 INFO DAGScheduler: Job 3 finished: csv at NativeMethodAccessorImpl.java:0, took 0.942249 s
25/11/18 06:07:34 INFO FileFormatWriter: Start to commit write Job 26dcb0ec-abcf-47f5-8d25-d877b5fa138b.
25/11/18 06:07:34 INFO FileFormatWriter: Write Job 26dcb0ec-abcf-47f5-8d25-d877b5fa138b committed. Elapsed time: 122 ms.
25/11/18 06:07:34 INFO FileFormatWriter: Finished processing stats for write job 26dcb0ec-abcf-47f5-8d25-d877b5fa138b.
25/11/18 06:07:34 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/11/18 06:07:34 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/11/18 06:07:34 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/11/18 06:07:34 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:07:34 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:07:34 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:07:34 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:07:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:07:34 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:07:34 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:07:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:07:34 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:07:34 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:07:34 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 338.2 KiB, free 363.2 MiB)
25/11/18 06:07:35 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 363.2 MiB)
25/11/18 06:07:35 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 6b05748f7bac:34143 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:07:35 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:07:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:07:35 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:07:35 INFO DAGScheduler: Got job 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/11/18 06:07:35 INFO DAGScheduler: Final stage: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/11/18 06:07:35 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:07:35 INFO DAGScheduler: Missing parents: List()
25/11/18 06:07:35 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/11/18 06:07:35 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 14.4 KiB, free 363.2 MiB)
25/11/18 06:07:35 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 363.2 MiB)
25/11/18 06:07:35 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 6b05748f7bac:34143 (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:07:35 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/11/18 06:07:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/11/18 06:07:35 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/11/18 06:07:35 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:07:35 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.20.0.6:36787 (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:07:35 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.20.0.6:36787 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:07:35 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 240 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:07:35 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/11/18 06:07:35 INFO DAGScheduler: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.264 s
25/11/18 06:07:35 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:07:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/11/18 06:07:35 INFO DAGScheduler: Job 4 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.293141 s
25/11/18 06:07:35 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 1025.0 KiB, free 362.2 MiB)
25/11/18 06:07:35 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 250.0 B, free 362.2 MiB)
25/11/18 06:07:35 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 6b05748f7bac:34143 (size: 250.0 B, free: 366.1 MiB)
25/11/18 06:07:35 INFO SparkContext: Created broadcast 12 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:07:35 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:07:35 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:07:35 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:07:35 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 338.0 KiB, free 361.9 MiB)
25/11/18 06:07:35 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 361.8 MiB)
25/11/18 06:07:35 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 6b05748f7bac:34143 (size: 32.5 KiB, free: 366.0 MiB)
25/11/18 06:07:35 INFO SparkContext: Created broadcast 13 from parquet at NativeMethodAccessorImpl.java:0
25/11/18 06:07:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:07:35 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
25/11/18 06:07:35 INFO DAGScheduler: Got job 5 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:07:35 INFO DAGScheduler: Final stage: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0)
25/11/18 06:07:35 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:07:35 INFO DAGScheduler: Missing parents: List()
25/11/18 06:07:35 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:07:35 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 211.3 KiB, free 361.6 MiB)
25/11/18 06:07:35 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 76.0 KiB, free 361.5 MiB)
25/11/18 06:07:35 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 6b05748f7bac:34143 (size: 76.0 KiB, free: 366.0 MiB)
25/11/18 06:07:35 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/11/18 06:07:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:07:35 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/11/18 06:07:35 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:07:35 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.20.0.6:36787 (size: 76.0 KiB, free: 366.0 MiB)
25/11/18 06:07:35 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.20.0.6:36787 (size: 250.0 B, free: 366.0 MiB)
25/11/18 06:07:36 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.20.0.6:36787 (size: 32.5 KiB, free: 366.0 MiB)
25/11/18 06:07:37 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 1769 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:07:37 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/11/18 06:07:37 INFO DAGScheduler: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0) finished in 1.846 s
25/11/18 06:07:37 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:07:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/11/18 06:07:37 INFO DAGScheduler: Job 5 finished: parquet at NativeMethodAccessorImpl.java:0, took 1.855835 s
25/11/18 06:07:37 INFO FileFormatWriter: Start to commit write Job 2be2cb68-30da-4dcf-9453-18b2936d4ece.
25/11/18 06:07:37 INFO FileFormatWriter: Write Job 2be2cb68-30da-4dcf-9453-18b2936d4ece committed. Elapsed time: 59 ms.
25/11/18 06:07:37 INFO FileFormatWriter: Finished processing stats for write job 2be2cb68-30da-4dcf-9453-18b2936d4ece.
Job completed for 2025-01-01
25/11/18 06:07:37 INFO SparkUI: Stopped Spark web UI at http://6b05748f7bac:4040
25/11/18 06:07:37 INFO StandaloneSchedulerBackend: Shutting down all executors
25/11/18 06:07:37 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/11/18 06:07:37 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/11/18 06:07:37 INFO MemoryStore: MemoryStore cleared
25/11/18 06:07:37 INFO BlockManager: BlockManager stopped
25/11/18 06:07:37 INFO BlockManagerMaster: BlockManagerMaster stopped
25/11/18 06:07:37 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/11/18 06:07:37 INFO SparkContext: Successfully stopped SparkContext
25/11/18 06:07:38 INFO ShutdownHookManager: Shutdown hook called
25/11/18 06:07:38 INFO ShutdownHookManager: Deleting directory /tmp/spark-524bb50a-9455-49d4-86cf-612d6c69d3ba
25/11/18 06:07:38 INFO ShutdownHookManager: Deleting directory /tmp/spark-d80124b8-6de5-4b3e-9593-0dfd7a0b824c
25/11/18 06:07:38 INFO ShutdownHookManager: Deleting directory /tmp/spark-524bb50a-9455-49d4-86cf-612d6c69d3ba/pyspark-9bdf167c-fade-4b6f-9108-24e0cff22f47
Job completed for 2025-01-01
/mnt/c/pyspark_stack/spark-apps/cron/run_sales.sh: 1: ---: not found
Triggering sales_etl_job.py for 2025-01-01...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/11/18 06:08:08 INFO SparkContext: Running Spark version 3.2.1
25/11/18 06:08:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/11/18 06:08:09 INFO ResourceUtils: ==============================================================
25/11/18 06:08:09 INFO ResourceUtils: No custom resources configured for spark.driver.
25/11/18 06:08:09 INFO ResourceUtils: ==============================================================
25/11/18 06:08:09 INFO SparkContext: Submitted application: SalesETLJob
25/11/18 06:08:09 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/11/18 06:08:09 INFO ResourceProfile: Limiting resource is cpu
25/11/18 06:08:09 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/11/18 06:08:09 INFO SecurityManager: Changing view acls to: spark
25/11/18 06:08:09 INFO SecurityManager: Changing modify acls to: spark
25/11/18 06:08:09 INFO SecurityManager: Changing view acls groups to: 
25/11/18 06:08:09 INFO SecurityManager: Changing modify acls groups to: 
25/11/18 06:08:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
25/11/18 06:08:09 INFO Utils: Successfully started service 'sparkDriver' on port 33077.
25/11/18 06:08:09 INFO SparkEnv: Registering MapOutputTracker
25/11/18 06:08:09 INFO SparkEnv: Registering BlockManagerMaster
25/11/18 06:08:09 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/11/18 06:08:09 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/11/18 06:08:09 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/11/18 06:08:09 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-05d1dc24-4624-4903-b6f5-59c2f2a87f45
25/11/18 06:08:09 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/11/18 06:08:10 INFO SparkEnv: Registering OutputCommitCoordinator
25/11/18 06:08:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/11/18 06:08:10 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://6b05748f7bac:4040
25/11/18 06:08:10 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/11/18 06:08:11 INFO TransportClientFactory: Successfully created connection to spark-master/172.20.0.3:7077 after 64 ms (0 ms spent in bootstraps)
25/11/18 06:08:11 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20251118060811-0008
25/11/18 06:08:11 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251118060811-0008/0 on worker-20251118055626-172.20.0.6-38023 (172.20.0.6:38023) with 12 core(s)
25/11/18 06:08:11 INFO StandaloneSchedulerBackend: Granted executor ID app-20251118060811-0008/0 on hostPort 172.20.0.6:38023 with 12 core(s), 1024.0 MiB RAM
25/11/18 06:08:11 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42465.
25/11/18 06:08:11 INFO NettyBlockTransferService: Server created on 6b05748f7bac:42465
25/11/18 06:08:11 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/11/18 06:08:11 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 6b05748f7bac, 42465, None)
25/11/18 06:08:11 INFO BlockManagerMasterEndpoint: Registering block manager 6b05748f7bac:42465 with 366.3 MiB RAM, BlockManagerId(driver, 6b05748f7bac, 42465, None)
25/11/18 06:08:11 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 6b05748f7bac, 42465, None)
25/11/18 06:08:11 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 6b05748f7bac, 42465, None)
25/11/18 06:08:11 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251118060811-0008/0 is now RUNNING
25/11/18 06:08:11 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/11/18 06:08:12 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/11/18 06:08:12 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
25/11/18 06:08:15 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.6:52760) with ID 0,  ResourceProfileId 0
25/11/18 06:08:16 INFO InMemoryFileIndex: It took 269 ms to list leaf files for 1 paths.
25/11/18 06:08:16 INFO InMemoryFileIndex: It took 15 ms to list leaf files for 1 paths.
25/11/18 06:08:16 INFO BlockManagerMasterEndpoint: Registering block manager 172.20.0.6:43487 with 366.3 MiB RAM, BlockManagerId(0, 172.20.0.6, 43487, None)
25/11/18 06:08:20 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:08:20 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/11/18 06:08:20 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:08:22 INFO CodeGenerator: Code generated in 315.498873 ms
25/11/18 06:08:22 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 338.3 KiB, free 366.0 MiB)
25/11/18 06:08:22 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.9 MiB)
25/11/18 06:08:22 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 6b05748f7bac:42465 (size: 32.4 KiB, free: 366.3 MiB)
25/11/18 06:08:22 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:08:22 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:08:22 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/11/18 06:08:22 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:08:22 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/11/18 06:08:22 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:08:22 INFO DAGScheduler: Missing parents: List()
25/11/18 06:08:22 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:08:22 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/11/18 06:08:22 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/11/18 06:08:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 6b05748f7bac:42465 (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:08:22 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/11/18 06:08:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:08:22 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/11/18 06:08:22 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:08:23 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.0.6:43487 (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:08:25 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.0.6:43487 (size: 32.4 KiB, free: 366.3 MiB)
25/11/18 06:08:26 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 3889 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:08:26 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/11/18 06:08:26 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 4.084 s
25/11/18 06:08:26 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:08:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/11/18 06:08:26 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 4.950119 s
25/11/18 06:08:30 INFO CodeGenerator: Code generated in 23.648162 ms
25/11/18 06:08:30 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:08:30 INFO FileSourceStrategy: Post-Scan Filters: 
25/11/18 06:08:30 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:08:30 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 338.3 KiB, free 365.6 MiB)
25/11/18 06:08:30 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.6 MiB)
25/11/18 06:08:30 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 6b05748f7bac:42465 (size: 32.4 KiB, free: 366.2 MiB)
25/11/18 06:08:30 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:08:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:08:30 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
25/11/18 06:08:30 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 1 paths.
25/11/18 06:08:30 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:08:30 INFO FileSourceStrategy: Post-Scan Filters: 
25/11/18 06:08:30 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:08:30 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 338.1 KiB, free 365.2 MiB)
25/11/18 06:08:30 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.2 MiB)
25/11/18 06:08:30 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 6b05748f7bac:42465 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:08:30 INFO SparkContext: Created broadcast 3 from json at NativeMethodAccessorImpl.java:0
25/11/18 06:08:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:08:30 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
25/11/18 06:08:30 INFO DAGScheduler: Got job 1 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:08:30 INFO DAGScheduler: Final stage: ResultStage 1 (json at NativeMethodAccessorImpl.java:0)
25/11/18 06:08:30 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:08:30 INFO DAGScheduler: Missing parents: List()
25/11/18 06:08:30 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:08:30 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 12.4 KiB, free 365.2 MiB)
25/11/18 06:08:30 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 365.2 MiB)
25/11/18 06:08:30 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 6b05748f7bac:42465 (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:08:30 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/11/18 06:08:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:08:30 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/11/18 06:08:30 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:08:30 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.0.6:43487 (size: 6.5 KiB, free: 366.3 MiB)
25/11/18 06:08:30 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.0.6:43487 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:08:31 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 280 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:08:31 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/11/18 06:08:31 INFO DAGScheduler: ResultStage 1 (json at NativeMethodAccessorImpl.java:0) finished in 0.330 s
25/11/18 06:08:31 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:08:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/11/18 06:08:31 INFO DAGScheduler: Job 1 finished: json at NativeMethodAccessorImpl.java:0, took 0.346719 s
25/11/18 06:08:31 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/11/18 06:08:31 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/11/18 06:08:31 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/11/18 06:08:31 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:08:31 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:08:31 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:08:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:08:32 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:08:32 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
25/11/18 06:08:32 INFO CodeGenerator: Code generated in 41.042711 ms
25/11/18 06:08:32 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 338.2 KiB, free 364.8 MiB)
25/11/18 06:08:32 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 364.8 MiB)
25/11/18 06:08:32 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 6b05748f7bac:42465 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:08:32 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:08:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:08:32 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:08:32 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/11/18 06:08:32 INFO DAGScheduler: Final stage: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/11/18 06:08:32 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:08:32 INFO DAGScheduler: Missing parents: List()
25/11/18 06:08:32 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/11/18 06:08:32 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 14.4 KiB, free 364.8 MiB)
25/11/18 06:08:32 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 364.8 MiB)
25/11/18 06:08:32 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 6b05748f7bac:42465 (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:08:32 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/11/18 06:08:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/11/18 06:08:32 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/11/18 06:08:32 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:08:32 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.20.0.6:43487 (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:08:32 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.20.0.6:43487 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:08:33 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 508 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:08:33 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/11/18 06:08:33 INFO DAGScheduler: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.564 s
25/11/18 06:08:33 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:08:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/11/18 06:08:33 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.574314 s
25/11/18 06:08:33 INFO CodeGenerator: Code generated in 20.028319 ms
25/11/18 06:08:33 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 1025.0 KiB, free 363.8 MiB)
25/11/18 06:08:33 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 250.0 B, free 363.8 MiB)
25/11/18 06:08:33 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 6b05748f7bac:42465 (size: 250.0 B, free: 366.2 MiB)
25/11/18 06:08:33 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:08:33 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:08:33 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:08:33 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:08:33 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 6b05748f7bac:42465 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/11/18 06:08:33 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.0.6:43487 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/11/18 06:08:33 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 6b05748f7bac:42465 in memory (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:08:33 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.20.0.6:43487 in memory (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:08:33 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 6b05748f7bac:42465 in memory (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:08:33 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.20.0.6:43487 in memory (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:08:33 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 6b05748f7bac:42465 in memory (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:08:33 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.20.0.6:43487 in memory (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:08:33 INFO CodeGenerator: Code generated in 42.393862 ms
25/11/18 06:08:33 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 338.0 KiB, free 363.9 MiB)
25/11/18 06:08:33 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 363.9 MiB)
25/11/18 06:08:33 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 6b05748f7bac:42465 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:08:33 INFO SparkContext: Created broadcast 8 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:08:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:08:33 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/11/18 06:08:33 INFO DAGScheduler: Got job 3 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:08:33 INFO DAGScheduler: Final stage: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0)
25/11/18 06:08:33 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:08:33 INFO DAGScheduler: Missing parents: List()
25/11/18 06:08:33 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:08:33 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 211.3 KiB, free 363.6 MiB)
25/11/18 06:08:33 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 75.9 KiB, free 363.6 MiB)
25/11/18 06:08:33 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 6b05748f7bac:42465 (size: 75.9 KiB, free: 366.1 MiB)
25/11/18 06:08:33 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/11/18 06:08:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:08:33 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/11/18 06:08:33 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:08:33 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.20.0.6:43487 (size: 75.9 KiB, free: 366.2 MiB)
25/11/18 06:08:33 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.20.0.6:43487 (size: 250.0 B, free: 366.2 MiB)
25/11/18 06:08:34 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.20.0.6:43487 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:08:34 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 708 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:08:34 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/11/18 06:08:34 INFO DAGScheduler: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0) finished in 0.753 s
25/11/18 06:08:34 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:08:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/11/18 06:08:34 INFO DAGScheduler: Job 3 finished: csv at NativeMethodAccessorImpl.java:0, took 0.763298 s
25/11/18 06:08:34 INFO FileFormatWriter: Start to commit write Job dbd8b387-f09b-42b2-b3e3-6a5defc93709.
25/11/18 06:08:34 INFO FileFormatWriter: Write Job dbd8b387-f09b-42b2-b3e3-6a5defc93709 committed. Elapsed time: 117 ms.
25/11/18 06:08:34 INFO FileFormatWriter: Finished processing stats for write job dbd8b387-f09b-42b2-b3e3-6a5defc93709.
25/11/18 06:08:34 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/11/18 06:08:34 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/11/18 06:08:34 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/11/18 06:08:34 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:08:34 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:08:34 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:08:34 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:08:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:08:34 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:08:34 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:08:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:08:34 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:08:34 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:08:34 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 338.2 KiB, free 363.2 MiB)
25/11/18 06:08:34 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 363.2 MiB)
25/11/18 06:08:34 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 6b05748f7bac:42465 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:08:34 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:08:34 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:08:34 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:08:34 INFO DAGScheduler: Got job 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/11/18 06:08:34 INFO DAGScheduler: Final stage: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/11/18 06:08:34 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:08:34 INFO DAGScheduler: Missing parents: List()
25/11/18 06:08:34 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/11/18 06:08:34 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 14.4 KiB, free 363.2 MiB)
25/11/18 06:08:34 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 363.2 MiB)
25/11/18 06:08:34 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 6b05748f7bac:42465 (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:08:34 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/11/18 06:08:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/11/18 06:08:34 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/11/18 06:08:34 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:08:34 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.20.0.6:43487 (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:08:34 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.20.0.6:43487 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:08:34 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 113 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:08:34 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/11/18 06:08:34 INFO DAGScheduler: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.127 s
25/11/18 06:08:34 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:08:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/11/18 06:08:34 INFO DAGScheduler: Job 4 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.134747 s
25/11/18 06:08:34 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 1025.0 KiB, free 362.2 MiB)
25/11/18 06:08:34 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 250.0 B, free 362.2 MiB)
25/11/18 06:08:34 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 6b05748f7bac:42465 (size: 250.0 B, free: 366.1 MiB)
25/11/18 06:08:34 INFO SparkContext: Created broadcast 12 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:08:34 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:08:34 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:08:34 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:08:34 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 338.0 KiB, free 361.9 MiB)
25/11/18 06:08:34 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 361.8 MiB)
25/11/18 06:08:34 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 6b05748f7bac:42465 (size: 32.5 KiB, free: 366.0 MiB)
25/11/18 06:08:34 INFO SparkContext: Created broadcast 13 from parquet at NativeMethodAccessorImpl.java:0
25/11/18 06:08:34 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:08:34 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
25/11/18 06:08:35 INFO DAGScheduler: Got job 5 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:08:35 INFO DAGScheduler: Final stage: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0)
25/11/18 06:08:35 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:08:35 INFO DAGScheduler: Missing parents: List()
25/11/18 06:08:35 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:08:35 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 211.3 KiB, free 361.6 MiB)
25/11/18 06:08:35 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 76.0 KiB, free 361.5 MiB)
25/11/18 06:08:35 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 6b05748f7bac:42465 (size: 76.0 KiB, free: 366.0 MiB)
25/11/18 06:08:35 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/11/18 06:08:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:08:35 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/11/18 06:08:35 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:08:35 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.20.0.6:43487 (size: 76.0 KiB, free: 366.0 MiB)
25/11/18 06:08:35 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.20.0.6:43487 (size: 250.0 B, free: 366.0 MiB)
25/11/18 06:08:36 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.20.0.6:43487 (size: 32.5 KiB, free: 366.0 MiB)
25/11/18 06:08:36 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 1808 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:08:36 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/11/18 06:08:36 INFO DAGScheduler: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0) finished in 1.849 s
25/11/18 06:08:36 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:08:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/11/18 06:08:36 INFO DAGScheduler: Job 5 finished: parquet at NativeMethodAccessorImpl.java:0, took 1.855555 s
25/11/18 06:08:36 INFO FileFormatWriter: Start to commit write Job a4253513-9822-429a-9912-dcfaae6b82cb.
25/11/18 06:08:36 INFO FileFormatWriter: Write Job a4253513-9822-429a-9912-dcfaae6b82cb committed. Elapsed time: 36 ms.
25/11/18 06:08:36 INFO FileFormatWriter: Finished processing stats for write job a4253513-9822-429a-9912-dcfaae6b82cb.
Job completed for 2025-01-01
25/11/18 06:08:36 INFO SparkUI: Stopped Spark web UI at http://6b05748f7bac:4040
25/11/18 06:08:36 INFO StandaloneSchedulerBackend: Shutting down all executors
25/11/18 06:08:36 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/11/18 06:08:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/11/18 06:08:37 INFO MemoryStore: MemoryStore cleared
25/11/18 06:08:37 INFO BlockManager: BlockManager stopped
25/11/18 06:08:37 INFO BlockManagerMaster: BlockManagerMaster stopped
25/11/18 06:08:37 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/11/18 06:08:37 INFO SparkContext: Successfully stopped SparkContext
25/11/18 06:08:37 INFO ShutdownHookManager: Shutdown hook called
25/11/18 06:08:37 INFO ShutdownHookManager: Deleting directory /tmp/spark-cae0c4d8-d9e2-41a5-8663-28df13ba125e
25/11/18 06:08:37 INFO ShutdownHookManager: Deleting directory /tmp/spark-cae0c4d8-d9e2-41a5-8663-28df13ba125e/pyspark-a0b83902-db98-4f92-9e97-7cc24a2d5a71
25/11/18 06:08:37 INFO ShutdownHookManager: Deleting directory /tmp/spark-b7456443-612e-4298-b79f-06db46c51e07
Job completed for 2025-01-01
/mnt/c/pyspark_stack/spark-apps/cron/run_sales.sh: 1: ---: not found
Triggering sales_etl_job.py for 2025-01-01...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/11/18 06:09:09 INFO SparkContext: Running Spark version 3.2.1
25/11/18 06:09:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/11/18 06:09:09 INFO ResourceUtils: ==============================================================
25/11/18 06:09:09 INFO ResourceUtils: No custom resources configured for spark.driver.
25/11/18 06:09:09 INFO ResourceUtils: ==============================================================
25/11/18 06:09:09 INFO SparkContext: Submitted application: SalesETLJob
25/11/18 06:09:09 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/11/18 06:09:09 INFO ResourceProfile: Limiting resource is cpu
25/11/18 06:09:09 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/11/18 06:09:09 INFO SecurityManager: Changing view acls to: spark
25/11/18 06:09:09 INFO SecurityManager: Changing modify acls to: spark
25/11/18 06:09:09 INFO SecurityManager: Changing view acls groups to: 
25/11/18 06:09:09 INFO SecurityManager: Changing modify acls groups to: 
25/11/18 06:09:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
25/11/18 06:09:10 INFO Utils: Successfully started service 'sparkDriver' on port 38325.
25/11/18 06:09:10 INFO SparkEnv: Registering MapOutputTracker
25/11/18 06:09:10 INFO SparkEnv: Registering BlockManagerMaster
25/11/18 06:09:10 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/11/18 06:09:10 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/11/18 06:09:10 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/11/18 06:09:10 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-1bf3c0a8-3fc6-48a0-886a-8fcd317d83d6
25/11/18 06:09:10 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/11/18 06:09:10 INFO SparkEnv: Registering OutputCommitCoordinator
25/11/18 06:09:11 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/11/18 06:09:11 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://6b05748f7bac:4040
25/11/18 06:09:12 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/11/18 06:09:12 INFO TransportClientFactory: Successfully created connection to spark-master/172.20.0.3:7077 after 60 ms (0 ms spent in bootstraps)
25/11/18 06:09:12 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20251118060912-0009
25/11/18 06:09:12 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251118060912-0009/0 on worker-20251118055626-172.20.0.6-38023 (172.20.0.6:38023) with 12 core(s)
25/11/18 06:09:12 INFO StandaloneSchedulerBackend: Granted executor ID app-20251118060912-0009/0 on hostPort 172.20.0.6:38023 with 12 core(s), 1024.0 MiB RAM
25/11/18 06:09:12 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35615.
25/11/18 06:09:12 INFO NettyBlockTransferService: Server created on 6b05748f7bac:35615
25/11/18 06:09:12 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/11/18 06:09:12 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 6b05748f7bac, 35615, None)
25/11/18 06:09:12 INFO BlockManagerMasterEndpoint: Registering block manager 6b05748f7bac:35615 with 366.3 MiB RAM, BlockManagerId(driver, 6b05748f7bac, 35615, None)
25/11/18 06:09:12 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 6b05748f7bac, 35615, None)
25/11/18 06:09:12 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 6b05748f7bac, 35615, None)
25/11/18 06:09:12 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251118060912-0009/0 is now RUNNING
25/11/18 06:09:13 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/11/18 06:09:13 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/11/18 06:09:13 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
25/11/18 06:09:17 INFO InMemoryFileIndex: It took 174 ms to list leaf files for 1 paths.
25/11/18 06:09:17 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.6:48352) with ID 0,  ResourceProfileId 0
25/11/18 06:09:17 INFO InMemoryFileIndex: It took 11 ms to list leaf files for 1 paths.
25/11/18 06:09:17 INFO BlockManagerMasterEndpoint: Registering block manager 172.20.0.6:41541 with 366.3 MiB RAM, BlockManagerId(0, 172.20.0.6, 41541, None)
25/11/18 06:09:23 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:09:23 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/11/18 06:09:23 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:09:25 INFO CodeGenerator: Code generated in 669.690309 ms
25/11/18 06:09:25 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 338.3 KiB, free 366.0 MiB)
25/11/18 06:09:25 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.9 MiB)
25/11/18 06:09:25 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 6b05748f7bac:35615 (size: 32.4 KiB, free: 366.3 MiB)
25/11/18 06:09:25 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:09:25 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:09:25 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/11/18 06:09:25 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:09:25 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/11/18 06:09:25 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:09:25 INFO DAGScheduler: Missing parents: List()
25/11/18 06:09:25 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:09:25 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/11/18 06:09:25 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/11/18 06:09:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 6b05748f7bac:35615 (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:09:25 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/11/18 06:09:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:09:25 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/11/18 06:09:25 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:09:26 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.0.6:41541 (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:09:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.0.6:41541 (size: 32.4 KiB, free: 366.3 MiB)
25/11/18 06:09:29 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 3755 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:09:29 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/11/18 06:09:29 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 3.937 s
25/11/18 06:09:29 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:09:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/11/18 06:09:29 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 4.008163 s
25/11/18 06:09:29 INFO CodeGenerator: Code generated in 18.976025 ms
25/11/18 06:09:29 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:09:29 INFO FileSourceStrategy: Post-Scan Filters: 
25/11/18 06:09:29 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:09:29 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 338.3 KiB, free 365.6 MiB)
25/11/18 06:09:29 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.6 MiB)
25/11/18 06:09:29 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 6b05748f7bac:35615 (size: 32.4 KiB, free: 366.2 MiB)
25/11/18 06:09:29 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:09:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:09:29 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 1 paths.
25/11/18 06:09:29 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
25/11/18 06:09:30 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:09:30 INFO FileSourceStrategy: Post-Scan Filters: 
25/11/18 06:09:30 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:09:30 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 338.1 KiB, free 365.2 MiB)
25/11/18 06:09:30 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.2 MiB)
25/11/18 06:09:30 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 6b05748f7bac:35615 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:09:30 INFO SparkContext: Created broadcast 3 from json at NativeMethodAccessorImpl.java:0
25/11/18 06:09:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:09:30 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
25/11/18 06:09:30 INFO DAGScheduler: Got job 1 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:09:30 INFO DAGScheduler: Final stage: ResultStage 1 (json at NativeMethodAccessorImpl.java:0)
25/11/18 06:09:30 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:09:30 INFO DAGScheduler: Missing parents: List()
25/11/18 06:09:30 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:09:30 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 12.4 KiB, free 365.2 MiB)
25/11/18 06:09:30 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 365.2 MiB)
25/11/18 06:09:30 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 6b05748f7bac:35615 (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:09:30 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/11/18 06:09:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:09:30 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/11/18 06:09:30 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:09:30 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.0.6:41541 (size: 6.5 KiB, free: 366.3 MiB)
25/11/18 06:09:30 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.0.6:41541 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:09:30 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 268 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:09:30 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/11/18 06:09:30 INFO DAGScheduler: ResultStage 1 (json at NativeMethodAccessorImpl.java:0) finished in 0.311 s
25/11/18 06:09:30 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:09:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/11/18 06:09:30 INFO DAGScheduler: Job 1 finished: json at NativeMethodAccessorImpl.java:0, took 0.323143 s
25/11/18 06:09:31 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/11/18 06:09:31 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/11/18 06:09:31 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/11/18 06:09:31 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:09:31 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:09:31 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:09:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:09:31 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:09:31 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
25/11/18 06:09:31 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 6b05748f7bac:35615 in memory (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:09:31 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.20.0.6:41541 in memory (size: 32.5 KiB, free: 366.3 MiB)
25/11/18 06:09:31 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 6b05748f7bac:35615 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/11/18 06:09:31 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.0.6:41541 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:09:31 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 6b05748f7bac:35615 in memory (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:09:31 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.20.0.6:41541 in memory (size: 6.5 KiB, free: 366.3 MiB)
25/11/18 06:09:31 INFO CodeGenerator: Code generated in 26.552967 ms
25/11/18 06:09:31 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 338.2 KiB, free 365.2 MiB)
25/11/18 06:09:31 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.2 MiB)
25/11/18 06:09:31 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 6b05748f7bac:35615 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:09:31 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:09:31 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:09:31 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:09:31 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/11/18 06:09:31 INFO DAGScheduler: Final stage: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/11/18 06:09:31 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:09:31 INFO DAGScheduler: Missing parents: List()
25/11/18 06:09:31 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/11/18 06:09:31 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 14.4 KiB, free 365.2 MiB)
25/11/18 06:09:31 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 365.2 MiB)
25/11/18 06:09:31 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 6b05748f7bac:35615 (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:09:31 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/11/18 06:09:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/11/18 06:09:31 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/11/18 06:09:31 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:09:31 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.20.0.6:41541 (size: 7.2 KiB, free: 366.3 MiB)
25/11/18 06:09:31 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.20.0.6:41541 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:09:31 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 315 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:09:31 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/11/18 06:09:31 INFO DAGScheduler: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.329 s
25/11/18 06:09:31 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:09:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/11/18 06:09:31 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.336586 s
25/11/18 06:09:32 INFO CodeGenerator: Code generated in 12.373495 ms
25/11/18 06:09:32 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 1025.0 KiB, free 364.2 MiB)
25/11/18 06:09:32 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 250.0 B, free 364.2 MiB)
25/11/18 06:09:32 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 6b05748f7bac:35615 (size: 250.0 B, free: 366.2 MiB)
25/11/18 06:09:32 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:09:32 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:09:32 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:09:32 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:09:32 INFO CodeGenerator: Code generated in 36.223934 ms
25/11/18 06:09:32 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 338.0 KiB, free 363.9 MiB)
25/11/18 06:09:32 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 363.8 MiB)
25/11/18 06:09:32 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 6b05748f7bac:35615 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:09:32 INFO SparkContext: Created broadcast 8 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:09:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:09:32 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/11/18 06:09:32 INFO DAGScheduler: Got job 3 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:09:32 INFO DAGScheduler: Final stage: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0)
25/11/18 06:09:32 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:09:32 INFO DAGScheduler: Missing parents: List()
25/11/18 06:09:32 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:09:32 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 211.3 KiB, free 363.6 MiB)
25/11/18 06:09:32 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 75.9 KiB, free 363.5 MiB)
25/11/18 06:09:32 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 6b05748f7bac:35615 (size: 75.9 KiB, free: 366.1 MiB)
25/11/18 06:09:32 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/11/18 06:09:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:09:32 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/11/18 06:09:32 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:09:32 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.20.0.6:41541 (size: 75.9 KiB, free: 366.2 MiB)
25/11/18 06:09:32 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.20.0.6:41541 (size: 250.0 B, free: 366.2 MiB)
25/11/18 06:09:32 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.20.0.6:41541 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:09:32 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in -208 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:09:32 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/11/18 06:09:32 INFO DAGScheduler: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0) finished in -0.171 s
25/11/18 06:09:32 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:09:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/11/18 06:09:32 INFO DAGScheduler: Job 3 finished: csv at NativeMethodAccessorImpl.java:0, took 0.636567 s
25/11/18 06:09:32 INFO FileFormatWriter: Start to commit write Job 508499c3-cd2b-4021-95a3-7b693d82e5fa.
25/11/18 06:09:35 INFO FileFormatWriter: Write Job 508499c3-cd2b-4021-95a3-7b693d82e5fa committed. Elapsed time: 90 ms.
25/11/18 06:09:35 INFO FileFormatWriter: Finished processing stats for write job 508499c3-cd2b-4021-95a3-7b693d82e5fa.
25/11/18 06:09:35 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/11/18 06:09:35 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/11/18 06:09:35 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/11/18 06:09:35 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:09:35 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:09:35 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:09:35 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:09:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:09:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:09:35 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:09:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:09:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:09:35 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:09:35 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 338.2 KiB, free 363.2 MiB)
25/11/18 06:09:35 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 363.2 MiB)
25/11/18 06:09:35 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 6b05748f7bac:35615 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:09:35 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:09:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:09:36 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:09:36 INFO DAGScheduler: Got job 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/11/18 06:09:36 INFO DAGScheduler: Final stage: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/11/18 06:09:36 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:09:36 INFO DAGScheduler: Missing parents: List()
25/11/18 06:09:36 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/11/18 06:09:36 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 14.4 KiB, free 363.2 MiB)
25/11/18 06:09:36 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 363.2 MiB)
25/11/18 06:09:36 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 6b05748f7bac:35615 (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:09:36 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/11/18 06:09:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/11/18 06:09:36 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/11/18 06:09:36 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:09:36 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.20.0.6:41541 (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:09:36 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.20.0.6:41541 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:09:36 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 96 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:09:36 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/11/18 06:09:36 INFO DAGScheduler: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.122 s
25/11/18 06:09:36 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:09:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/11/18 06:09:36 INFO DAGScheduler: Job 4 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.130932 s
25/11/18 06:09:36 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 1025.0 KiB, free 362.2 MiB)
25/11/18 06:09:36 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 250.0 B, free 362.2 MiB)
25/11/18 06:09:36 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 6b05748f7bac:35615 (size: 250.0 B, free: 366.1 MiB)
25/11/18 06:09:36 INFO SparkContext: Created broadcast 12 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:09:36 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:09:36 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:09:36 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:09:36 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 338.0 KiB, free 361.8 MiB)
25/11/18 06:09:36 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 361.8 MiB)
25/11/18 06:09:36 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 6b05748f7bac:35615 (size: 32.5 KiB, free: 366.0 MiB)
25/11/18 06:09:36 INFO SparkContext: Created broadcast 13 from parquet at NativeMethodAccessorImpl.java:0
25/11/18 06:09:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:09:36 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
25/11/18 06:09:36 INFO DAGScheduler: Got job 5 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:09:36 INFO DAGScheduler: Final stage: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0)
25/11/18 06:09:36 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:09:36 INFO DAGScheduler: Missing parents: List()
25/11/18 06:09:36 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:09:36 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 211.3 KiB, free 361.6 MiB)
25/11/18 06:09:36 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 76.0 KiB, free 361.5 MiB)
25/11/18 06:09:36 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 6b05748f7bac:35615 (size: 76.0 KiB, free: 365.9 MiB)
25/11/18 06:09:36 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/11/18 06:09:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:09:36 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/11/18 06:09:36 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:09:36 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.20.0.6:41541 (size: 76.0 KiB, free: 366.0 MiB)
25/11/18 06:09:36 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.20.0.6:41541 (size: 250.0 B, free: 366.0 MiB)
25/11/18 06:09:37 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.20.0.6:41541 (size: 32.5 KiB, free: 366.0 MiB)
25/11/18 06:09:38 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 1865 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:09:38 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/11/18 06:09:38 INFO DAGScheduler: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0) finished in 1.900 s
25/11/18 06:09:38 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:09:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/11/18 06:09:38 INFO DAGScheduler: Job 5 finished: parquet at NativeMethodAccessorImpl.java:0, took 1.905771 s
25/11/18 06:09:38 INFO FileFormatWriter: Start to commit write Job 946d9fc7-1ce3-48ae-9c12-06bcbcfa89c3.
25/11/18 06:09:38 INFO FileFormatWriter: Write Job 946d9fc7-1ce3-48ae-9c12-06bcbcfa89c3 committed. Elapsed time: 29 ms.
25/11/18 06:09:38 INFO FileFormatWriter: Finished processing stats for write job 946d9fc7-1ce3-48ae-9c12-06bcbcfa89c3.
Job completed for 2025-01-01
25/11/18 06:09:38 INFO SparkUI: Stopped Spark web UI at http://6b05748f7bac:4040
25/11/18 06:09:38 INFO StandaloneSchedulerBackend: Shutting down all executors
25/11/18 06:09:38 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/11/18 06:09:38 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/11/18 06:09:38 INFO MemoryStore: MemoryStore cleared
25/11/18 06:09:38 INFO BlockManager: BlockManager stopped
25/11/18 06:09:38 INFO BlockManagerMaster: BlockManagerMaster stopped
25/11/18 06:09:38 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/11/18 06:09:38 INFO SparkContext: Successfully stopped SparkContext
25/11/18 06:09:38 INFO ShutdownHookManager: Shutdown hook called
25/11/18 06:09:38 INFO ShutdownHookManager: Deleting directory /tmp/spark-0d53f93a-8c07-4285-b802-cb937b4693a1/pyspark-0e8537fd-5d69-4104-aa4e-1cf0764cb221
25/11/18 06:09:38 INFO ShutdownHookManager: Deleting directory /tmp/spark-0d53f93a-8c07-4285-b802-cb937b4693a1
25/11/18 06:09:38 INFO ShutdownHookManager: Deleting directory /tmp/spark-cc1205b8-02be-43e7-b6bb-d0939698d02c
Job completed for 2025-01-01
/mnt/c/pyspark_stack/spark-apps/cron/run_sales.sh: 1: ---: not found
Triggering sales_etl_job.py for 2025-01-01...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/11/18 06:10:04 INFO SparkContext: Running Spark version 3.2.1
25/11/18 06:10:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/11/18 06:10:08 INFO ResourceUtils: ==============================================================
25/11/18 06:10:08 INFO ResourceUtils: No custom resources configured for spark.driver.
25/11/18 06:10:08 INFO ResourceUtils: ==============================================================
25/11/18 06:10:08 INFO SparkContext: Submitted application: SalesETLJob
25/11/18 06:10:08 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/11/18 06:10:08 INFO ResourceProfile: Limiting resource is cpu
25/11/18 06:10:08 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/11/18 06:10:08 INFO SecurityManager: Changing view acls to: spark
25/11/18 06:10:08 INFO SecurityManager: Changing modify acls to: spark
25/11/18 06:10:08 INFO SecurityManager: Changing view acls groups to: 
25/11/18 06:10:08 INFO SecurityManager: Changing modify acls groups to: 
25/11/18 06:10:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
25/11/18 06:10:09 INFO Utils: Successfully started service 'sparkDriver' on port 37225.
25/11/18 06:10:09 INFO SparkEnv: Registering MapOutputTracker
25/11/18 06:10:09 INFO SparkEnv: Registering BlockManagerMaster
25/11/18 06:10:09 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/11/18 06:10:09 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/11/18 06:10:09 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/11/18 06:10:09 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-525934b9-0a59-47c8-89b8-6b671eb12b3f
25/11/18 06:10:09 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/11/18 06:10:09 INFO SparkEnv: Registering OutputCommitCoordinator
25/11/18 06:10:09 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/11/18 06:10:10 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://6b05748f7bac:4040
25/11/18 06:10:10 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/11/18 06:10:10 INFO TransportClientFactory: Successfully created connection to spark-master/172.20.0.3:7077 after 46 ms (0 ms spent in bootstraps)
25/11/18 06:10:10 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20251118061010-0010
25/11/18 06:10:10 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251118061010-0010/0 on worker-20251118055626-172.20.0.6-38023 (172.20.0.6:38023) with 12 core(s)
25/11/18 06:10:10 INFO StandaloneSchedulerBackend: Granted executor ID app-20251118061010-0010/0 on hostPort 172.20.0.6:38023 with 12 core(s), 1024.0 MiB RAM
25/11/18 06:10:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41037.
25/11/18 06:10:10 INFO NettyBlockTransferService: Server created on 6b05748f7bac:41037
25/11/18 06:10:10 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/11/18 06:10:10 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 6b05748f7bac, 41037, None)
25/11/18 06:10:10 INFO BlockManagerMasterEndpoint: Registering block manager 6b05748f7bac:41037 with 366.3 MiB RAM, BlockManagerId(driver, 6b05748f7bac, 41037, None)
25/11/18 06:10:10 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 6b05748f7bac, 41037, None)
25/11/18 06:10:10 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 6b05748f7bac, 41037, None)
25/11/18 06:10:10 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251118061010-0010/0 is now RUNNING
25/11/18 06:10:11 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/11/18 06:10:11 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/11/18 06:10:11 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
25/11/18 06:10:13 INFO InMemoryFileIndex: It took 123 ms to list leaf files for 1 paths.
25/11/18 06:10:14 INFO InMemoryFileIndex: It took 9 ms to list leaf files for 1 paths.
25/11/18 06:10:14 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.6:50216) with ID 0,  ResourceProfileId 0
25/11/18 06:10:14 INFO BlockManagerMasterEndpoint: Registering block manager 172.20.0.6:45565 with 366.3 MiB RAM, BlockManagerId(0, 172.20.0.6, 45565, None)
25/11/18 06:10:18 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:10:18 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/11/18 06:10:18 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:10:20 INFO CodeGenerator: Code generated in 394.364042 ms
25/11/18 06:10:20 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 338.3 KiB, free 366.0 MiB)
25/11/18 06:10:20 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.9 MiB)
25/11/18 06:10:20 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 6b05748f7bac:41037 (size: 32.4 KiB, free: 366.3 MiB)
25/11/18 06:10:20 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:10:20 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:10:20 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/11/18 06:10:20 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:10:20 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/11/18 06:10:20 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:10:20 INFO DAGScheduler: Missing parents: List()
25/11/18 06:10:20 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:10:20 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/11/18 06:10:20 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/11/18 06:10:20 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 6b05748f7bac:41037 (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:10:20 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/11/18 06:10:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:10:20 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/11/18 06:10:21 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:10:21 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.0.6:45565 (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:10:23 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.0.6:45565 (size: 32.4 KiB, free: 366.3 MiB)
25/11/18 06:10:25 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4382 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:10:25 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/11/18 06:10:25 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 4.585 s
25/11/18 06:10:25 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:10:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/11/18 06:10:25 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 4.673509 s
25/11/18 06:10:25 INFO CodeGenerator: Code generated in 62.345674 ms
25/11/18 06:10:25 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:10:25 INFO FileSourceStrategy: Post-Scan Filters: 
25/11/18 06:10:25 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:10:25 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 338.3 KiB, free 365.6 MiB)
25/11/18 06:10:25 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.6 MiB)
25/11/18 06:10:25 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 6b05748f7bac:41037 (size: 32.4 KiB, free: 366.2 MiB)
25/11/18 06:10:25 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:10:25 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:10:25 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 1 paths.
25/11/18 06:10:26 INFO InMemoryFileIndex: It took 17 ms to list leaf files for 1 paths.
25/11/18 06:10:26 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:10:26 INFO FileSourceStrategy: Post-Scan Filters: 
25/11/18 06:10:26 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:10:26 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 338.1 KiB, free 365.2 MiB)
25/11/18 06:10:26 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.2 MiB)
25/11/18 06:10:26 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 6b05748f7bac:41037 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:10:26 INFO SparkContext: Created broadcast 3 from json at NativeMethodAccessorImpl.java:0
25/11/18 06:10:26 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:10:26 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
25/11/18 06:10:26 INFO DAGScheduler: Got job 1 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:10:26 INFO DAGScheduler: Final stage: ResultStage 1 (json at NativeMethodAccessorImpl.java:0)
25/11/18 06:10:26 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:10:26 INFO DAGScheduler: Missing parents: List()
25/11/18 06:10:26 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:10:26 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 12.4 KiB, free 365.2 MiB)
25/11/18 06:10:26 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 365.2 MiB)
25/11/18 06:10:26 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 6b05748f7bac:41037 (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:10:26 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/11/18 06:10:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:10:26 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/11/18 06:10:26 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:10:26 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.0.6:45565 (size: 6.5 KiB, free: 366.3 MiB)
25/11/18 06:10:26 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.0.6:45565 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:10:26 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 470 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:10:26 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/11/18 06:10:26 INFO DAGScheduler: ResultStage 1 (json at NativeMethodAccessorImpl.java:0) finished in 0.545 s
25/11/18 06:10:26 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:10:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/11/18 06:10:26 INFO DAGScheduler: Job 1 finished: json at NativeMethodAccessorImpl.java:0, took 0.566074 s
25/11/18 06:10:27 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/11/18 06:10:27 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/11/18 06:10:28 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/11/18 06:10:28 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:10:28 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:10:28 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:10:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:10:28 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:10:28 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
25/11/18 06:10:28 INFO CodeGenerator: Code generated in 35.943234 ms
25/11/18 06:10:28 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 338.2 KiB, free 364.8 MiB)
25/11/18 06:10:28 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 364.8 MiB)
25/11/18 06:10:28 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 6b05748f7bac:41037 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:10:28 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:10:28 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:10:28 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:10:28 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/11/18 06:10:28 INFO DAGScheduler: Final stage: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/11/18 06:10:28 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:10:28 INFO DAGScheduler: Missing parents: List()
25/11/18 06:10:28 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/11/18 06:10:28 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 14.4 KiB, free 364.8 MiB)
25/11/18 06:10:28 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 364.8 MiB)
25/11/18 06:10:28 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 6b05748f7bac:41037 (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:10:28 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/11/18 06:10:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/11/18 06:10:28 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/11/18 06:10:28 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:10:28 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 6b05748f7bac:41037 in memory (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:10:28 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.20.0.6:45565 in memory (size: 32.5 KiB, free: 366.3 MiB)
25/11/18 06:10:28 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.20.0.6:45565 (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:10:28 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 6b05748f7bac:41037 in memory (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:10:28 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.20.0.6:45565 in memory (size: 6.5 KiB, free: 366.3 MiB)
25/11/18 06:10:28 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 6b05748f7bac:41037 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/11/18 06:10:28 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.0.6:45565 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:10:28 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.20.0.6:45565 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:10:29 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 401 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:10:29 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/11/18 06:10:29 INFO DAGScheduler: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.444 s
25/11/18 06:10:29 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:10:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/11/18 06:10:29 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.514233 s
25/11/18 06:10:29 INFO CodeGenerator: Code generated in 18.498337 ms
25/11/18 06:10:29 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 1025.0 KiB, free 364.2 MiB)
25/11/18 06:10:29 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 250.0 B, free 364.2 MiB)
25/11/18 06:10:29 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 6b05748f7bac:41037 (size: 250.0 B, free: 366.2 MiB)
25/11/18 06:10:29 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:10:29 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:10:29 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:10:29 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:10:29 INFO CodeGenerator: Code generated in 36.315509 ms
25/11/18 06:10:29 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 338.0 KiB, free 363.9 MiB)
25/11/18 06:10:29 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 363.8 MiB)
25/11/18 06:10:29 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 6b05748f7bac:41037 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:10:29 INFO SparkContext: Created broadcast 8 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:10:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:10:29 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/11/18 06:10:29 INFO DAGScheduler: Got job 3 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:10:29 INFO DAGScheduler: Final stage: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0)
25/11/18 06:10:29 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:10:29 INFO DAGScheduler: Missing parents: List()
25/11/18 06:10:29 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:10:29 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 211.3 KiB, free 363.6 MiB)
25/11/18 06:10:29 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 75.9 KiB, free 363.5 MiB)
25/11/18 06:10:29 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 6b05748f7bac:41037 (size: 75.9 KiB, free: 366.1 MiB)
25/11/18 06:10:29 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/11/18 06:10:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:10:29 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/11/18 06:10:29 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:10:29 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.20.0.6:45565 (size: 75.9 KiB, free: 366.2 MiB)
25/11/18 06:10:29 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.20.0.6:45565 (size: 250.0 B, free: 366.2 MiB)
25/11/18 06:10:30 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.20.0.6:45565 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:10:30 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 783 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:10:30 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/11/18 06:10:30 INFO DAGScheduler: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0) finished in 0.835 s
25/11/18 06:10:30 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:10:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/11/18 06:10:30 INFO DAGScheduler: Job 3 finished: csv at NativeMethodAccessorImpl.java:0, took 0.843696 s
25/11/18 06:10:30 INFO FileFormatWriter: Start to commit write Job 5d1548cb-287a-48a0-9dbd-6b0a02731a41.
25/11/18 06:10:30 INFO FileFormatWriter: Write Job 5d1548cb-287a-48a0-9dbd-6b0a02731a41 committed. Elapsed time: 116 ms.
25/11/18 06:10:30 INFO FileFormatWriter: Finished processing stats for write job 5d1548cb-287a-48a0-9dbd-6b0a02731a41.
25/11/18 06:10:30 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/11/18 06:10:30 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/11/18 06:10:30 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/11/18 06:10:30 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:10:30 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:10:30 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:10:30 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:10:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:10:30 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:10:30 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:10:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:10:30 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:10:30 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:10:30 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 338.2 KiB, free 363.2 MiB)
25/11/18 06:10:30 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 363.2 MiB)
25/11/18 06:10:30 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 6b05748f7bac:41037 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:10:30 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:10:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:10:30 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:10:30 INFO DAGScheduler: Got job 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/11/18 06:10:30 INFO DAGScheduler: Final stage: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/11/18 06:10:30 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:10:30 INFO DAGScheduler: Missing parents: List()
25/11/18 06:10:30 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/11/18 06:10:30 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 14.4 KiB, free 363.2 MiB)
25/11/18 06:10:30 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 363.2 MiB)
25/11/18 06:10:30 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 6b05748f7bac:41037 (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:10:30 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/11/18 06:10:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/11/18 06:10:30 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/11/18 06:10:30 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:10:30 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.20.0.6:45565 (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:10:30 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.20.0.6:45565 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:10:30 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 124 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:10:30 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/11/18 06:10:30 INFO DAGScheduler: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.140 s
25/11/18 06:10:30 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:10:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/11/18 06:10:30 INFO DAGScheduler: Job 4 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.156029 s
25/11/18 06:10:30 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 1025.0 KiB, free 362.2 MiB)
25/11/18 06:10:30 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 250.0 B, free 362.2 MiB)
25/11/18 06:10:30 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 6b05748f7bac:41037 (size: 250.0 B, free: 366.1 MiB)
25/11/18 06:10:30 INFO SparkContext: Created broadcast 12 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:10:30 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:10:30 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:10:30 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:10:31 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 338.0 KiB, free 361.8 MiB)
25/11/18 06:10:31 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 361.8 MiB)
25/11/18 06:10:31 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 6b05748f7bac:41037 (size: 32.5 KiB, free: 366.0 MiB)
25/11/18 06:10:31 INFO SparkContext: Created broadcast 13 from parquet at NativeMethodAccessorImpl.java:0
25/11/18 06:10:31 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:10:31 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
25/11/18 06:10:31 INFO DAGScheduler: Got job 5 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:10:31 INFO DAGScheduler: Final stage: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0)
25/11/18 06:10:31 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:10:31 INFO DAGScheduler: Missing parents: List()
25/11/18 06:10:31 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:10:31 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 211.3 KiB, free 361.6 MiB)
25/11/18 06:10:31 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 76.0 KiB, free 361.5 MiB)
25/11/18 06:10:31 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 6b05748f7bac:41037 (size: 76.0 KiB, free: 365.9 MiB)
25/11/18 06:10:31 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/11/18 06:10:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:10:31 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/11/18 06:10:31 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:10:31 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.20.0.6:45565 (size: 76.0 KiB, free: 366.0 MiB)
25/11/18 06:10:31 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.20.0.6:45565 (size: 250.0 B, free: 366.0 MiB)
25/11/18 06:10:31 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.20.0.6:45565 (size: 32.5 KiB, free: 366.0 MiB)
25/11/18 06:10:32 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 1406 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:10:32 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/11/18 06:10:32 INFO DAGScheduler: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0) finished in 1.442 s
25/11/18 06:10:32 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:10:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/11/18 06:10:32 INFO DAGScheduler: Job 5 finished: parquet at NativeMethodAccessorImpl.java:0, took 1.448942 s
25/11/18 06:10:32 INFO FileFormatWriter: Start to commit write Job 3fa24ed6-9e6c-41f8-807b-38fa75918f69.
25/11/18 06:10:32 INFO FileFormatWriter: Write Job 3fa24ed6-9e6c-41f8-807b-38fa75918f69 committed. Elapsed time: 40 ms.
25/11/18 06:10:32 INFO FileFormatWriter: Finished processing stats for write job 3fa24ed6-9e6c-41f8-807b-38fa75918f69.
Job completed for 2025-01-01
25/11/18 06:10:32 INFO SparkUI: Stopped Spark web UI at http://6b05748f7bac:4040
25/11/18 06:10:32 INFO StandaloneSchedulerBackend: Shutting down all executors
25/11/18 06:10:32 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/11/18 06:10:32 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/11/18 06:10:32 INFO MemoryStore: MemoryStore cleared
25/11/18 06:10:32 INFO BlockManager: BlockManager stopped
25/11/18 06:10:32 INFO BlockManagerMaster: BlockManagerMaster stopped
25/11/18 06:10:32 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/11/18 06:10:32 INFO SparkContext: Successfully stopped SparkContext
25/11/18 06:10:33 INFO ShutdownHookManager: Shutdown hook called
25/11/18 06:10:33 INFO ShutdownHookManager: Deleting directory /tmp/spark-94805b4f-099a-4dd8-8ec5-50ec0b16ce02
25/11/18 06:10:33 INFO ShutdownHookManager: Deleting directory /tmp/spark-65cfc9d2-4de2-4e88-9f1c-b087472dfbf3
25/11/18 06:10:33 INFO ShutdownHookManager: Deleting directory /tmp/spark-94805b4f-099a-4dd8-8ec5-50ec0b16ce02/pyspark-63f43b5b-8ff4-4569-9603-bb040bf5eb7b
Job completed for 2025-01-01
/mnt/c/pyspark_stack/spark-apps/cron/run_sales.sh: 1: ---: not found
Triggering sales_etl_job.py for 2025-01-01...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/11/18 06:11:08 INFO SparkContext: Running Spark version 3.2.1
25/11/18 06:11:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/11/18 06:11:08 INFO ResourceUtils: ==============================================================
25/11/18 06:11:08 INFO ResourceUtils: No custom resources configured for spark.driver.
25/11/18 06:11:08 INFO ResourceUtils: ==============================================================
25/11/18 06:11:08 INFO SparkContext: Submitted application: SalesETLJob
25/11/18 06:11:08 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/11/18 06:11:08 INFO ResourceProfile: Limiting resource is cpu
25/11/18 06:11:08 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/11/18 06:11:08 INFO SecurityManager: Changing view acls to: spark
25/11/18 06:11:08 INFO SecurityManager: Changing modify acls to: spark
25/11/18 06:11:08 INFO SecurityManager: Changing view acls groups to: 
25/11/18 06:11:08 INFO SecurityManager: Changing modify acls groups to: 
25/11/18 06:11:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
25/11/18 06:11:08 INFO Utils: Successfully started service 'sparkDriver' on port 36681.
25/11/18 06:11:09 INFO SparkEnv: Registering MapOutputTracker
25/11/18 06:11:09 INFO SparkEnv: Registering BlockManagerMaster
25/11/18 06:11:09 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/11/18 06:11:09 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/11/18 06:11:09 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/11/18 06:11:09 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a9a2acd7-fbed-476e-97c0-602542b2c7ea
25/11/18 06:11:09 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/11/18 06:11:09 INFO SparkEnv: Registering OutputCommitCoordinator
25/11/18 06:11:09 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/11/18 06:11:09 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://6b05748f7bac:4040
25/11/18 06:11:09 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/11/18 06:11:10 INFO TransportClientFactory: Successfully created connection to spark-master/172.20.0.3:7077 after 44 ms (0 ms spent in bootstraps)
25/11/18 06:11:10 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20251118061110-0011
25/11/18 06:11:10 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251118061110-0011/0 on worker-20251118055626-172.20.0.6-38023 (172.20.0.6:38023) with 12 core(s)
25/11/18 06:11:10 INFO StandaloneSchedulerBackend: Granted executor ID app-20251118061110-0011/0 on hostPort 172.20.0.6:38023 with 12 core(s), 1024.0 MiB RAM
25/11/18 06:11:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 32771.
25/11/18 06:11:10 INFO NettyBlockTransferService: Server created on 6b05748f7bac:32771
25/11/18 06:11:10 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/11/18 06:11:10 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 6b05748f7bac, 32771, None)
25/11/18 06:11:10 INFO BlockManagerMasterEndpoint: Registering block manager 6b05748f7bac:32771 with 366.3 MiB RAM, BlockManagerId(driver, 6b05748f7bac, 32771, None)
25/11/18 06:11:10 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 6b05748f7bac, 32771, None)
25/11/18 06:11:10 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 6b05748f7bac, 32771, None)
25/11/18 06:11:10 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251118061110-0011/0 is now RUNNING
25/11/18 06:11:10 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/11/18 06:11:13 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/11/18 06:11:13 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
25/11/18 06:11:16 INFO InMemoryFileIndex: It took 125 ms to list leaf files for 1 paths.
25/11/18 06:11:16 INFO InMemoryFileIndex: It took 11 ms to list leaf files for 1 paths.
25/11/18 06:11:16 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.6:41476) with ID 0,  ResourceProfileId 0
25/11/18 06:11:16 INFO BlockManagerMasterEndpoint: Registering block manager 172.20.0.6:37257 with 366.3 MiB RAM, BlockManagerId(0, 172.20.0.6, 37257, None)
25/11/18 06:11:20 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:11:20 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/11/18 06:11:20 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:11:21 INFO CodeGenerator: Code generated in 431.145024 ms
25/11/18 06:11:21 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 338.3 KiB, free 366.0 MiB)
25/11/18 06:11:21 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.9 MiB)
25/11/18 06:11:21 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 6b05748f7bac:32771 (size: 32.4 KiB, free: 366.3 MiB)
25/11/18 06:11:21 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:11:21 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:11:21 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/11/18 06:11:21 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:11:21 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/11/18 06:11:21 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:11:21 INFO DAGScheduler: Missing parents: List()
25/11/18 06:11:21 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:11:22 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/11/18 06:11:22 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/11/18 06:11:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 6b05748f7bac:32771 (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:11:22 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/11/18 06:11:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:11:22 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/11/18 06:11:22 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:11:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.0.6:37257 (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:11:25 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.0.6:37257 (size: 32.4 KiB, free: 366.3 MiB)
25/11/18 06:11:27 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 5379 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:11:27 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/11/18 06:11:27 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 5.567 s
25/11/18 06:11:27 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:11:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/11/18 06:11:27 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 5.658856 s
25/11/18 06:11:27 INFO CodeGenerator: Code generated in 22.231007 ms
25/11/18 06:11:27 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:11:27 INFO FileSourceStrategy: Post-Scan Filters: 
25/11/18 06:11:27 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:11:27 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 338.3 KiB, free 365.6 MiB)
25/11/18 06:11:27 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.6 MiB)
25/11/18 06:11:27 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 6b05748f7bac:32771 (size: 32.4 KiB, free: 366.2 MiB)
25/11/18 06:11:27 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:11:27 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:11:27 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
25/11/18 06:11:28 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
25/11/18 06:11:28 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:11:28 INFO FileSourceStrategy: Post-Scan Filters: 
25/11/18 06:11:28 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:11:28 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 338.1 KiB, free 365.2 MiB)
25/11/18 06:11:28 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.2 MiB)
25/11/18 06:11:28 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 6b05748f7bac:32771 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:11:28 INFO SparkContext: Created broadcast 3 from json at NativeMethodAccessorImpl.java:0
25/11/18 06:11:28 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:11:28 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
25/11/18 06:11:28 INFO DAGScheduler: Got job 1 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:11:28 INFO DAGScheduler: Final stage: ResultStage 1 (json at NativeMethodAccessorImpl.java:0)
25/11/18 06:11:28 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:11:28 INFO DAGScheduler: Missing parents: List()
25/11/18 06:11:28 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:11:28 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 12.4 KiB, free 365.2 MiB)
25/11/18 06:11:28 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 365.2 MiB)
25/11/18 06:11:28 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 6b05748f7bac:32771 (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:11:28 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/11/18 06:11:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:11:28 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/11/18 06:11:28 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:11:28 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.0.6:37257 (size: 6.5 KiB, free: 366.3 MiB)
25/11/18 06:11:28 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.0.6:37257 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:11:28 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 328 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:11:28 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/11/18 06:11:28 INFO DAGScheduler: ResultStage 1 (json at NativeMethodAccessorImpl.java:0) finished in 0.377 s
25/11/18 06:11:28 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:11:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/11/18 06:11:28 INFO DAGScheduler: Job 1 finished: json at NativeMethodAccessorImpl.java:0, took 0.388599 s
25/11/18 06:11:29 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/11/18 06:11:29 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/11/18 06:11:29 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/11/18 06:11:29 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:11:29 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:11:29 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:11:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:11:29 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:11:29 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
25/11/18 06:11:30 INFO CodeGenerator: Code generated in 29.265523 ms
25/11/18 06:11:30 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 338.2 KiB, free 364.8 MiB)
25/11/18 06:11:30 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 364.8 MiB)
25/11/18 06:11:30 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 6b05748f7bac:32771 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:11:30 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:11:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:11:30 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:11:30 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/11/18 06:11:30 INFO DAGScheduler: Final stage: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/11/18 06:11:30 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:11:30 INFO DAGScheduler: Missing parents: List()
25/11/18 06:11:30 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/11/18 06:11:30 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 14.4 KiB, free 364.8 MiB)
25/11/18 06:11:30 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 364.8 MiB)
25/11/18 06:11:30 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 6b05748f7bac:32771 (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:11:30 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/11/18 06:11:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/11/18 06:11:30 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/11/18 06:11:30 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:11:30 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.20.0.6:37257 (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:11:30 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.20.0.6:37257 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:11:30 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 388 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:11:30 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/11/18 06:11:30 INFO DAGScheduler: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.421 s
25/11/18 06:11:30 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:11:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/11/18 06:11:30 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.428096 s
25/11/18 06:11:30 INFO CodeGenerator: Code generated in 16.938866 ms
25/11/18 06:11:30 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 1025.0 KiB, free 363.8 MiB)
25/11/18 06:11:30 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 250.0 B, free 363.8 MiB)
25/11/18 06:11:30 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 6b05748f7bac:32771 (size: 250.0 B, free: 366.2 MiB)
25/11/18 06:11:30 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:11:30 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:11:30 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:11:30 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:11:30 INFO CodeGenerator: Code generated in 64.952026 ms
25/11/18 06:11:30 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 338.0 KiB, free 363.5 MiB)
25/11/18 06:11:30 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 363.4 MiB)
25/11/18 06:11:30 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 6b05748f7bac:32771 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:11:30 INFO SparkContext: Created broadcast 8 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:11:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:11:31 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/11/18 06:11:31 INFO DAGScheduler: Got job 3 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:11:31 INFO DAGScheduler: Final stage: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0)
25/11/18 06:11:31 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:11:31 INFO DAGScheduler: Missing parents: List()
25/11/18 06:11:31 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:11:31 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 211.3 KiB, free 363.2 MiB)
25/11/18 06:11:31 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 75.9 KiB, free 363.2 MiB)
25/11/18 06:11:31 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 6b05748f7bac:32771 (size: 75.9 KiB, free: 366.0 MiB)
25/11/18 06:11:31 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/11/18 06:11:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:11:31 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/11/18 06:11:31 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 6b05748f7bac:32771 in memory (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:11:31 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:11:31 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.20.0.6:37257 in memory (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:11:31 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.20.0.6:37257 (size: 75.9 KiB, free: 366.1 MiB)
25/11/18 06:11:31 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 6b05748f7bac:32771 in memory (size: 5.8 KiB, free: 366.1 MiB)
25/11/18 06:11:31 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.0.6:37257 in memory (size: 5.8 KiB, free: 366.1 MiB)
25/11/18 06:11:31 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 6b05748f7bac:32771 in memory (size: 6.5 KiB, free: 366.1 MiB)
25/11/18 06:11:31 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.20.0.6:37257 in memory (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:11:31 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 6b05748f7bac:32771 in memory (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:11:31 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.20.0.6:37257 in memory (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:11:31 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.20.0.6:37257 (size: 250.0 B, free: 366.2 MiB)
25/11/18 06:11:31 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.20.0.6:37257 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:11:31 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 806 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:11:31 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/11/18 06:11:31 INFO DAGScheduler: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0) finished in 0.854 s
25/11/18 06:11:31 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:11:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/11/18 06:11:31 INFO DAGScheduler: Job 3 finished: csv at NativeMethodAccessorImpl.java:0, took 0.878065 s
25/11/18 06:11:31 INFO FileFormatWriter: Start to commit write Job 50042bdb-356d-46f4-8c85-08e772e6d25f.
25/11/18 06:11:32 INFO FileFormatWriter: Write Job 50042bdb-356d-46f4-8c85-08e772e6d25f committed. Elapsed time: 107 ms.
25/11/18 06:11:32 INFO FileFormatWriter: Finished processing stats for write job 50042bdb-356d-46f4-8c85-08e772e6d25f.
25/11/18 06:11:32 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/11/18 06:11:32 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/11/18 06:11:32 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/11/18 06:11:32 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:11:32 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:11:32 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:11:32 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:11:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:11:32 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:11:32 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:11:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:11:32 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:11:32 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:11:32 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 338.2 KiB, free 363.2 MiB)
25/11/18 06:11:32 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 363.2 MiB)
25/11/18 06:11:32 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 6b05748f7bac:32771 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:11:32 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:11:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:11:32 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:11:32 INFO DAGScheduler: Got job 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/11/18 06:11:32 INFO DAGScheduler: Final stage: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/11/18 06:11:32 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:11:32 INFO DAGScheduler: Missing parents: List()
25/11/18 06:11:32 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/11/18 06:11:32 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 14.4 KiB, free 363.2 MiB)
25/11/18 06:11:32 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 363.2 MiB)
25/11/18 06:11:32 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 6b05748f7bac:32771 (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:11:32 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/11/18 06:11:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/11/18 06:11:32 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/11/18 06:11:32 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:11:32 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.20.0.6:37257 (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:11:32 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.20.0.6:37257 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:11:32 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 103 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:11:32 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/11/18 06:11:32 INFO DAGScheduler: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.118 s
25/11/18 06:11:32 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:11:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/11/18 06:11:32 INFO DAGScheduler: Job 4 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.124943 s
25/11/18 06:11:32 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 1025.0 KiB, free 362.2 MiB)
25/11/18 06:11:32 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 250.0 B, free 362.2 MiB)
25/11/18 06:11:32 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 6b05748f7bac:32771 (size: 250.0 B, free: 366.1 MiB)
25/11/18 06:11:32 INFO SparkContext: Created broadcast 12 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:11:32 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:11:32 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:11:32 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:11:32 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 338.0 KiB, free 361.9 MiB)
25/11/18 06:11:32 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 361.8 MiB)
25/11/18 06:11:32 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 6b05748f7bac:32771 (size: 32.5 KiB, free: 366.0 MiB)
25/11/18 06:11:32 INFO SparkContext: Created broadcast 13 from parquet at NativeMethodAccessorImpl.java:0
25/11/18 06:11:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:11:32 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
25/11/18 06:11:32 INFO DAGScheduler: Got job 5 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:11:32 INFO DAGScheduler: Final stage: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0)
25/11/18 06:11:32 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:11:32 INFO DAGScheduler: Missing parents: List()
25/11/18 06:11:32 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:11:32 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 211.3 KiB, free 361.6 MiB)
25/11/18 06:11:32 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 76.0 KiB, free 361.5 MiB)
25/11/18 06:11:32 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 6b05748f7bac:32771 (size: 76.0 KiB, free: 366.0 MiB)
25/11/18 06:11:32 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/11/18 06:11:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:11:32 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/11/18 06:11:32 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:11:32 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.20.0.6:37257 (size: 76.0 KiB, free: 366.0 MiB)
25/11/18 06:11:32 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.20.0.6:37257 (size: 250.0 B, free: 366.0 MiB)
25/11/18 06:11:33 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.20.0.6:37257 (size: 32.5 KiB, free: 366.0 MiB)
25/11/18 06:11:34 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 1761 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:11:34 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/11/18 06:11:34 INFO DAGScheduler: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0) finished in 1.794 s
25/11/18 06:11:34 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:11:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/11/18 06:11:34 INFO DAGScheduler: Job 5 finished: parquet at NativeMethodAccessorImpl.java:0, took 1.798895 s
25/11/18 06:11:34 INFO FileFormatWriter: Start to commit write Job e0471e61-3c84-4599-90d4-b84a558ed095.
25/11/18 06:11:34 INFO FileFormatWriter: Write Job e0471e61-3c84-4599-90d4-b84a558ed095 committed. Elapsed time: 30 ms.
25/11/18 06:11:34 INFO FileFormatWriter: Finished processing stats for write job e0471e61-3c84-4599-90d4-b84a558ed095.
Job completed for 2025-01-01
25/11/18 06:11:34 INFO SparkUI: Stopped Spark web UI at http://6b05748f7bac:4040
25/11/18 06:11:34 INFO StandaloneSchedulerBackend: Shutting down all executors
25/11/18 06:11:34 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/11/18 06:11:34 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/11/18 06:11:34 INFO MemoryStore: MemoryStore cleared
25/11/18 06:11:34 INFO BlockManager: BlockManager stopped
25/11/18 06:11:34 INFO BlockManagerMaster: BlockManagerMaster stopped
25/11/18 06:11:34 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/11/18 06:11:34 INFO SparkContext: Successfully stopped SparkContext
25/11/18 06:11:35 INFO ShutdownHookManager: Shutdown hook called
25/11/18 06:11:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-2b18294b-0529-486b-a768-56c5a64641e5
25/11/18 06:11:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-147bdc87-5587-4203-97b9-57c96b63ef10/pyspark-2b926772-3697-4a20-b66f-e6e6e240cca3
25/11/18 06:11:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-147bdc87-5587-4203-97b9-57c96b63ef10
Job completed for 2025-01-01
/mnt/c/pyspark_stack/spark-apps/cron/run_sales.sh: 1: ---: not found
Triggering sales_etl_job.py for 2025-01-01...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/11/18 06:12:07 INFO SparkContext: Running Spark version 3.2.1
25/11/18 06:12:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/11/18 06:12:08 INFO ResourceUtils: ==============================================================
25/11/18 06:12:08 INFO ResourceUtils: No custom resources configured for spark.driver.
25/11/18 06:12:08 INFO ResourceUtils: ==============================================================
25/11/18 06:12:08 INFO SparkContext: Submitted application: SalesETLJob
25/11/18 06:12:08 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/11/18 06:12:08 INFO ResourceProfile: Limiting resource is cpu
25/11/18 06:12:08 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/11/18 06:12:08 INFO SecurityManager: Changing view acls to: spark
25/11/18 06:12:08 INFO SecurityManager: Changing modify acls to: spark
25/11/18 06:12:08 INFO SecurityManager: Changing view acls groups to: 
25/11/18 06:12:08 INFO SecurityManager: Changing modify acls groups to: 
25/11/18 06:12:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
25/11/18 06:12:08 INFO Utils: Successfully started service 'sparkDriver' on port 45051.
25/11/18 06:12:08 INFO SparkEnv: Registering MapOutputTracker
25/11/18 06:12:08 INFO SparkEnv: Registering BlockManagerMaster
25/11/18 06:12:08 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/11/18 06:12:08 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/11/18 06:12:08 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/11/18 06:12:08 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-093392a7-aef5-4b26-ad0b-b4b3d005d08c
25/11/18 06:12:09 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/11/18 06:12:09 INFO SparkEnv: Registering OutputCommitCoordinator
25/11/18 06:12:09 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/11/18 06:12:09 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://6b05748f7bac:4040
25/11/18 06:12:10 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/11/18 06:12:10 INFO TransportClientFactory: Successfully created connection to spark-master/172.20.0.3:7077 after 59 ms (0 ms spent in bootstraps)
25/11/18 06:12:10 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20251118061210-0012
25/11/18 06:12:10 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251118061210-0012/0 on worker-20251118055626-172.20.0.6-38023 (172.20.0.6:38023) with 12 core(s)
25/11/18 06:12:10 INFO StandaloneSchedulerBackend: Granted executor ID app-20251118061210-0012/0 on hostPort 172.20.0.6:38023 with 12 core(s), 1024.0 MiB RAM
25/11/18 06:12:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39439.
25/11/18 06:12:10 INFO NettyBlockTransferService: Server created on 6b05748f7bac:39439
25/11/18 06:12:10 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/11/18 06:12:10 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 6b05748f7bac, 39439, None)
25/11/18 06:12:10 INFO BlockManagerMasterEndpoint: Registering block manager 6b05748f7bac:39439 with 366.3 MiB RAM, BlockManagerId(driver, 6b05748f7bac, 39439, None)
25/11/18 06:12:10 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 6b05748f7bac, 39439, None)
25/11/18 06:12:10 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 6b05748f7bac, 39439, None)
25/11/18 06:12:10 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251118061210-0012/0 is now RUNNING
25/11/18 06:12:10 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/11/18 06:12:11 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/11/18 06:12:11 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
25/11/18 06:12:14 INFO InMemoryFileIndex: It took 201 ms to list leaf files for 1 paths.
25/11/18 06:12:14 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.6:43904) with ID 0,  ResourceProfileId 0
25/11/18 06:12:14 INFO InMemoryFileIndex: It took 13 ms to list leaf files for 1 paths.
25/11/18 06:12:15 INFO BlockManagerMasterEndpoint: Registering block manager 172.20.0.6:46823 with 366.3 MiB RAM, BlockManagerId(0, 172.20.0.6, 46823, None)
25/11/18 06:12:22 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:12:22 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/11/18 06:12:22 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:12:23 INFO CodeGenerator: Code generated in 331.211429 ms
25/11/18 06:12:23 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 338.3 KiB, free 366.0 MiB)
25/11/18 06:12:23 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.9 MiB)
25/11/18 06:12:23 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 6b05748f7bac:39439 (size: 32.4 KiB, free: 366.3 MiB)
25/11/18 06:12:23 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:12:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:12:24 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/11/18 06:12:24 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:12:24 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/11/18 06:12:24 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:12:24 INFO DAGScheduler: Missing parents: List()
25/11/18 06:12:24 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:12:24 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/11/18 06:12:24 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/11/18 06:12:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 6b05748f7bac:39439 (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:12:24 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/11/18 06:12:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:12:24 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/11/18 06:12:24 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:12:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.0.6:46823 (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:12:26 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.0.6:46823 (size: 32.4 KiB, free: 366.3 MiB)
25/11/18 06:12:28 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 3819 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:12:28 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/11/18 06:12:28 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 3.993 s
25/11/18 06:12:28 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:12:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/11/18 06:12:28 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 4.061578 s
25/11/18 06:12:28 INFO CodeGenerator: Code generated in 20.119838 ms
25/11/18 06:12:28 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:12:28 INFO FileSourceStrategy: Post-Scan Filters: 
25/11/18 06:12:28 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:12:28 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 338.3 KiB, free 365.6 MiB)
25/11/18 06:12:28 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.6 MiB)
25/11/18 06:12:28 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 6b05748f7bac:39439 (size: 32.4 KiB, free: 366.2 MiB)
25/11/18 06:12:28 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:12:28 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:12:28 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
25/11/18 06:12:28 INFO InMemoryFileIndex: It took 5 ms to list leaf files for 1 paths.
25/11/18 06:12:28 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:12:28 INFO FileSourceStrategy: Post-Scan Filters: 
25/11/18 06:12:28 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:12:28 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 338.1 KiB, free 365.2 MiB)
25/11/18 06:12:28 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.2 MiB)
25/11/18 06:12:28 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 6b05748f7bac:39439 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:12:28 INFO SparkContext: Created broadcast 3 from json at NativeMethodAccessorImpl.java:0
25/11/18 06:12:28 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:12:28 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
25/11/18 06:12:28 INFO DAGScheduler: Got job 1 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:12:28 INFO DAGScheduler: Final stage: ResultStage 1 (json at NativeMethodAccessorImpl.java:0)
25/11/18 06:12:28 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:12:28 INFO DAGScheduler: Missing parents: List()
25/11/18 06:12:28 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:12:28 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 12.4 KiB, free 365.2 MiB)
25/11/18 06:12:28 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 365.2 MiB)
25/11/18 06:12:28 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 6b05748f7bac:39439 (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:12:28 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/11/18 06:12:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:12:28 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/11/18 06:12:28 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:12:28 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.0.6:46823 (size: 6.5 KiB, free: 366.3 MiB)
25/11/18 06:12:28 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.0.6:46823 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:12:29 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 313 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:12:29 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/11/18 06:12:29 INFO DAGScheduler: ResultStage 1 (json at NativeMethodAccessorImpl.java:0) finished in 0.400 s
25/11/18 06:12:29 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:12:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/11/18 06:12:29 INFO DAGScheduler: Job 1 finished: json at NativeMethodAccessorImpl.java:0, took 0.412838 s
25/11/18 06:12:29 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/11/18 06:12:29 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/11/18 06:12:29 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/11/18 06:12:29 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:12:29 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:12:29 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:12:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:12:30 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:12:30 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
25/11/18 06:12:30 INFO CodeGenerator: Code generated in 34.851787 ms
25/11/18 06:12:30 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 338.2 KiB, free 364.8 MiB)
25/11/18 06:12:30 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 364.8 MiB)
25/11/18 06:12:30 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 6b05748f7bac:39439 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:12:30 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:12:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:12:30 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:12:30 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/11/18 06:12:30 INFO DAGScheduler: Final stage: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/11/18 06:12:30 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:12:30 INFO DAGScheduler: Missing parents: List()
25/11/18 06:12:30 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/11/18 06:12:30 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 14.4 KiB, free 364.8 MiB)
25/11/18 06:12:30 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 364.8 MiB)
25/11/18 06:12:30 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 6b05748f7bac:39439 (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:12:30 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/11/18 06:12:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/11/18 06:12:30 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/11/18 06:12:30 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:12:30 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.20.0.6:46823 (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:12:30 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.20.0.6:46823 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:12:30 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 345 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:12:30 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/11/18 06:12:30 INFO DAGScheduler: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.374 s
25/11/18 06:12:30 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:12:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/11/18 06:12:30 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.383440 s
25/11/18 06:12:30 INFO CodeGenerator: Code generated in 15.255915 ms
25/11/18 06:12:30 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 1025.0 KiB, free 363.8 MiB)
25/11/18 06:12:30 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 6b05748f7bac:39439 in memory (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:12:30 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 250.0 B, free 364.2 MiB)
25/11/18 06:12:30 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 6b05748f7bac:39439 (size: 250.0 B, free: 366.2 MiB)
25/11/18 06:12:30 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:12:30 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.20.0.6:46823 in memory (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:12:30 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 6b05748f7bac:39439 in memory (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:12:30 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:12:30 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:12:30 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:12:30 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.20.0.6:46823 in memory (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:12:30 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 6b05748f7bac:39439 in memory (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:12:30 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.20.0.6:46823 in memory (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:12:30 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 6b05748f7bac:39439 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/11/18 06:12:30 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.0.6:46823 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/11/18 06:12:31 INFO CodeGenerator: Code generated in 31.846656 ms
25/11/18 06:12:31 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 338.0 KiB, free 363.9 MiB)
25/11/18 06:12:31 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 363.9 MiB)
25/11/18 06:12:31 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 6b05748f7bac:39439 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:12:31 INFO SparkContext: Created broadcast 8 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:12:31 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:12:31 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/11/18 06:12:31 INFO DAGScheduler: Got job 3 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:12:31 INFO DAGScheduler: Final stage: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0)
25/11/18 06:12:31 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:12:31 INFO DAGScheduler: Missing parents: List()
25/11/18 06:12:31 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:12:31 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 211.3 KiB, free 363.6 MiB)
25/11/18 06:12:31 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 75.9 KiB, free 363.6 MiB)
25/11/18 06:12:31 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 6b05748f7bac:39439 (size: 75.9 KiB, free: 366.1 MiB)
25/11/18 06:12:31 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/11/18 06:12:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:12:31 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/11/18 06:12:31 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:12:31 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.20.0.6:46823 (size: 75.9 KiB, free: 366.2 MiB)
25/11/18 06:12:31 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.20.0.6:46823 (size: 250.0 B, free: 366.2 MiB)
25/11/18 06:12:31 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.20.0.6:46823 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:12:32 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 1182 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:12:32 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/11/18 06:12:32 INFO DAGScheduler: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0) finished in 1.233 s
25/11/18 06:12:32 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:12:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/11/18 06:12:32 INFO DAGScheduler: Job 3 finished: csv at NativeMethodAccessorImpl.java:0, took 1.242873 s
25/11/18 06:12:32 INFO FileFormatWriter: Start to commit write Job 62ec993a-4a42-43d8-85f0-54a56db027b4.
25/11/18 06:12:32 INFO FileFormatWriter: Write Job 62ec993a-4a42-43d8-85f0-54a56db027b4 committed. Elapsed time: 159 ms.
25/11/18 06:12:32 INFO FileFormatWriter: Finished processing stats for write job 62ec993a-4a42-43d8-85f0-54a56db027b4.
25/11/18 06:12:32 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/11/18 06:12:32 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/11/18 06:12:32 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/11/18 06:12:32 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:12:32 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:12:32 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:12:32 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:12:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:12:32 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:12:32 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:12:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:12:32 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:12:32 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:12:32 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 338.2 KiB, free 363.2 MiB)
25/11/18 06:12:32 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 363.2 MiB)
25/11/18 06:12:32 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 6b05748f7bac:39439 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:12:32 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:12:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:12:32 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:12:32 INFO DAGScheduler: Got job 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/11/18 06:12:32 INFO DAGScheduler: Final stage: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/11/18 06:12:32 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:12:32 INFO DAGScheduler: Missing parents: List()
25/11/18 06:12:32 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/11/18 06:12:32 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 14.4 KiB, free 363.2 MiB)
25/11/18 06:12:32 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 363.2 MiB)
25/11/18 06:12:32 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 6b05748f7bac:39439 (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:12:32 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/11/18 06:12:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/11/18 06:12:32 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/11/18 06:12:32 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:12:32 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.20.0.6:46823 (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:12:32 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.20.0.6:46823 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:12:33 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 159 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:12:33 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/11/18 06:12:33 INFO DAGScheduler: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.179 s
25/11/18 06:12:33 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:12:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/11/18 06:12:33 INFO DAGScheduler: Job 4 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.189170 s
25/11/18 06:12:33 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 1025.0 KiB, free 362.2 MiB)
25/11/18 06:12:33 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 250.0 B, free 362.2 MiB)
25/11/18 06:12:33 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 6b05748f7bac:39439 (size: 250.0 B, free: 366.1 MiB)
25/11/18 06:12:33 INFO SparkContext: Created broadcast 12 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:12:33 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:12:33 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:12:33 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:12:33 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 338.0 KiB, free 361.9 MiB)
25/11/18 06:12:33 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 361.8 MiB)
25/11/18 06:12:33 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 6b05748f7bac:39439 (size: 32.5 KiB, free: 366.0 MiB)
25/11/18 06:12:33 INFO SparkContext: Created broadcast 13 from parquet at NativeMethodAccessorImpl.java:0
25/11/18 06:12:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:12:33 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
25/11/18 06:12:33 INFO DAGScheduler: Got job 5 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:12:33 INFO DAGScheduler: Final stage: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0)
25/11/18 06:12:33 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:12:33 INFO DAGScheduler: Missing parents: List()
25/11/18 06:12:33 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:12:33 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 211.3 KiB, free 361.6 MiB)
25/11/18 06:12:33 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 76.0 KiB, free 361.5 MiB)
25/11/18 06:12:33 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 6b05748f7bac:39439 (size: 76.0 KiB, free: 366.0 MiB)
25/11/18 06:12:33 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/11/18 06:12:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:12:33 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/11/18 06:12:33 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:12:33 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.20.0.6:46823 (size: 76.0 KiB, free: 366.0 MiB)
25/11/18 06:12:33 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.20.0.6:46823 (size: 250.0 B, free: 366.0 MiB)
25/11/18 06:12:33 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.20.0.6:46823 (size: 32.5 KiB, free: 366.0 MiB)
25/11/18 06:12:34 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 1592 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:12:34 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/11/18 06:12:34 INFO DAGScheduler: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0) finished in 1.626 s
25/11/18 06:12:34 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:12:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/11/18 06:12:34 INFO DAGScheduler: Job 5 finished: parquet at NativeMethodAccessorImpl.java:0, took 1.632019 s
25/11/18 06:12:34 INFO FileFormatWriter: Start to commit write Job 605627ee-a0fe-4ab0-b916-f8d4ea02e4e1.
25/11/18 06:12:34 INFO FileFormatWriter: Write Job 605627ee-a0fe-4ab0-b916-f8d4ea02e4e1 committed. Elapsed time: 36 ms.
25/11/18 06:12:34 INFO FileFormatWriter: Finished processing stats for write job 605627ee-a0fe-4ab0-b916-f8d4ea02e4e1.
Job completed for 2025-01-01
25/11/18 06:12:34 INFO SparkUI: Stopped Spark web UI at http://6b05748f7bac:4040
25/11/18 06:12:34 INFO StandaloneSchedulerBackend: Shutting down all executors
25/11/18 06:12:34 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/11/18 06:12:34 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/11/18 06:12:34 INFO MemoryStore: MemoryStore cleared
25/11/18 06:12:34 INFO BlockManager: BlockManager stopped
25/11/18 06:12:34 INFO BlockManagerMaster: BlockManagerMaster stopped
25/11/18 06:12:34 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/11/18 06:12:34 INFO SparkContext: Successfully stopped SparkContext
25/11/18 06:12:35 INFO ShutdownHookManager: Shutdown hook called
25/11/18 06:12:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-d27bc1c4-5446-4858-8eed-aa2a3ae61d14
25/11/18 06:12:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-6999f792-ee3a-4a0d-82b7-58b834289fc2/pyspark-e0d35fe1-020d-4dcd-b635-55af1daa824a
25/11/18 06:12:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-6999f792-ee3a-4a0d-82b7-58b834289fc2
Job completed for 2025-01-01
/mnt/c/pyspark_stack/spark-apps/cron/run_sales.sh: 1: ---: not found
Triggering sales_etl_job.py for 2025-01-01...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/11/18 06:13:08 INFO SparkContext: Running Spark version 3.2.1
25/11/18 06:13:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/11/18 06:13:09 INFO ResourceUtils: ==============================================================
25/11/18 06:13:09 INFO ResourceUtils: No custom resources configured for spark.driver.
25/11/18 06:13:09 INFO ResourceUtils: ==============================================================
25/11/18 06:13:09 INFO SparkContext: Submitted application: SalesETLJob
25/11/18 06:13:09 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/11/18 06:13:09 INFO ResourceProfile: Limiting resource is cpu
25/11/18 06:13:09 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/11/18 06:13:09 INFO SecurityManager: Changing view acls to: spark
25/11/18 06:13:09 INFO SecurityManager: Changing modify acls to: spark
25/11/18 06:13:09 INFO SecurityManager: Changing view acls groups to: 
25/11/18 06:13:09 INFO SecurityManager: Changing modify acls groups to: 
25/11/18 06:13:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
25/11/18 06:13:09 INFO Utils: Successfully started service 'sparkDriver' on port 43277.
25/11/18 06:13:09 INFO SparkEnv: Registering MapOutputTracker
25/11/18 06:13:09 INFO SparkEnv: Registering BlockManagerMaster
25/11/18 06:13:09 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/11/18 06:13:09 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/11/18 06:13:09 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/11/18 06:13:09 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-cd44bf9d-9063-41e1-a502-ecd16ecffa15
25/11/18 06:13:09 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/11/18 06:13:10 INFO SparkEnv: Registering OutputCommitCoordinator
25/11/18 06:13:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/11/18 06:13:10 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://6b05748f7bac:4040
25/11/18 06:13:10 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/11/18 06:13:10 INFO TransportClientFactory: Successfully created connection to spark-master/172.20.0.3:7077 after 62 ms (0 ms spent in bootstraps)
25/11/18 06:13:11 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20251118061311-0013
25/11/18 06:13:11 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251118061311-0013/0 on worker-20251118055626-172.20.0.6-38023 (172.20.0.6:38023) with 12 core(s)
25/11/18 06:13:11 INFO StandaloneSchedulerBackend: Granted executor ID app-20251118061311-0013/0 on hostPort 172.20.0.6:38023 with 12 core(s), 1024.0 MiB RAM
25/11/18 06:13:11 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36959.
25/11/18 06:13:11 INFO NettyBlockTransferService: Server created on 6b05748f7bac:36959
25/11/18 06:13:11 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/11/18 06:13:11 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 6b05748f7bac, 36959, None)
25/11/18 06:13:11 INFO BlockManagerMasterEndpoint: Registering block manager 6b05748f7bac:36959 with 366.3 MiB RAM, BlockManagerId(driver, 6b05748f7bac, 36959, None)
25/11/18 06:13:11 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 6b05748f7bac, 36959, None)
25/11/18 06:13:11 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 6b05748f7bac, 36959, None)
25/11/18 06:13:11 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251118061311-0013/0 is now RUNNING
25/11/18 06:13:11 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/11/18 06:13:12 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/11/18 06:13:12 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
25/11/18 06:13:15 INFO InMemoryFileIndex: It took 224 ms to list leaf files for 1 paths.
25/11/18 06:13:15 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.6:58168) with ID 0,  ResourceProfileId 0
25/11/18 06:13:15 INFO InMemoryFileIndex: It took 18 ms to list leaf files for 1 paths.
25/11/18 06:13:15 INFO BlockManagerMasterEndpoint: Registering block manager 172.20.0.6:44577 with 366.3 MiB RAM, BlockManagerId(0, 172.20.0.6, 44577, None)
25/11/18 06:13:20 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:13:20 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/11/18 06:13:20 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:13:21 INFO CodeGenerator: Code generated in 252.731876 ms
25/11/18 06:13:21 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 338.3 KiB, free 366.0 MiB)
25/11/18 06:13:21 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.9 MiB)
25/11/18 06:13:21 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 6b05748f7bac:36959 (size: 32.4 KiB, free: 366.3 MiB)
25/11/18 06:13:21 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:13:21 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:13:24 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/11/18 06:13:24 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:13:24 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/11/18 06:13:24 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:13:24 INFO DAGScheduler: Missing parents: List()
25/11/18 06:13:24 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:13:24 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/11/18 06:13:24 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/11/18 06:13:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 6b05748f7bac:36959 (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:13:24 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/11/18 06:13:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:13:25 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/11/18 06:13:25 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:13:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.0.6:44577 (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:13:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.0.6:44577 (size: 32.4 KiB, free: 366.3 MiB)
25/11/18 06:13:29 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4209 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:13:29 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/11/18 06:13:29 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 4.359 s
25/11/18 06:13:29 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:13:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/11/18 06:13:29 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 4.425086 s
25/11/18 06:13:29 INFO CodeGenerator: Code generated in 22.458919 ms
25/11/18 06:13:29 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:13:29 INFO FileSourceStrategy: Post-Scan Filters: 
25/11/18 06:13:29 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:13:29 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 338.3 KiB, free 365.6 MiB)
25/11/18 06:13:29 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.6 MiB)
25/11/18 06:13:29 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 6b05748f7bac:36959 (size: 32.4 KiB, free: 366.2 MiB)
25/11/18 06:13:29 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:13:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:13:29 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
25/11/18 06:13:29 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
25/11/18 06:13:29 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:13:29 INFO FileSourceStrategy: Post-Scan Filters: 
25/11/18 06:13:29 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:13:29 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 338.1 KiB, free 365.2 MiB)
25/11/18 06:13:29 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.2 MiB)
25/11/18 06:13:29 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 6b05748f7bac:36959 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:13:29 INFO SparkContext: Created broadcast 3 from json at NativeMethodAccessorImpl.java:0
25/11/18 06:13:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:13:29 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
25/11/18 06:13:29 INFO DAGScheduler: Got job 1 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:13:29 INFO DAGScheduler: Final stage: ResultStage 1 (json at NativeMethodAccessorImpl.java:0)
25/11/18 06:13:29 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:13:29 INFO DAGScheduler: Missing parents: List()
25/11/18 06:13:29 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:13:29 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 12.4 KiB, free 365.2 MiB)
25/11/18 06:13:29 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 365.2 MiB)
25/11/18 06:13:29 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 6b05748f7bac:36959 (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:13:29 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/11/18 06:13:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:13:29 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/11/18 06:13:29 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:13:29 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.0.6:44577 (size: 6.5 KiB, free: 366.3 MiB)
25/11/18 06:13:29 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.0.6:44577 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:13:30 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 246 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:13:30 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/11/18 06:13:30 INFO DAGScheduler: ResultStage 1 (json at NativeMethodAccessorImpl.java:0) finished in 0.287 s
25/11/18 06:13:30 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:13:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/11/18 06:13:30 INFO DAGScheduler: Job 1 finished: json at NativeMethodAccessorImpl.java:0, took 0.298976 s
25/11/18 06:13:30 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/11/18 06:13:30 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/11/18 06:13:30 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/11/18 06:13:30 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:13:30 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:13:30 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:13:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:13:31 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:13:31 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
25/11/18 06:13:31 INFO CodeGenerator: Code generated in 35.261216 ms
25/11/18 06:13:31 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 338.2 KiB, free 364.8 MiB)
25/11/18 06:13:31 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 364.8 MiB)
25/11/18 06:13:31 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 6b05748f7bac:36959 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:13:31 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:13:31 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:13:31 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:13:31 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/11/18 06:13:31 INFO DAGScheduler: Final stage: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/11/18 06:13:31 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:13:31 INFO DAGScheduler: Missing parents: List()
25/11/18 06:13:31 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/11/18 06:13:31 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 14.4 KiB, free 364.8 MiB)
25/11/18 06:13:31 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 364.8 MiB)
25/11/18 06:13:31 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 6b05748f7bac:36959 (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:13:31 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/11/18 06:13:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/11/18 06:13:31 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/11/18 06:13:31 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:13:31 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.20.0.6:44577 (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:13:31 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.20.0.6:44577 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:13:31 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 327 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:13:31 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/11/18 06:13:31 INFO DAGScheduler: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.355 s
25/11/18 06:13:31 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:13:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/11/18 06:13:31 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.361909 s
25/11/18 06:13:31 INFO CodeGenerator: Code generated in 16.808361 ms
25/11/18 06:13:31 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 1025.0 KiB, free 363.8 MiB)
25/11/18 06:13:31 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 250.0 B, free 363.8 MiB)
25/11/18 06:13:31 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 6b05748f7bac:36959 (size: 250.0 B, free: 366.2 MiB)
25/11/18 06:13:31 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:13:31 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:13:31 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:13:31 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:13:32 INFO CodeGenerator: Code generated in 40.883409 ms
25/11/18 06:13:32 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 338.0 KiB, free 363.5 MiB)
25/11/18 06:13:32 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 363.4 MiB)
25/11/18 06:13:32 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 6b05748f7bac:36959 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:13:32 INFO SparkContext: Created broadcast 8 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:13:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:13:32 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 6b05748f7bac:36959 in memory (size: 5.8 KiB, free: 366.1 MiB)
25/11/18 06:13:32 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/11/18 06:13:32 INFO DAGScheduler: Got job 3 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:13:32 INFO DAGScheduler: Final stage: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0)
25/11/18 06:13:32 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:13:32 INFO DAGScheduler: Missing parents: List()
25/11/18 06:13:32 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:13:32 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.0.6:44577 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/11/18 06:13:32 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 6b05748f7bac:36959 in memory (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:13:32 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.20.0.6:44577 in memory (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:13:32 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 211.3 KiB, free 363.3 MiB)
25/11/18 06:13:32 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 75.9 KiB, free 363.2 MiB)
25/11/18 06:13:32 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 6b05748f7bac:36959 (size: 75.9 KiB, free: 366.1 MiB)
25/11/18 06:13:32 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/11/18 06:13:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:13:32 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/11/18 06:13:32 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 6b05748f7bac:36959 in memory (size: 6.5 KiB, free: 366.1 MiB)
25/11/18 06:13:32 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:13:32 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.20.0.6:44577 in memory (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:13:32 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 6b05748f7bac:36959 in memory (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:13:32 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.20.0.6:44577 (size: 75.9 KiB, free: 366.1 MiB)
25/11/18 06:13:32 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.20.0.6:44577 in memory (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:13:32 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.20.0.6:44577 (size: 250.0 B, free: 366.2 MiB)
25/11/18 06:13:32 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.20.0.6:44577 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:13:33 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 622 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:13:33 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/11/18 06:13:33 INFO DAGScheduler: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0) finished in 0.708 s
25/11/18 06:13:33 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:13:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/11/18 06:13:33 INFO DAGScheduler: Job 3 finished: csv at NativeMethodAccessorImpl.java:0, took 0.721481 s
25/11/18 06:13:33 INFO FileFormatWriter: Start to commit write Job 1099c1ad-3d49-4ec6-ab32-d13344c63376.
25/11/18 06:13:33 INFO FileFormatWriter: Write Job 1099c1ad-3d49-4ec6-ab32-d13344c63376 committed. Elapsed time: 81 ms.
25/11/18 06:13:33 INFO FileFormatWriter: Finished processing stats for write job 1099c1ad-3d49-4ec6-ab32-d13344c63376.
25/11/18 06:13:33 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/11/18 06:13:33 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/11/18 06:13:33 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/11/18 06:13:33 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:13:33 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:13:33 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:13:33 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:13:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:13:33 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:13:33 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:13:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:13:33 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:13:33 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:13:33 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 338.2 KiB, free 363.2 MiB)
25/11/18 06:13:33 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 363.2 MiB)
25/11/18 06:13:33 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 6b05748f7bac:36959 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:13:33 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:13:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:13:33 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:13:33 INFO DAGScheduler: Got job 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/11/18 06:13:33 INFO DAGScheduler: Final stage: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/11/18 06:13:33 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:13:33 INFO DAGScheduler: Missing parents: List()
25/11/18 06:13:33 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/11/18 06:13:33 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 14.4 KiB, free 363.2 MiB)
25/11/18 06:13:33 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 363.2 MiB)
25/11/18 06:13:33 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 6b05748f7bac:36959 (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:13:33 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/11/18 06:13:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/11/18 06:13:33 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/11/18 06:13:33 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:13:33 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.20.0.6:44577 (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:13:33 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.20.0.6:44577 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:13:33 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 143 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:13:33 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/11/18 06:13:33 INFO DAGScheduler: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.164 s
25/11/18 06:13:33 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:13:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/11/18 06:13:33 INFO DAGScheduler: Job 4 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.173408 s
25/11/18 06:13:33 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 1025.0 KiB, free 362.2 MiB)
25/11/18 06:13:33 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 250.0 B, free 362.2 MiB)
25/11/18 06:13:33 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 6b05748f7bac:36959 (size: 250.0 B, free: 366.1 MiB)
25/11/18 06:13:33 INFO SparkContext: Created broadcast 12 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:13:33 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:13:33 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:13:33 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:13:33 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 338.0 KiB, free 361.9 MiB)
25/11/18 06:13:33 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 361.8 MiB)
25/11/18 06:13:33 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 6b05748f7bac:36959 (size: 32.5 KiB, free: 366.0 MiB)
25/11/18 06:13:33 INFO SparkContext: Created broadcast 13 from parquet at NativeMethodAccessorImpl.java:0
25/11/18 06:13:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:13:33 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
25/11/18 06:13:33 INFO DAGScheduler: Got job 5 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:13:33 INFO DAGScheduler: Final stage: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0)
25/11/18 06:13:33 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:13:33 INFO DAGScheduler: Missing parents: List()
25/11/18 06:13:33 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:13:33 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 211.3 KiB, free 361.6 MiB)
25/11/18 06:13:33 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 76.0 KiB, free 361.5 MiB)
25/11/18 06:13:33 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 6b05748f7bac:36959 (size: 76.0 KiB, free: 366.0 MiB)
25/11/18 06:13:33 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/11/18 06:13:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:13:33 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/11/18 06:13:33 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:13:33 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.20.0.6:44577 (size: 76.0 KiB, free: 366.0 MiB)
25/11/18 06:13:33 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.20.0.6:44577 (size: 250.0 B, free: 366.0 MiB)
25/11/18 06:13:34 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.20.0.6:44577 (size: 32.5 KiB, free: 366.0 MiB)
25/11/18 06:13:35 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 1546 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:13:35 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/11/18 06:13:35 INFO DAGScheduler: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0) finished in 1.582 s
25/11/18 06:13:35 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:13:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/11/18 06:13:35 INFO DAGScheduler: Job 5 finished: parquet at NativeMethodAccessorImpl.java:0, took 1.589802 s
25/11/18 06:13:35 INFO FileFormatWriter: Start to commit write Job 858c44a5-dd48-4e9e-a618-6c3c1a0afa0f.
25/11/18 06:13:35 INFO FileFormatWriter: Write Job 858c44a5-dd48-4e9e-a618-6c3c1a0afa0f committed. Elapsed time: 33 ms.
25/11/18 06:13:35 INFO FileFormatWriter: Finished processing stats for write job 858c44a5-dd48-4e9e-a618-6c3c1a0afa0f.
Job completed for 2025-01-01
25/11/18 06:13:35 INFO SparkUI: Stopped Spark web UI at http://6b05748f7bac:4040
25/11/18 06:13:35 INFO StandaloneSchedulerBackend: Shutting down all executors
25/11/18 06:13:35 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/11/18 06:13:35 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/11/18 06:13:35 INFO MemoryStore: MemoryStore cleared
25/11/18 06:13:35 INFO BlockManager: BlockManager stopped
25/11/18 06:13:35 INFO BlockManagerMaster: BlockManagerMaster stopped
25/11/18 06:13:35 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/11/18 06:13:35 INFO SparkContext: Successfully stopped SparkContext
25/11/18 06:13:35 INFO ShutdownHookManager: Shutdown hook called
25/11/18 06:13:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-742be1af-39e2-4c80-bc1b-8828f71f99ba
25/11/18 06:13:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-f4c7116b-36b3-4f5e-8c57-bed3b341c155
25/11/18 06:13:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-742be1af-39e2-4c80-bc1b-8828f71f99ba/pyspark-ef5d90d6-0290-4900-95cc-b7a9d48d1c3a
Job completed for 2025-01-01
/mnt/c/pyspark_stack/spark-apps/cron/run_sales.sh: 1: ---: not found
Triggering sales_etl_job.py for 2025-01-01...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/11/18 06:14:08 INFO SparkContext: Running Spark version 3.2.1
25/11/18 06:14:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/11/18 06:14:08 INFO ResourceUtils: ==============================================================
25/11/18 06:14:08 INFO ResourceUtils: No custom resources configured for spark.driver.
25/11/18 06:14:08 INFO ResourceUtils: ==============================================================
25/11/18 06:14:08 INFO SparkContext: Submitted application: SalesETLJob
25/11/18 06:14:08 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/11/18 06:14:08 INFO ResourceProfile: Limiting resource is cpu
25/11/18 06:14:08 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/11/18 06:14:09 INFO SecurityManager: Changing view acls to: spark
25/11/18 06:14:09 INFO SecurityManager: Changing modify acls to: spark
25/11/18 06:14:09 INFO SecurityManager: Changing view acls groups to: 
25/11/18 06:14:09 INFO SecurityManager: Changing modify acls groups to: 
25/11/18 06:14:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
25/11/18 06:14:09 INFO Utils: Successfully started service 'sparkDriver' on port 34097.
25/11/18 06:14:09 INFO SparkEnv: Registering MapOutputTracker
25/11/18 06:14:09 INFO SparkEnv: Registering BlockManagerMaster
25/11/18 06:14:09 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/11/18 06:14:09 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/11/18 06:14:09 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/11/18 06:14:09 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2121ce9e-68cd-41f0-b0e0-3fe50adfada1
25/11/18 06:14:09 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/11/18 06:14:09 INFO SparkEnv: Registering OutputCommitCoordinator
25/11/18 06:14:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/11/18 06:14:10 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://6b05748f7bac:4040
25/11/18 06:14:10 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/11/18 06:14:10 INFO TransportClientFactory: Successfully created connection to spark-master/172.20.0.3:7077 after 56 ms (0 ms spent in bootstraps)
25/11/18 06:14:10 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20251118061410-0014
25/11/18 06:14:10 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251118061410-0014/0 on worker-20251118055626-172.20.0.6-38023 (172.20.0.6:38023) with 12 core(s)
25/11/18 06:14:10 INFO StandaloneSchedulerBackend: Granted executor ID app-20251118061410-0014/0 on hostPort 172.20.0.6:38023 with 12 core(s), 1024.0 MiB RAM
25/11/18 06:14:11 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38527.
25/11/18 06:14:11 INFO NettyBlockTransferService: Server created on 6b05748f7bac:38527
25/11/18 06:14:11 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/11/18 06:14:11 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 6b05748f7bac, 38527, None)
25/11/18 06:14:11 INFO BlockManagerMasterEndpoint: Registering block manager 6b05748f7bac:38527 with 366.3 MiB RAM, BlockManagerId(driver, 6b05748f7bac, 38527, None)
25/11/18 06:14:11 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 6b05748f7bac, 38527, None)
25/11/18 06:14:11 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 6b05748f7bac, 38527, None)
25/11/18 06:14:11 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251118061410-0014/0 is now RUNNING
25/11/18 06:14:11 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/11/18 06:14:12 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/11/18 06:14:12 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
25/11/18 06:14:15 INFO InMemoryFileIndex: It took 247 ms to list leaf files for 1 paths.
25/11/18 06:14:15 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.6:35168) with ID 0,  ResourceProfileId 0
25/11/18 06:14:15 INFO InMemoryFileIndex: It took 14 ms to list leaf files for 1 paths.
25/11/18 06:14:15 INFO BlockManagerMasterEndpoint: Registering block manager 172.20.0.6:37885 with 366.3 MiB RAM, BlockManagerId(0, 172.20.0.6, 37885, None)
25/11/18 06:14:20 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:14:20 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/11/18 06:14:20 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:14:21 INFO CodeGenerator: Code generated in 274.947802 ms
25/11/18 06:14:21 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 338.3 KiB, free 366.0 MiB)
25/11/18 06:14:21 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.9 MiB)
25/11/18 06:14:21 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 6b05748f7bac:38527 (size: 32.4 KiB, free: 366.3 MiB)
25/11/18 06:14:21 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:14:21 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:14:21 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/11/18 06:14:22 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:14:22 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/11/18 06:14:22 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:14:22 INFO DAGScheduler: Missing parents: List()
25/11/18 06:14:22 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:14:22 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/11/18 06:14:22 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/11/18 06:14:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 6b05748f7bac:38527 (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:14:22 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/11/18 06:14:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:14:22 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/11/18 06:14:22 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:14:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.0.6:37885 (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:14:24 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.0.6:37885 (size: 32.4 KiB, free: 366.3 MiB)
25/11/18 06:14:26 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4284 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:14:26 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/11/18 06:14:26 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 4.429 s
25/11/18 06:14:26 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:14:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/11/18 06:14:26 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 4.505226 s
25/11/18 06:14:26 INFO CodeGenerator: Code generated in 21.101392 ms
25/11/18 06:14:26 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:14:26 INFO FileSourceStrategy: Post-Scan Filters: 
25/11/18 06:14:26 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:14:26 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 338.3 KiB, free 365.6 MiB)
25/11/18 06:14:26 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.6 MiB)
25/11/18 06:14:26 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 6b05748f7bac:38527 (size: 32.4 KiB, free: 366.2 MiB)
25/11/18 06:14:26 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:14:26 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:14:26 INFO InMemoryFileIndex: It took 9 ms to list leaf files for 1 paths.
25/11/18 06:14:26 INFO InMemoryFileIndex: It took 5 ms to list leaf files for 1 paths.
25/11/18 06:14:26 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:14:26 INFO FileSourceStrategy: Post-Scan Filters: 
25/11/18 06:14:26 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:14:26 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 338.1 KiB, free 365.2 MiB)
25/11/18 06:14:26 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.2 MiB)
25/11/18 06:14:26 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 6b05748f7bac:38527 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:14:26 INFO SparkContext: Created broadcast 3 from json at NativeMethodAccessorImpl.java:0
25/11/18 06:14:26 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:14:27 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
25/11/18 06:14:27 INFO DAGScheduler: Got job 1 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:14:27 INFO DAGScheduler: Final stage: ResultStage 1 (json at NativeMethodAccessorImpl.java:0)
25/11/18 06:14:27 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:14:27 INFO DAGScheduler: Missing parents: List()
25/11/18 06:14:27 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:14:27 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 12.4 KiB, free 365.2 MiB)
25/11/18 06:14:27 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 365.2 MiB)
25/11/18 06:14:27 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 6b05748f7bac:38527 (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:14:27 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/11/18 06:14:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:14:27 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/11/18 06:14:27 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:14:27 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.0.6:37885 (size: 6.5 KiB, free: 366.3 MiB)
25/11/18 06:14:27 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.0.6:37885 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:14:27 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 247 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:14:27 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/11/18 06:14:27 INFO DAGScheduler: ResultStage 1 (json at NativeMethodAccessorImpl.java:0) finished in 0.285 s
25/11/18 06:14:27 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:14:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/11/18 06:14:27 INFO DAGScheduler: Job 1 finished: json at NativeMethodAccessorImpl.java:0, took 0.296837 s
25/11/18 06:14:30 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/11/18 06:14:30 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/11/18 06:14:30 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/11/18 06:14:30 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:14:30 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:14:30 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:14:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:14:31 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:14:31 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
25/11/18 06:14:31 INFO CodeGenerator: Code generated in 41.375453 ms
25/11/18 06:14:31 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 338.2 KiB, free 364.8 MiB)
25/11/18 06:14:31 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 364.8 MiB)
25/11/18 06:14:31 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 6b05748f7bac:38527 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:14:31 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:14:31 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:14:31 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:14:31 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/11/18 06:14:31 INFO DAGScheduler: Final stage: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/11/18 06:14:31 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:14:31 INFO DAGScheduler: Missing parents: List()
25/11/18 06:14:31 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/11/18 06:14:31 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 14.4 KiB, free 364.8 MiB)
25/11/18 06:14:31 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 364.8 MiB)
25/11/18 06:14:31 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 6b05748f7bac:38527 (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:14:31 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/11/18 06:14:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/11/18 06:14:31 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/11/18 06:14:31 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:14:31 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.20.0.6:37885 (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:14:31 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.20.0.6:37885 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:14:31 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 320 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:14:31 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/11/18 06:14:31 INFO DAGScheduler: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.347 s
25/11/18 06:14:31 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:14:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/11/18 06:14:31 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.356816 s
25/11/18 06:14:31 INFO CodeGenerator: Code generated in 21.82102 ms
25/11/18 06:14:31 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 1025.0 KiB, free 363.8 MiB)
25/11/18 06:14:31 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 250.0 B, free 363.8 MiB)
25/11/18 06:14:31 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 6b05748f7bac:38527 (size: 250.0 B, free: 366.2 MiB)
25/11/18 06:14:31 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:14:31 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:14:31 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:14:31 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:14:31 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 6b05748f7bac:38527 in memory (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:14:31 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.20.0.6:37885 in memory (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:14:31 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 6b05748f7bac:38527 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/11/18 06:14:31 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.0.6:37885 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/11/18 06:14:31 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 6b05748f7bac:38527 in memory (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:14:31 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.20.0.6:37885 in memory (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:14:31 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 6b05748f7bac:38527 in memory (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:14:31 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.20.0.6:37885 in memory (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:14:32 INFO CodeGenerator: Code generated in 45.087236 ms
25/11/18 06:14:32 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 338.0 KiB, free 363.9 MiB)
25/11/18 06:14:32 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 363.9 MiB)
25/11/18 06:14:32 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 6b05748f7bac:38527 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:14:32 INFO SparkContext: Created broadcast 8 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:14:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:14:32 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/11/18 06:14:32 INFO DAGScheduler: Got job 3 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:14:32 INFO DAGScheduler: Final stage: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0)
25/11/18 06:14:32 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:14:32 INFO DAGScheduler: Missing parents: List()
25/11/18 06:14:32 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:14:32 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 211.3 KiB, free 363.6 MiB)
25/11/18 06:14:32 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 75.9 KiB, free 363.6 MiB)
25/11/18 06:14:32 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 6b05748f7bac:38527 (size: 75.9 KiB, free: 366.1 MiB)
25/11/18 06:14:32 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/11/18 06:14:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:14:32 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/11/18 06:14:32 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:14:32 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.20.0.6:37885 (size: 75.9 KiB, free: 366.2 MiB)
25/11/18 06:14:32 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.20.0.6:37885 (size: 250.0 B, free: 366.2 MiB)
25/11/18 06:14:32 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.20.0.6:37885 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:14:32 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 652 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:14:32 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/11/18 06:14:32 INFO DAGScheduler: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0) finished in 0.692 s
25/11/18 06:14:32 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:14:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/11/18 06:14:32 INFO DAGScheduler: Job 3 finished: csv at NativeMethodAccessorImpl.java:0, took 0.700928 s
25/11/18 06:14:32 INFO FileFormatWriter: Start to commit write Job 570c9dd9-c546-4e6a-a1d1-1c7eb1e862c6.
25/11/18 06:14:32 INFO FileFormatWriter: Write Job 570c9dd9-c546-4e6a-a1d1-1c7eb1e862c6 committed. Elapsed time: 99 ms.
25/11/18 06:14:32 INFO FileFormatWriter: Finished processing stats for write job 570c9dd9-c546-4e6a-a1d1-1c7eb1e862c6.
25/11/18 06:14:33 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/11/18 06:14:33 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/11/18 06:14:33 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/11/18 06:14:33 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:14:33 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:14:33 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:14:33 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:14:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:14:33 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:14:33 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:14:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:14:33 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:14:33 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:14:33 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 338.2 KiB, free 363.2 MiB)
25/11/18 06:14:33 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 363.2 MiB)
25/11/18 06:14:33 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 6b05748f7bac:38527 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:14:33 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:14:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:14:33 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:14:33 INFO DAGScheduler: Got job 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/11/18 06:14:33 INFO DAGScheduler: Final stage: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/11/18 06:14:33 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:14:33 INFO DAGScheduler: Missing parents: List()
25/11/18 06:14:33 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/11/18 06:14:33 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 14.4 KiB, free 363.2 MiB)
25/11/18 06:14:33 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 363.2 MiB)
25/11/18 06:14:33 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 6b05748f7bac:38527 (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:14:33 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/11/18 06:14:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/11/18 06:14:33 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/11/18 06:14:33 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:14:33 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.20.0.6:37885 (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:14:33 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.20.0.6:37885 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:14:33 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 102 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:14:33 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/11/18 06:14:33 INFO DAGScheduler: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.117 s
25/11/18 06:14:33 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:14:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/11/18 06:14:33 INFO DAGScheduler: Job 4 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.123981 s
25/11/18 06:14:33 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 1025.0 KiB, free 362.2 MiB)
25/11/18 06:14:33 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 250.0 B, free 362.2 MiB)
25/11/18 06:14:33 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 6b05748f7bac:38527 (size: 250.0 B, free: 366.1 MiB)
25/11/18 06:14:33 INFO SparkContext: Created broadcast 12 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:14:33 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:14:33 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:14:33 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:14:33 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 338.0 KiB, free 361.9 MiB)
25/11/18 06:14:33 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 361.8 MiB)
25/11/18 06:14:33 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 6b05748f7bac:38527 (size: 32.5 KiB, free: 366.0 MiB)
25/11/18 06:14:33 INFO SparkContext: Created broadcast 13 from parquet at NativeMethodAccessorImpl.java:0
25/11/18 06:14:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:14:33 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
25/11/18 06:14:33 INFO DAGScheduler: Got job 5 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:14:33 INFO DAGScheduler: Final stage: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0)
25/11/18 06:14:33 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:14:33 INFO DAGScheduler: Missing parents: List()
25/11/18 06:14:33 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:14:33 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 211.3 KiB, free 361.6 MiB)
25/11/18 06:14:33 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 76.0 KiB, free 361.5 MiB)
25/11/18 06:14:33 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 6b05748f7bac:38527 (size: 76.0 KiB, free: 366.0 MiB)
25/11/18 06:14:33 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/11/18 06:14:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:14:33 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/11/18 06:14:33 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:14:33 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.20.0.6:37885 (size: 76.0 KiB, free: 366.0 MiB)
25/11/18 06:14:33 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.20.0.6:37885 (size: 250.0 B, free: 366.0 MiB)
25/11/18 06:14:34 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.20.0.6:37885 (size: 32.5 KiB, free: 366.0 MiB)
25/11/18 06:14:35 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 1805 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:14:35 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/11/18 06:14:35 INFO DAGScheduler: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0) finished in 1.844 s
25/11/18 06:14:35 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:14:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/11/18 06:14:35 INFO DAGScheduler: Job 5 finished: parquet at NativeMethodAccessorImpl.java:0, took 1.850206 s
25/11/18 06:14:35 INFO FileFormatWriter: Start to commit write Job 9ba45b2a-81fc-49e4-b4e2-f48a5acb2cca.
25/11/18 06:14:35 INFO FileFormatWriter: Write Job 9ba45b2a-81fc-49e4-b4e2-f48a5acb2cca committed. Elapsed time: 43 ms.
25/11/18 06:14:35 INFO FileFormatWriter: Finished processing stats for write job 9ba45b2a-81fc-49e4-b4e2-f48a5acb2cca.
Job completed for 2025-01-01
25/11/18 06:14:35 INFO SparkUI: Stopped Spark web UI at http://6b05748f7bac:4040
25/11/18 06:14:35 INFO StandaloneSchedulerBackend: Shutting down all executors
25/11/18 06:14:35 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/11/18 06:14:35 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/11/18 06:14:35 INFO MemoryStore: MemoryStore cleared
25/11/18 06:14:35 INFO BlockManager: BlockManager stopped
25/11/18 06:14:35 INFO BlockManagerMaster: BlockManagerMaster stopped
25/11/18 06:14:35 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/11/18 06:14:35 INFO SparkContext: Successfully stopped SparkContext
25/11/18 06:14:35 INFO ShutdownHookManager: Shutdown hook called
25/11/18 06:14:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-53d48821-18ce-459e-8e14-4a2ae83cf592
25/11/18 06:14:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-e8e862c7-8dbe-422b-a67d-699d1dde584c/pyspark-b2c05074-7b81-4a52-adee-971cb4666524
25/11/18 06:14:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-e8e862c7-8dbe-422b-a67d-699d1dde584c
Job completed for 2025-01-01
/mnt/c/pyspark_stack/spark-apps/cron/run_sales.sh: 1: ---: not found
Triggering sales_etl_job.py for 2025-01-01...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/11/18 06:15:08 INFO SparkContext: Running Spark version 3.2.1
25/11/18 06:15:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/11/18 06:15:08 INFO ResourceUtils: ==============================================================
25/11/18 06:15:08 INFO ResourceUtils: No custom resources configured for spark.driver.
25/11/18 06:15:08 INFO ResourceUtils: ==============================================================
25/11/18 06:15:08 INFO SparkContext: Submitted application: SalesETLJob
25/11/18 06:15:08 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/11/18 06:15:08 INFO ResourceProfile: Limiting resource is cpu
25/11/18 06:15:08 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/11/18 06:15:08 INFO SecurityManager: Changing view acls to: spark
25/11/18 06:15:08 INFO SecurityManager: Changing modify acls to: spark
25/11/18 06:15:08 INFO SecurityManager: Changing view acls groups to: 
25/11/18 06:15:08 INFO SecurityManager: Changing modify acls groups to: 
25/11/18 06:15:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
25/11/18 06:15:09 INFO Utils: Successfully started service 'sparkDriver' on port 45099.
25/11/18 06:15:09 INFO SparkEnv: Registering MapOutputTracker
25/11/18 06:15:09 INFO SparkEnv: Registering BlockManagerMaster
25/11/18 06:15:09 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/11/18 06:15:09 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/11/18 06:15:09 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/11/18 06:15:09 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a75a7d36-9c7d-437f-871a-fafd715a149c
25/11/18 06:15:09 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/11/18 06:15:09 INFO SparkEnv: Registering OutputCommitCoordinator
25/11/18 06:15:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/11/18 06:15:10 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://6b05748f7bac:4040
25/11/18 06:15:10 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/11/18 06:15:10 INFO TransportClientFactory: Successfully created connection to spark-master/172.20.0.3:7077 after 63 ms (0 ms spent in bootstraps)
25/11/18 06:15:10 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20251118061510-0015
25/11/18 06:15:10 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251118061510-0015/0 on worker-20251118055626-172.20.0.6-38023 (172.20.0.6:38023) with 12 core(s)
25/11/18 06:15:10 INFO StandaloneSchedulerBackend: Granted executor ID app-20251118061510-0015/0 on hostPort 172.20.0.6:38023 with 12 core(s), 1024.0 MiB RAM
25/11/18 06:15:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43635.
25/11/18 06:15:10 INFO NettyBlockTransferService: Server created on 6b05748f7bac:43635
25/11/18 06:15:10 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/11/18 06:15:10 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 6b05748f7bac, 43635, None)
25/11/18 06:15:10 INFO BlockManagerMasterEndpoint: Registering block manager 6b05748f7bac:43635 with 366.3 MiB RAM, BlockManagerId(driver, 6b05748f7bac, 43635, None)
25/11/18 06:15:10 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 6b05748f7bac, 43635, None)
25/11/18 06:15:11 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 6b05748f7bac, 43635, None)
25/11/18 06:15:11 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251118061510-0015/0 is now RUNNING
25/11/18 06:15:11 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/11/18 06:15:12 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/11/18 06:15:12 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
25/11/18 06:15:15 INFO InMemoryFileIndex: It took 145 ms to list leaf files for 1 paths.
25/11/18 06:15:15 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.6:51374) with ID 0,  ResourceProfileId 0
25/11/18 06:15:15 INFO InMemoryFileIndex: It took 16 ms to list leaf files for 1 paths.
25/11/18 06:15:16 INFO BlockManagerMasterEndpoint: Registering block manager 172.20.0.6:36519 with 366.3 MiB RAM, BlockManagerId(0, 172.20.0.6, 36519, None)
25/11/18 06:15:20 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:15:20 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/11/18 06:15:20 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:15:21 INFO CodeGenerator: Code generated in 370.606801 ms
25/11/18 06:15:21 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 338.3 KiB, free 366.0 MiB)
25/11/18 06:15:22 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.9 MiB)
25/11/18 06:15:22 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 6b05748f7bac:43635 (size: 32.4 KiB, free: 366.3 MiB)
25/11/18 06:15:22 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:15:22 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:15:22 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/11/18 06:15:22 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:15:22 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/11/18 06:15:22 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:15:22 INFO DAGScheduler: Missing parents: List()
25/11/18 06:15:22 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:15:22 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/11/18 06:15:22 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/11/18 06:15:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 6b05748f7bac:43635 (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:15:22 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/11/18 06:15:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:15:22 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/11/18 06:15:22 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:15:23 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.0.6:36519 (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:15:25 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.0.6:36519 (size: 32.4 KiB, free: 366.3 MiB)
25/11/18 06:15:26 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4299 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:15:26 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/11/18 06:15:26 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 4.521 s
25/11/18 06:15:26 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:15:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/11/18 06:15:26 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 4.603459 s
25/11/18 06:15:26 INFO CodeGenerator: Code generated in 22.50841 ms
25/11/18 06:15:27 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:15:27 INFO FileSourceStrategy: Post-Scan Filters: 
25/11/18 06:15:27 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:15:27 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 338.3 KiB, free 365.6 MiB)
25/11/18 06:15:27 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.6 MiB)
25/11/18 06:15:27 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 6b05748f7bac:43635 (size: 32.4 KiB, free: 366.2 MiB)
25/11/18 06:15:27 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:15:27 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:15:27 INFO InMemoryFileIndex: It took 12 ms to list leaf files for 1 paths.
25/11/18 06:15:27 INFO InMemoryFileIndex: It took 13 ms to list leaf files for 1 paths.
25/11/18 06:15:27 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:15:27 INFO FileSourceStrategy: Post-Scan Filters: 
25/11/18 06:15:27 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:15:27 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 338.1 KiB, free 365.2 MiB)
25/11/18 06:15:27 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.2 MiB)
25/11/18 06:15:27 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 6b05748f7bac:43635 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:15:27 INFO SparkContext: Created broadcast 3 from json at NativeMethodAccessorImpl.java:0
25/11/18 06:15:27 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:15:27 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
25/11/18 06:15:27 INFO DAGScheduler: Got job 1 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:15:27 INFO DAGScheduler: Final stage: ResultStage 1 (json at NativeMethodAccessorImpl.java:0)
25/11/18 06:15:27 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:15:27 INFO DAGScheduler: Missing parents: List()
25/11/18 06:15:27 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:15:27 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 12.4 KiB, free 365.2 MiB)
25/11/18 06:15:27 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 365.2 MiB)
25/11/18 06:15:27 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 6b05748f7bac:43635 (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:15:27 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/11/18 06:15:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:15:27 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/11/18 06:15:27 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:15:27 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.0.6:36519 (size: 6.5 KiB, free: 366.3 MiB)
25/11/18 06:15:27 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.0.6:36519 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:15:27 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 277 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:15:27 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/11/18 06:15:27 INFO DAGScheduler: ResultStage 1 (json at NativeMethodAccessorImpl.java:0) finished in 0.315 s
25/11/18 06:15:27 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:15:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/11/18 06:15:27 INFO DAGScheduler: Job 1 finished: json at NativeMethodAccessorImpl.java:0, took 0.325258 s
25/11/18 06:15:28 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/11/18 06:15:28 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/11/18 06:15:28 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/11/18 06:15:28 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:15:28 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:15:28 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:15:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:15:28 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:15:28 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
25/11/18 06:15:29 INFO CodeGenerator: Code generated in 91.959728 ms
25/11/18 06:15:29 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 338.2 KiB, free 364.8 MiB)
25/11/18 06:15:29 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 364.8 MiB)
25/11/18 06:15:29 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 6b05748f7bac:43635 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:15:29 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:15:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:15:29 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:15:29 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/11/18 06:15:29 INFO DAGScheduler: Final stage: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/11/18 06:15:29 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:15:29 INFO DAGScheduler: Missing parents: List()
25/11/18 06:15:29 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/11/18 06:15:29 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 14.4 KiB, free 364.8 MiB)
25/11/18 06:15:29 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 364.8 MiB)
25/11/18 06:15:29 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 6b05748f7bac:43635 (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:15:29 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/11/18 06:15:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/11/18 06:15:29 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/11/18 06:15:29 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:15:29 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.20.0.6:36519 (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:15:29 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.20.0.6:36519 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:15:29 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 403 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:15:29 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/11/18 06:15:29 INFO DAGScheduler: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.431 s
25/11/18 06:15:29 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:15:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/11/18 06:15:29 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.437842 s
25/11/18 06:15:29 INFO CodeGenerator: Code generated in 17.215182 ms
25/11/18 06:15:29 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 1025.0 KiB, free 363.8 MiB)
25/11/18 06:15:29 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 250.0 B, free 363.8 MiB)
25/11/18 06:15:29 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 6b05748f7bac:43635 (size: 250.0 B, free: 366.2 MiB)
25/11/18 06:15:29 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:15:29 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:15:29 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:15:29 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:15:30 INFO CodeGenerator: Code generated in 146.452265 ms
25/11/18 06:15:30 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 338.0 KiB, free 363.5 MiB)
25/11/18 06:15:30 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 6b05748f7bac:43635 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/11/18 06:15:30 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.0.6:36519 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/11/18 06:15:30 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 363.4 MiB)
25/11/18 06:15:30 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 6b05748f7bac:43635 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:15:30 INFO SparkContext: Created broadcast 8 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:15:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:15:30 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 6b05748f7bac:43635 in memory (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:15:30 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.20.0.6:36519 in memory (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:15:30 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 6b05748f7bac:43635 in memory (size: 6.5 KiB, free: 366.1 MiB)
25/11/18 06:15:30 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.20.0.6:36519 in memory (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:15:30 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 6b05748f7bac:43635 in memory (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:15:30 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.20.0.6:36519 in memory (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:15:30 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/11/18 06:15:30 INFO DAGScheduler: Got job 3 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:15:30 INFO DAGScheduler: Final stage: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0)
25/11/18 06:15:30 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:15:30 INFO DAGScheduler: Missing parents: List()
25/11/18 06:15:30 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:15:30 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 211.3 KiB, free 363.6 MiB)
25/11/18 06:15:30 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 75.9 KiB, free 363.6 MiB)
25/11/18 06:15:30 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 6b05748f7bac:43635 (size: 75.9 KiB, free: 366.1 MiB)
25/11/18 06:15:30 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/11/18 06:15:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:15:30 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/11/18 06:15:30 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:15:30 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.20.0.6:36519 (size: 75.9 KiB, free: 366.2 MiB)
25/11/18 06:15:30 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.20.0.6:36519 (size: 250.0 B, free: 366.2 MiB)
25/11/18 06:15:30 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.20.0.6:36519 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:15:31 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 709 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:15:31 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/11/18 06:15:31 INFO DAGScheduler: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0) finished in 0.760 s
25/11/18 06:15:31 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:15:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/11/18 06:15:31 INFO DAGScheduler: Job 3 finished: csv at NativeMethodAccessorImpl.java:0, took 0.770637 s
25/11/18 06:15:31 INFO FileFormatWriter: Start to commit write Job 188fc0e6-dd7e-4991-9b5c-8693b8aef859.
25/11/18 06:15:31 INFO FileFormatWriter: Write Job 188fc0e6-dd7e-4991-9b5c-8693b8aef859 committed. Elapsed time: 97 ms.
25/11/18 06:15:31 INFO FileFormatWriter: Finished processing stats for write job 188fc0e6-dd7e-4991-9b5c-8693b8aef859.
25/11/18 06:15:31 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/11/18 06:15:31 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/11/18 06:15:31 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/11/18 06:15:31 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:15:31 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:15:31 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:15:31 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:15:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:15:31 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:15:31 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:15:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:15:31 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:15:31 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:15:31 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 338.2 KiB, free 363.2 MiB)
25/11/18 06:15:31 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 363.2 MiB)
25/11/18 06:15:31 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 6b05748f7bac:43635 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:15:31 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:15:31 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:15:31 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:15:31 INFO DAGScheduler: Got job 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/11/18 06:15:31 INFO DAGScheduler: Final stage: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/11/18 06:15:31 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:15:31 INFO DAGScheduler: Missing parents: List()
25/11/18 06:15:31 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/11/18 06:15:31 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 14.4 KiB, free 363.2 MiB)
25/11/18 06:15:31 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 363.2 MiB)
25/11/18 06:15:31 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 6b05748f7bac:43635 (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:15:31 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/11/18 06:15:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/11/18 06:15:31 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/11/18 06:15:31 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:15:31 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.20.0.6:36519 (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:15:31 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.20.0.6:36519 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:15:31 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 88 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:15:31 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/11/18 06:15:31 INFO DAGScheduler: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.102 s
25/11/18 06:15:31 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:15:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/11/18 06:15:31 INFO DAGScheduler: Job 4 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.107724 s
25/11/18 06:15:31 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 1025.0 KiB, free 362.2 MiB)
25/11/18 06:15:31 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 250.0 B, free 362.2 MiB)
25/11/18 06:15:31 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 6b05748f7bac:43635 (size: 250.0 B, free: 366.1 MiB)
25/11/18 06:15:31 INFO SparkContext: Created broadcast 12 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:15:31 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:15:31 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:15:31 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:15:31 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 338.0 KiB, free 361.9 MiB)
25/11/18 06:15:31 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 361.8 MiB)
25/11/18 06:15:31 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 6b05748f7bac:43635 (size: 32.5 KiB, free: 366.0 MiB)
25/11/18 06:15:31 INFO SparkContext: Created broadcast 13 from parquet at NativeMethodAccessorImpl.java:0
25/11/18 06:15:31 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:15:31 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
25/11/18 06:15:31 INFO DAGScheduler: Got job 5 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:15:31 INFO DAGScheduler: Final stage: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0)
25/11/18 06:15:31 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:15:31 INFO DAGScheduler: Missing parents: List()
25/11/18 06:15:31 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:15:31 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 211.3 KiB, free 361.6 MiB)
25/11/18 06:15:31 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 76.0 KiB, free 361.5 MiB)
25/11/18 06:15:31 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 6b05748f7bac:43635 (size: 76.0 KiB, free: 366.0 MiB)
25/11/18 06:15:31 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/11/18 06:15:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:15:31 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/11/18 06:15:31 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:15:31 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.20.0.6:36519 (size: 76.0 KiB, free: 366.0 MiB)
25/11/18 06:15:31 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.20.0.6:36519 (size: 250.0 B, free: 366.0 MiB)
25/11/18 06:15:32 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.20.0.6:36519 (size: 32.5 KiB, free: 366.0 MiB)
25/11/18 06:15:36 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 4786 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:15:36 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/11/18 06:15:36 INFO DAGScheduler: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0) finished in 4.828 s
25/11/18 06:15:36 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:15:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/11/18 06:15:36 INFO DAGScheduler: Job 5 finished: parquet at NativeMethodAccessorImpl.java:0, took 2.106510 s
25/11/18 06:15:36 INFO FileFormatWriter: Start to commit write Job 8a15aee1-01bc-4997-96c6-4385dfa73cbb.
25/11/18 06:15:36 INFO FileFormatWriter: Write Job 8a15aee1-01bc-4997-96c6-4385dfa73cbb committed. Elapsed time: 34 ms.
25/11/18 06:15:36 INFO FileFormatWriter: Finished processing stats for write job 8a15aee1-01bc-4997-96c6-4385dfa73cbb.
Job completed for 2025-01-01
25/11/18 06:15:36 INFO SparkUI: Stopped Spark web UI at http://6b05748f7bac:4040
25/11/18 06:15:36 INFO StandaloneSchedulerBackend: Shutting down all executors
25/11/18 06:15:36 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/11/18 06:15:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/11/18 06:15:36 INFO MemoryStore: MemoryStore cleared
25/11/18 06:15:36 INFO BlockManager: BlockManager stopped
25/11/18 06:15:36 INFO BlockManagerMaster: BlockManagerMaster stopped
25/11/18 06:15:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/11/18 06:15:36 INFO SparkContext: Successfully stopped SparkContext
25/11/18 06:15:36 INFO ShutdownHookManager: Shutdown hook called
25/11/18 06:15:36 INFO ShutdownHookManager: Deleting directory /tmp/spark-f0b935ca-154a-4212-8b91-99f59062202b
25/11/18 06:15:37 INFO ShutdownHookManager: Deleting directory /tmp/spark-93c23f8a-2114-423a-a31e-81ee8aac52bd/pyspark-f1f7e180-32c7-405a-9e99-6ec07fee42f0
25/11/18 06:15:37 INFO ShutdownHookManager: Deleting directory /tmp/spark-93c23f8a-2114-423a-a31e-81ee8aac52bd
Job completed for 2025-01-01
/mnt/c/pyspark_stack/spark-apps/cron/run_sales.sh: 1: ---: not found
Triggering sales_etl_job.py for 2025-01-01...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/11/18 06:16:08 INFO SparkContext: Running Spark version 3.2.1
25/11/18 06:16:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/11/18 06:16:09 INFO ResourceUtils: ==============================================================
25/11/18 06:16:09 INFO ResourceUtils: No custom resources configured for spark.driver.
25/11/18 06:16:09 INFO ResourceUtils: ==============================================================
25/11/18 06:16:09 INFO SparkContext: Submitted application: SalesETLJob
25/11/18 06:16:09 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/11/18 06:16:09 INFO ResourceProfile: Limiting resource is cpu
25/11/18 06:16:09 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/11/18 06:16:09 INFO SecurityManager: Changing view acls to: spark
25/11/18 06:16:09 INFO SecurityManager: Changing modify acls to: spark
25/11/18 06:16:09 INFO SecurityManager: Changing view acls groups to: 
25/11/18 06:16:09 INFO SecurityManager: Changing modify acls groups to: 
25/11/18 06:16:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
25/11/18 06:16:09 INFO Utils: Successfully started service 'sparkDriver' on port 41701.
25/11/18 06:16:09 INFO SparkEnv: Registering MapOutputTracker
25/11/18 06:16:09 INFO SparkEnv: Registering BlockManagerMaster
25/11/18 06:16:10 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/11/18 06:16:10 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/11/18 06:16:10 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/11/18 06:16:10 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-f4b2e089-5ba3-4164-a612-6f22749d843c
25/11/18 06:16:10 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/11/18 06:16:10 INFO SparkEnv: Registering OutputCommitCoordinator
25/11/18 06:16:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/11/18 06:16:10 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://6b05748f7bac:4040
25/11/18 06:16:11 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/11/18 06:16:11 INFO TransportClientFactory: Successfully created connection to spark-master/172.20.0.3:7077 after 110 ms (0 ms spent in bootstraps)
25/11/18 06:16:11 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20251118061611-0016
25/11/18 06:16:11 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251118061611-0016/0 on worker-20251118055626-172.20.0.6-38023 (172.20.0.6:38023) with 12 core(s)
25/11/18 06:16:11 INFO StandaloneSchedulerBackend: Granted executor ID app-20251118061611-0016/0 on hostPort 172.20.0.6:38023 with 12 core(s), 1024.0 MiB RAM
25/11/18 06:16:11 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39265.
25/11/18 06:16:11 INFO NettyBlockTransferService: Server created on 6b05748f7bac:39265
25/11/18 06:16:11 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/11/18 06:16:11 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 6b05748f7bac, 39265, None)
25/11/18 06:16:11 INFO BlockManagerMasterEndpoint: Registering block manager 6b05748f7bac:39265 with 366.3 MiB RAM, BlockManagerId(driver, 6b05748f7bac, 39265, None)
25/11/18 06:16:11 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 6b05748f7bac, 39265, None)
25/11/18 06:16:11 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 6b05748f7bac, 39265, None)
25/11/18 06:16:11 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251118061611-0016/0 is now RUNNING
25/11/18 06:16:12 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/11/18 06:16:12 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/11/18 06:16:12 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
25/11/18 06:16:16 INFO InMemoryFileIndex: It took 220 ms to list leaf files for 1 paths.
25/11/18 06:16:16 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.6:39370) with ID 0,  ResourceProfileId 0
25/11/18 06:16:16 INFO InMemoryFileIndex: It took 11 ms to list leaf files for 1 paths.
25/11/18 06:16:16 INFO BlockManagerMasterEndpoint: Registering block manager 172.20.0.6:46807 with 366.3 MiB RAM, BlockManagerId(0, 172.20.0.6, 46807, None)
25/11/18 06:16:21 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:16:21 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/11/18 06:16:21 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:16:22 INFO CodeGenerator: Code generated in 387.956512 ms
25/11/18 06:16:22 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 338.3 KiB, free 366.0 MiB)
25/11/18 06:16:22 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.9 MiB)
25/11/18 06:16:22 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 6b05748f7bac:39265 (size: 32.4 KiB, free: 366.3 MiB)
25/11/18 06:16:22 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:16:22 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:16:22 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/11/18 06:16:22 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:16:22 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/11/18 06:16:22 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:16:22 INFO DAGScheduler: Missing parents: List()
25/11/18 06:16:22 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:16:22 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/11/18 06:16:22 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/11/18 06:16:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 6b05748f7bac:39265 (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:16:22 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/11/18 06:16:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:16:22 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/11/18 06:16:22 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:16:23 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.0.6:46807 (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:16:25 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.0.6:46807 (size: 32.4 KiB, free: 366.3 MiB)
25/11/18 06:16:27 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4281 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:16:27 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/11/18 06:16:27 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 4.527 s
25/11/18 06:16:27 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:16:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/11/18 06:16:27 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 4.626933 s
25/11/18 06:16:27 INFO CodeGenerator: Code generated in 16.519795 ms
25/11/18 06:16:27 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:16:27 INFO FileSourceStrategy: Post-Scan Filters: 
25/11/18 06:16:27 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:16:27 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 338.3 KiB, free 365.6 MiB)
25/11/18 06:16:27 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.6 MiB)
25/11/18 06:16:27 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 6b05748f7bac:39265 (size: 32.4 KiB, free: 366.2 MiB)
25/11/18 06:16:27 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:16:27 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:16:27 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
25/11/18 06:16:27 INFO InMemoryFileIndex: It took 10 ms to list leaf files for 1 paths.
25/11/18 06:16:27 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:16:27 INFO FileSourceStrategy: Post-Scan Filters: 
25/11/18 06:16:27 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:16:27 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 338.1 KiB, free 365.2 MiB)
25/11/18 06:16:27 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.2 MiB)
25/11/18 06:16:27 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 6b05748f7bac:39265 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:16:27 INFO SparkContext: Created broadcast 3 from json at NativeMethodAccessorImpl.java:0
25/11/18 06:16:27 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:16:27 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
25/11/18 06:16:27 INFO DAGScheduler: Got job 1 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:16:27 INFO DAGScheduler: Final stage: ResultStage 1 (json at NativeMethodAccessorImpl.java:0)
25/11/18 06:16:27 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:16:27 INFO DAGScheduler: Missing parents: List()
25/11/18 06:16:27 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:16:27 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 12.4 KiB, free 365.2 MiB)
25/11/18 06:16:27 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 365.2 MiB)
25/11/18 06:16:27 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 6b05748f7bac:39265 (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:16:27 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/11/18 06:16:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:16:27 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/11/18 06:16:27 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:16:27 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.0.6:46807 (size: 6.5 KiB, free: 366.3 MiB)
25/11/18 06:16:28 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.0.6:46807 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:16:28 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 433 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:16:28 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/11/18 06:16:28 INFO DAGScheduler: ResultStage 1 (json at NativeMethodAccessorImpl.java:0) finished in 0.479 s
25/11/18 06:16:28 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:16:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/11/18 06:16:28 INFO DAGScheduler: Job 1 finished: json at NativeMethodAccessorImpl.java:0, took 0.493650 s
25/11/18 06:16:29 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/11/18 06:16:29 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/11/18 06:16:29 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/11/18 06:16:29 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:16:29 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:16:29 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:16:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:16:30 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:16:30 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
25/11/18 06:16:30 INFO CodeGenerator: Code generated in 33.027218 ms
25/11/18 06:16:30 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 338.2 KiB, free 364.8 MiB)
25/11/18 06:16:30 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 364.8 MiB)
25/11/18 06:16:30 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 6b05748f7bac:39265 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:16:30 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:16:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:16:30 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:16:30 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/11/18 06:16:30 INFO DAGScheduler: Final stage: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/11/18 06:16:30 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:16:30 INFO DAGScheduler: Missing parents: List()
25/11/18 06:16:30 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/11/18 06:16:30 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 14.4 KiB, free 364.8 MiB)
25/11/18 06:16:30 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 364.8 MiB)
25/11/18 06:16:30 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 6b05748f7bac:39265 (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:16:30 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/11/18 06:16:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/11/18 06:16:30 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/11/18 06:16:30 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:16:30 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.20.0.6:46807 (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:16:30 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.20.0.6:46807 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:16:30 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 428 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:16:30 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/11/18 06:16:30 INFO DAGScheduler: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.457 s
25/11/18 06:16:30 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:16:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/11/18 06:16:30 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.463848 s
25/11/18 06:16:30 INFO CodeGenerator: Code generated in 24.00357 ms
25/11/18 06:16:30 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 1025.0 KiB, free 363.8 MiB)
25/11/18 06:16:30 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 250.0 B, free 363.8 MiB)
25/11/18 06:16:30 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 6b05748f7bac:39265 (size: 250.0 B, free: 366.2 MiB)
25/11/18 06:16:30 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:16:30 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:16:30 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:16:30 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:16:31 INFO CodeGenerator: Code generated in 47.949048 ms
25/11/18 06:16:31 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 338.0 KiB, free 363.5 MiB)
25/11/18 06:16:31 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 363.4 MiB)
25/11/18 06:16:31 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 6b05748f7bac:39265 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:16:31 INFO SparkContext: Created broadcast 8 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:16:31 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:16:31 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 6b05748f7bac:39265 in memory (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:16:31 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.20.0.6:46807 in memory (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:16:31 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 6b05748f7bac:39265 in memory (size: 5.8 KiB, free: 366.1 MiB)
25/11/18 06:16:31 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.0.6:46807 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/11/18 06:16:31 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/11/18 06:16:31 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 6b05748f7bac:39265 in memory (size: 6.5 KiB, free: 366.1 MiB)
25/11/18 06:16:31 INFO DAGScheduler: Got job 3 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:16:31 INFO DAGScheduler: Final stage: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0)
25/11/18 06:16:31 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:16:31 INFO DAGScheduler: Missing parents: List()
25/11/18 06:16:31 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:16:31 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.20.0.6:46807 in memory (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:16:31 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 6b05748f7bac:39265 in memory (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:16:31 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.20.0.6:46807 in memory (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:16:31 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 211.3 KiB, free 363.6 MiB)
25/11/18 06:16:31 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 75.9 KiB, free 363.6 MiB)
25/11/18 06:16:31 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 6b05748f7bac:39265 (size: 75.9 KiB, free: 366.1 MiB)
25/11/18 06:16:31 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/11/18 06:16:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:16:31 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/11/18 06:16:31 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:16:31 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.20.0.6:46807 (size: 75.9 KiB, free: 366.2 MiB)
25/11/18 06:16:31 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.20.0.6:46807 (size: 250.0 B, free: 366.2 MiB)
25/11/18 06:16:32 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.20.0.6:46807 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:16:32 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 927 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:16:32 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/11/18 06:16:32 INFO DAGScheduler: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0) finished in 0.982 s
25/11/18 06:16:32 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:16:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/11/18 06:16:32 INFO DAGScheduler: Job 3 finished: csv at NativeMethodAccessorImpl.java:0, took 0.996370 s
25/11/18 06:16:32 INFO FileFormatWriter: Start to commit write Job b0b49817-9e1b-43f7-b506-57c537a8b61d.
25/11/18 06:16:32 INFO FileFormatWriter: Write Job b0b49817-9e1b-43f7-b506-57c537a8b61d committed. Elapsed time: 125 ms.
25/11/18 06:16:32 INFO FileFormatWriter: Finished processing stats for write job b0b49817-9e1b-43f7-b506-57c537a8b61d.
25/11/18 06:16:32 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/11/18 06:16:32 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/11/18 06:16:32 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/11/18 06:16:32 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:16:32 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:16:32 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:16:32 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:16:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:16:32 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:16:32 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:16:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:16:32 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:16:32 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:16:32 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 338.2 KiB, free 363.2 MiB)
25/11/18 06:16:32 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 363.2 MiB)
25/11/18 06:16:32 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 6b05748f7bac:39265 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:16:32 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:16:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:16:32 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:16:32 INFO DAGScheduler: Got job 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/11/18 06:16:32 INFO DAGScheduler: Final stage: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/11/18 06:16:32 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:16:32 INFO DAGScheduler: Missing parents: List()
25/11/18 06:16:32 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/11/18 06:16:32 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 14.4 KiB, free 363.2 MiB)
25/11/18 06:16:32 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 363.2 MiB)
25/11/18 06:16:32 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 6b05748f7bac:39265 (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:16:32 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/11/18 06:16:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/11/18 06:16:32 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/11/18 06:16:32 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:16:32 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.20.0.6:46807 (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:16:32 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.20.0.6:46807 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:16:32 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 110 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:16:32 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/11/18 06:16:32 INFO DAGScheduler: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.127 s
25/11/18 06:16:32 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:16:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/11/18 06:16:32 INFO DAGScheduler: Job 4 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.136052 s
25/11/18 06:16:32 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 1025.0 KiB, free 362.2 MiB)
25/11/18 06:16:32 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 250.0 B, free 362.2 MiB)
25/11/18 06:16:32 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 6b05748f7bac:39265 (size: 250.0 B, free: 366.1 MiB)
25/11/18 06:16:32 INFO SparkContext: Created broadcast 12 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:16:32 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:16:32 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:16:32 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:16:33 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 338.0 KiB, free 361.9 MiB)
25/11/18 06:16:33 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 361.8 MiB)
25/11/18 06:16:33 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 6b05748f7bac:39265 (size: 32.5 KiB, free: 366.0 MiB)
25/11/18 06:16:33 INFO SparkContext: Created broadcast 13 from parquet at NativeMethodAccessorImpl.java:0
25/11/18 06:16:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:16:33 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
25/11/18 06:16:33 INFO DAGScheduler: Got job 5 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:16:33 INFO DAGScheduler: Final stage: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0)
25/11/18 06:16:33 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:16:33 INFO DAGScheduler: Missing parents: List()
25/11/18 06:16:33 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:16:33 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 211.3 KiB, free 361.6 MiB)
25/11/18 06:16:33 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 76.1 KiB, free 361.5 MiB)
25/11/18 06:16:33 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 6b05748f7bac:39265 (size: 76.1 KiB, free: 366.0 MiB)
25/11/18 06:16:33 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/11/18 06:16:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:16:33 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/11/18 06:16:33 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:16:33 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.20.0.6:46807 (size: 76.1 KiB, free: 366.0 MiB)
25/11/18 06:16:33 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.20.0.6:46807 (size: 250.0 B, free: 366.0 MiB)
25/11/18 06:16:34 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.20.0.6:46807 (size: 32.5 KiB, free: 366.0 MiB)
25/11/18 06:16:35 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 1947 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:16:35 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/11/18 06:16:35 INFO DAGScheduler: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0) finished in 1.976 s
25/11/18 06:16:35 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:16:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/11/18 06:16:35 INFO DAGScheduler: Job 5 finished: parquet at NativeMethodAccessorImpl.java:0, took 1.982638 s
25/11/18 06:16:35 INFO FileFormatWriter: Start to commit write Job 9f499d73-2fd2-47b3-a151-5d4f241fdc09.
25/11/18 06:16:35 INFO FileFormatWriter: Write Job 9f499d73-2fd2-47b3-a151-5d4f241fdc09 committed. Elapsed time: 47 ms.
25/11/18 06:16:35 INFO FileFormatWriter: Finished processing stats for write job 9f499d73-2fd2-47b3-a151-5d4f241fdc09.
Job completed for 2025-01-01
25/11/18 06:16:35 INFO SparkUI: Stopped Spark web UI at http://6b05748f7bac:4040
25/11/18 06:16:35 INFO StandaloneSchedulerBackend: Shutting down all executors
25/11/18 06:16:35 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/11/18 06:16:35 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/11/18 06:16:35 INFO MemoryStore: MemoryStore cleared
25/11/18 06:16:35 INFO BlockManager: BlockManager stopped
25/11/18 06:16:35 INFO BlockManagerMaster: BlockManagerMaster stopped
25/11/18 06:16:35 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/11/18 06:16:35 INFO SparkContext: Successfully stopped SparkContext
25/11/18 06:16:35 INFO ShutdownHookManager: Shutdown hook called
25/11/18 06:16:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-34ec0bff-7707-42ff-902c-cc5d839e28ba
25/11/18 06:16:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-8d645a82-e2bc-4cc1-a792-3af31d682b3b
25/11/18 06:16:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-8d645a82-e2bc-4cc1-a792-3af31d682b3b/pyspark-938cd4d5-e8cf-457f-bcc5-9abd23b4d597
Job completed for 2025-01-01
/mnt/c/pyspark_stack/spark-apps/cron/run_sales.sh: 1: ---: not found
Triggering sales_etl_job.py for 2025-01-01...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/11/18 06:17:08 INFO SparkContext: Running Spark version 3.2.1
25/11/18 06:17:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/11/18 06:17:08 INFO ResourceUtils: ==============================================================
25/11/18 06:17:08 INFO ResourceUtils: No custom resources configured for spark.driver.
25/11/18 06:17:08 INFO ResourceUtils: ==============================================================
25/11/18 06:17:08 INFO SparkContext: Submitted application: SalesETLJob
25/11/18 06:17:08 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/11/18 06:17:08 INFO ResourceProfile: Limiting resource is cpu
25/11/18 06:17:08 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/11/18 06:17:08 INFO SecurityManager: Changing view acls to: spark
25/11/18 06:17:08 INFO SecurityManager: Changing modify acls to: spark
25/11/18 06:17:08 INFO SecurityManager: Changing view acls groups to: 
25/11/18 06:17:08 INFO SecurityManager: Changing modify acls groups to: 
25/11/18 06:17:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
25/11/18 06:17:09 INFO Utils: Successfully started service 'sparkDriver' on port 45505.
25/11/18 06:17:09 INFO SparkEnv: Registering MapOutputTracker
25/11/18 06:17:09 INFO SparkEnv: Registering BlockManagerMaster
25/11/18 06:17:09 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/11/18 06:17:09 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/11/18 06:17:09 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/11/18 06:17:09 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-46c5bc88-f3de-43c3-95ac-b721d5930ceb
25/11/18 06:17:09 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/11/18 06:17:09 INFO SparkEnv: Registering OutputCommitCoordinator
25/11/18 06:17:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/11/18 06:17:10 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://6b05748f7bac:4040
25/11/18 06:17:10 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/11/18 06:17:11 INFO TransportClientFactory: Successfully created connection to spark-master/172.20.0.3:7077 after 78 ms (0 ms spent in bootstraps)
25/11/18 06:17:10 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20251118061710-0017
25/11/18 06:17:10 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251118061710-0017/0 on worker-20251118055626-172.20.0.6-38023 (172.20.0.6:38023) with 12 core(s)
25/11/18 06:17:10 INFO StandaloneSchedulerBackend: Granted executor ID app-20251118061710-0017/0 on hostPort 172.20.0.6:38023 with 12 core(s), 1024.0 MiB RAM
25/11/18 06:17:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39597.
25/11/18 06:17:10 INFO NettyBlockTransferService: Server created on 6b05748f7bac:39597
25/11/18 06:17:10 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/11/18 06:17:10 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 6b05748f7bac, 39597, None)
25/11/18 06:17:10 INFO BlockManagerMasterEndpoint: Registering block manager 6b05748f7bac:39597 with 366.3 MiB RAM, BlockManagerId(driver, 6b05748f7bac, 39597, None)
25/11/18 06:17:10 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 6b05748f7bac, 39597, None)
25/11/18 06:17:10 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 6b05748f7bac, 39597, None)
25/11/18 06:17:10 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251118061710-0017/0 is now RUNNING
25/11/18 06:17:14 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/11/18 06:17:15 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/11/18 06:17:15 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
25/11/18 06:17:18 INFO InMemoryFileIndex: It took 128 ms to list leaf files for 1 paths.
25/11/18 06:17:18 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.6:39390) with ID 0,  ResourceProfileId 0
25/11/18 06:17:18 INFO InMemoryFileIndex: It took 13 ms to list leaf files for 1 paths.
25/11/18 06:17:18 INFO BlockManagerMasterEndpoint: Registering block manager 172.20.0.6:46573 with 366.3 MiB RAM, BlockManagerId(0, 172.20.0.6, 46573, None)
25/11/18 06:17:23 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:17:23 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/11/18 06:17:23 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:17:24 INFO CodeGenerator: Code generated in 371.255636 ms
25/11/18 06:17:24 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 338.3 KiB, free 366.0 MiB)
25/11/18 06:17:24 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.9 MiB)
25/11/18 06:17:24 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 6b05748f7bac:39597 (size: 32.4 KiB, free: 366.3 MiB)
25/11/18 06:17:24 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:17:24 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:17:25 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/11/18 06:17:25 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:17:25 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/11/18 06:17:25 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:17:25 INFO DAGScheduler: Missing parents: List()
25/11/18 06:17:25 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:17:25 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/11/18 06:17:25 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/11/18 06:17:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 6b05748f7bac:39597 (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:17:25 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/11/18 06:17:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:17:25 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/11/18 06:17:25 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:17:26 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.0.6:46573 (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:17:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.0.6:46573 (size: 32.4 KiB, free: 366.3 MiB)
25/11/18 06:17:29 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4429 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:17:29 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/11/18 06:17:29 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 4.655 s
25/11/18 06:17:29 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:17:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/11/18 06:17:29 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 4.763479 s
25/11/18 06:17:30 INFO CodeGenerator: Code generated in 23.658775 ms
25/11/18 06:17:30 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:17:30 INFO FileSourceStrategy: Post-Scan Filters: 
25/11/18 06:17:30 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:17:30 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 338.3 KiB, free 365.6 MiB)
25/11/18 06:17:30 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.6 MiB)
25/11/18 06:17:30 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 6b05748f7bac:39597 (size: 32.4 KiB, free: 366.2 MiB)
25/11/18 06:17:30 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:17:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:17:30 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 1 paths.
25/11/18 06:17:30 INFO InMemoryFileIndex: It took 10 ms to list leaf files for 1 paths.
25/11/18 06:17:30 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:17:30 INFO FileSourceStrategy: Post-Scan Filters: 
25/11/18 06:17:30 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:17:30 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 338.1 KiB, free 365.2 MiB)
25/11/18 06:17:30 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.2 MiB)
25/11/18 06:17:30 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 6b05748f7bac:39597 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:17:30 INFO SparkContext: Created broadcast 3 from json at NativeMethodAccessorImpl.java:0
25/11/18 06:17:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:17:30 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
25/11/18 06:17:30 INFO DAGScheduler: Got job 1 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:17:30 INFO DAGScheduler: Final stage: ResultStage 1 (json at NativeMethodAccessorImpl.java:0)
25/11/18 06:17:30 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:17:30 INFO DAGScheduler: Missing parents: List()
25/11/18 06:17:30 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:17:30 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 12.4 KiB, free 365.2 MiB)
25/11/18 06:17:30 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 365.2 MiB)
25/11/18 06:17:30 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 6b05748f7bac:39597 (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:17:30 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/11/18 06:17:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:17:30 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/11/18 06:17:30 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:17:30 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.0.6:46573 (size: 6.5 KiB, free: 366.3 MiB)
25/11/18 06:17:30 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.0.6:46573 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:17:30 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 298 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:17:30 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/11/18 06:17:30 INFO DAGScheduler: ResultStage 1 (json at NativeMethodAccessorImpl.java:0) finished in 0.344 s
25/11/18 06:17:30 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:17:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/11/18 06:17:30 INFO DAGScheduler: Job 1 finished: json at NativeMethodAccessorImpl.java:0, took 0.356921 s
25/11/18 06:17:31 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/11/18 06:17:31 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/11/18 06:17:31 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/11/18 06:17:31 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:17:31 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:17:31 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:17:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:17:32 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:17:32 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
25/11/18 06:17:32 INFO CodeGenerator: Code generated in 35.760353 ms
25/11/18 06:17:32 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 338.2 KiB, free 364.8 MiB)
25/11/18 06:17:32 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 364.8 MiB)
25/11/18 06:17:32 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 6b05748f7bac:39597 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:17:32 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:17:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:17:32 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:17:32 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/11/18 06:17:32 INFO DAGScheduler: Final stage: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/11/18 06:17:32 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:17:32 INFO DAGScheduler: Missing parents: List()
25/11/18 06:17:32 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/11/18 06:17:32 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 14.4 KiB, free 364.8 MiB)
25/11/18 06:17:32 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 364.8 MiB)
25/11/18 06:17:32 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 6b05748f7bac:39597 (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:17:32 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/11/18 06:17:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/11/18 06:17:32 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/11/18 06:17:32 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:17:32 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 6b05748f7bac:39597 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/11/18 06:17:32 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.20.0.6:46573 (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:17:32 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.0.6:46573 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/11/18 06:17:32 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 6b05748f7bac:39597 in memory (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:17:32 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.20.0.6:46573 in memory (size: 32.5 KiB, free: 366.3 MiB)
25/11/18 06:17:32 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 6b05748f7bac:39597 in memory (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:17:32 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.20.0.6:46573 in memory (size: 6.5 KiB, free: 366.3 MiB)
25/11/18 06:17:32 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.20.0.6:46573 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:17:33 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 535 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:17:33 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/11/18 06:17:33 INFO DAGScheduler: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.624 s
25/11/18 06:17:33 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:17:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/11/18 06:17:33 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.635275 s
25/11/18 06:17:33 INFO CodeGenerator: Code generated in 18.740392 ms
25/11/18 06:17:33 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 1025.0 KiB, free 364.2 MiB)
25/11/18 06:17:33 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 250.0 B, free 364.2 MiB)
25/11/18 06:17:33 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 6b05748f7bac:39597 (size: 250.0 B, free: 366.2 MiB)
25/11/18 06:17:33 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:17:33 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:17:33 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:17:33 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:17:33 INFO CodeGenerator: Code generated in 48.963091 ms
25/11/18 06:17:33 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 338.0 KiB, free 363.9 MiB)
25/11/18 06:17:33 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 363.8 MiB)
25/11/18 06:17:33 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 6b05748f7bac:39597 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:17:33 INFO SparkContext: Created broadcast 8 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:17:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:17:33 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/11/18 06:17:33 INFO DAGScheduler: Got job 3 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:17:33 INFO DAGScheduler: Final stage: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0)
25/11/18 06:17:33 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:17:33 INFO DAGScheduler: Missing parents: List()
25/11/18 06:17:33 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:17:33 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 211.3 KiB, free 363.6 MiB)
25/11/18 06:17:33 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 75.9 KiB, free 363.5 MiB)
25/11/18 06:17:33 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 6b05748f7bac:39597 (size: 75.9 KiB, free: 366.1 MiB)
25/11/18 06:17:33 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/11/18 06:17:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:17:33 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/11/18 06:17:33 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:17:33 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.20.0.6:46573 (size: 75.9 KiB, free: 366.2 MiB)
25/11/18 06:17:33 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.20.0.6:46573 (size: 250.0 B, free: 366.2 MiB)
25/11/18 06:17:34 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.20.0.6:46573 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:17:34 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 939 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:17:34 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/11/18 06:17:34 INFO DAGScheduler: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0) finished in 0.996 s
25/11/18 06:17:34 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:17:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/11/18 06:17:34 INFO DAGScheduler: Job 3 finished: csv at NativeMethodAccessorImpl.java:0, took 1.009865 s
25/11/18 06:17:34 INFO FileFormatWriter: Start to commit write Job d63251e2-1883-41f5-9c14-f89f90143cb3.
25/11/18 06:17:34 INFO FileFormatWriter: Write Job d63251e2-1883-41f5-9c14-f89f90143cb3 committed. Elapsed time: 135 ms.
25/11/18 06:17:34 INFO FileFormatWriter: Finished processing stats for write job d63251e2-1883-41f5-9c14-f89f90143cb3.
25/11/18 06:17:34 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/11/18 06:17:34 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/11/18 06:17:34 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/11/18 06:17:34 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:17:34 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:17:34 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:17:34 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:17:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:17:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:17:35 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:17:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:17:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:17:35 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:17:35 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 338.2 KiB, free 363.2 MiB)
25/11/18 06:17:35 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 363.2 MiB)
25/11/18 06:17:35 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 6b05748f7bac:39597 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:17:35 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:17:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:17:35 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:17:35 INFO DAGScheduler: Got job 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/11/18 06:17:35 INFO DAGScheduler: Final stage: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/11/18 06:17:35 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:17:35 INFO DAGScheduler: Missing parents: List()
25/11/18 06:17:35 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/11/18 06:17:35 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 14.4 KiB, free 363.2 MiB)
25/11/18 06:17:35 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 363.2 MiB)
25/11/18 06:17:35 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 6b05748f7bac:39597 (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:17:35 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/11/18 06:17:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/11/18 06:17:35 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/11/18 06:17:35 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:17:35 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.20.0.6:46573 (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:17:35 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.20.0.6:46573 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:17:35 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 201 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:17:35 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/11/18 06:17:35 INFO DAGScheduler: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.228 s
25/11/18 06:17:35 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:17:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/11/18 06:17:35 INFO DAGScheduler: Job 4 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.243605 s
25/11/18 06:17:35 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 1025.0 KiB, free 362.2 MiB)
25/11/18 06:17:35 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 250.0 B, free 362.2 MiB)
25/11/18 06:17:35 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 6b05748f7bac:39597 (size: 250.0 B, free: 366.1 MiB)
25/11/18 06:17:35 INFO SparkContext: Created broadcast 12 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:17:35 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:17:35 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:17:35 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:17:35 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 338.0 KiB, free 361.8 MiB)
25/11/18 06:17:35 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 361.8 MiB)
25/11/18 06:17:35 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 6b05748f7bac:39597 (size: 32.5 KiB, free: 366.0 MiB)
25/11/18 06:17:35 INFO SparkContext: Created broadcast 13 from parquet at NativeMethodAccessorImpl.java:0
25/11/18 06:17:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:17:35 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
25/11/18 06:17:35 INFO DAGScheduler: Got job 5 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:17:35 INFO DAGScheduler: Final stage: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0)
25/11/18 06:17:35 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:17:35 INFO DAGScheduler: Missing parents: List()
25/11/18 06:17:35 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:17:35 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 211.3 KiB, free 361.6 MiB)
25/11/18 06:17:35 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 76.0 KiB, free 361.5 MiB)
25/11/18 06:17:35 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 6b05748f7bac:39597 (size: 76.0 KiB, free: 365.9 MiB)
25/11/18 06:17:35 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/11/18 06:17:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:17:35 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/11/18 06:17:35 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:17:35 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.20.0.6:46573 (size: 76.0 KiB, free: 366.0 MiB)
25/11/18 06:17:35 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.20.0.6:46573 (size: 250.0 B, free: 366.0 MiB)
25/11/18 06:17:36 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.20.0.6:46573 (size: 32.5 KiB, free: 366.0 MiB)
25/11/18 06:17:37 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 1734 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:17:37 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/11/18 06:17:37 INFO DAGScheduler: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0) finished in 1.797 s
25/11/18 06:17:37 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:17:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/11/18 06:17:37 INFO DAGScheduler: Job 5 finished: parquet at NativeMethodAccessorImpl.java:0, took 1.804439 s
25/11/18 06:17:37 INFO FileFormatWriter: Start to commit write Job e4050acb-a622-409f-998a-33f4075ee621.
25/11/18 06:17:37 INFO FileFormatWriter: Write Job e4050acb-a622-409f-998a-33f4075ee621 committed. Elapsed time: 43 ms.
25/11/18 06:17:37 INFO FileFormatWriter: Finished processing stats for write job e4050acb-a622-409f-998a-33f4075ee621.
Job completed for 2025-01-01
25/11/18 06:17:37 INFO SparkUI: Stopped Spark web UI at http://6b05748f7bac:4040
25/11/18 06:17:37 INFO StandaloneSchedulerBackend: Shutting down all executors
25/11/18 06:17:37 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/11/18 06:17:37 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/11/18 06:17:37 INFO MemoryStore: MemoryStore cleared
25/11/18 06:17:37 INFO BlockManager: BlockManager stopped
25/11/18 06:17:37 INFO BlockManagerMaster: BlockManagerMaster stopped
25/11/18 06:17:37 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/11/18 06:17:37 INFO SparkContext: Successfully stopped SparkContext
25/11/18 06:17:37 INFO ShutdownHookManager: Shutdown hook called
25/11/18 06:17:37 INFO ShutdownHookManager: Deleting directory /tmp/spark-7133a9e6-e56a-4614-8eae-f6f1219b9bed
25/11/18 06:17:37 INFO ShutdownHookManager: Deleting directory /tmp/spark-7133a9e6-e56a-4614-8eae-f6f1219b9bed/pyspark-2aaefd5e-40f1-4b60-b6ad-55308451c342
25/11/18 06:17:37 INFO ShutdownHookManager: Deleting directory /tmp/spark-95ce1327-d2d0-4e2b-8d6d-a9f0a818dcd9
Job completed for 2025-01-01
/mnt/c/pyspark_stack/spark-apps/cron/run_sales.sh: 1: ---: not found
Triggering sales_etl_job.py for 2025-01-01...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/11/18 06:18:08 INFO SparkContext: Running Spark version 3.2.1
25/11/18 06:18:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/11/18 06:18:08 INFO ResourceUtils: ==============================================================
25/11/18 06:18:08 INFO ResourceUtils: No custom resources configured for spark.driver.
25/11/18 06:18:08 INFO ResourceUtils: ==============================================================
25/11/18 06:18:08 INFO SparkContext: Submitted application: SalesETLJob
25/11/18 06:18:08 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/11/18 06:18:08 INFO ResourceProfile: Limiting resource is cpu
25/11/18 06:18:08 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/11/18 06:18:08 INFO SecurityManager: Changing view acls to: spark
25/11/18 06:18:08 INFO SecurityManager: Changing modify acls to: spark
25/11/18 06:18:08 INFO SecurityManager: Changing view acls groups to: 
25/11/18 06:18:08 INFO SecurityManager: Changing modify acls groups to: 
25/11/18 06:18:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
25/11/18 06:18:09 INFO Utils: Successfully started service 'sparkDriver' on port 43537.
25/11/18 06:18:09 INFO SparkEnv: Registering MapOutputTracker
25/11/18 06:18:09 INFO SparkEnv: Registering BlockManagerMaster
25/11/18 06:18:09 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/11/18 06:18:09 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/11/18 06:18:09 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/11/18 06:18:09 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e21391ae-9031-45f6-81af-9bca2fa9d90d
25/11/18 06:18:09 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/11/18 06:18:09 INFO SparkEnv: Registering OutputCommitCoordinator
25/11/18 06:18:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/11/18 06:18:10 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://6b05748f7bac:4040
25/11/18 06:18:10 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/11/18 06:18:10 INFO TransportClientFactory: Successfully created connection to spark-master/172.20.0.3:7077 after 51 ms (0 ms spent in bootstraps)
25/11/18 06:18:10 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20251118061810-0018
25/11/18 06:18:10 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251118061810-0018/0 on worker-20251118055626-172.20.0.6-38023 (172.20.0.6:38023) with 12 core(s)
25/11/18 06:18:10 INFO StandaloneSchedulerBackend: Granted executor ID app-20251118061810-0018/0 on hostPort 172.20.0.6:38023 with 12 core(s), 1024.0 MiB RAM
25/11/18 06:18:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39335.
25/11/18 06:18:10 INFO NettyBlockTransferService: Server created on 6b05748f7bac:39335
25/11/18 06:18:10 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/11/18 06:18:10 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 6b05748f7bac, 39335, None)
25/11/18 06:18:10 INFO BlockManagerMasterEndpoint: Registering block manager 6b05748f7bac:39335 with 366.3 MiB RAM, BlockManagerId(driver, 6b05748f7bac, 39335, None)
25/11/18 06:18:10 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251118061810-0018/0 is now RUNNING
25/11/18 06:18:10 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 6b05748f7bac, 39335, None)
25/11/18 06:18:10 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 6b05748f7bac, 39335, None)
25/11/18 06:18:11 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/11/18 06:18:11 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/11/18 06:18:11 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
25/11/18 06:18:14 INFO InMemoryFileIndex: It took 247 ms to list leaf files for 1 paths.
25/11/18 06:18:14 INFO InMemoryFileIndex: It took 14 ms to list leaf files for 1 paths.
25/11/18 06:18:14 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.6:48040) with ID 0,  ResourceProfileId 0
25/11/18 06:18:15 INFO BlockManagerMasterEndpoint: Registering block manager 172.20.0.6:40601 with 366.3 MiB RAM, BlockManagerId(0, 172.20.0.6, 40601, None)
25/11/18 06:18:22 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:18:22 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/11/18 06:18:22 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:18:23 INFO CodeGenerator: Code generated in 418.607376 ms
25/11/18 06:18:23 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 338.3 KiB, free 366.0 MiB)
25/11/18 06:18:23 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.9 MiB)
25/11/18 06:18:23 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 6b05748f7bac:39335 (size: 32.4 KiB, free: 366.3 MiB)
25/11/18 06:18:23 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:18:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:18:24 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/11/18 06:18:24 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:18:24 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/11/18 06:18:24 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:18:24 INFO DAGScheduler: Missing parents: List()
25/11/18 06:18:24 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:18:24 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/11/18 06:18:24 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/11/18 06:18:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 6b05748f7bac:39335 (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:18:24 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/11/18 06:18:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:18:24 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/11/18 06:18:24 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:18:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.0.6:40601 (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:18:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.0.6:40601 (size: 32.4 KiB, free: 366.3 MiB)
25/11/18 06:18:29 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4835 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:18:29 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/11/18 06:18:29 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 5.046 s
25/11/18 06:18:29 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:18:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/11/18 06:18:29 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 5.124906 s
25/11/18 06:18:29 INFO CodeGenerator: Code generated in 18.46783 ms
25/11/18 06:18:29 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:18:29 INFO FileSourceStrategy: Post-Scan Filters: 
25/11/18 06:18:29 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:18:29 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 338.3 KiB, free 365.6 MiB)
25/11/18 06:18:29 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.6 MiB)
25/11/18 06:18:29 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 6b05748f7bac:39335 (size: 32.4 KiB, free: 366.2 MiB)
25/11/18 06:18:29 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:18:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:18:29 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
25/11/18 06:18:29 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
25/11/18 06:18:29 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:18:29 INFO FileSourceStrategy: Post-Scan Filters: 
25/11/18 06:18:29 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:18:29 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 338.1 KiB, free 365.2 MiB)
25/11/18 06:18:29 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.2 MiB)
25/11/18 06:18:29 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 6b05748f7bac:39335 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:18:29 INFO SparkContext: Created broadcast 3 from json at NativeMethodAccessorImpl.java:0
25/11/18 06:18:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:18:29 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
25/11/18 06:18:29 INFO DAGScheduler: Got job 1 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:18:29 INFO DAGScheduler: Final stage: ResultStage 1 (json at NativeMethodAccessorImpl.java:0)
25/11/18 06:18:29 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:18:29 INFO DAGScheduler: Missing parents: List()
25/11/18 06:18:29 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:18:29 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 12.4 KiB, free 365.2 MiB)
25/11/18 06:18:29 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 365.2 MiB)
25/11/18 06:18:29 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 6b05748f7bac:39335 (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:18:29 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/11/18 06:18:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:18:29 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/11/18 06:18:29 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:18:29 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.0.6:40601 (size: 6.5 KiB, free: 366.3 MiB)
25/11/18 06:18:30 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.0.6:40601 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:18:30 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 372 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:18:30 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/11/18 06:18:30 INFO DAGScheduler: ResultStage 1 (json at NativeMethodAccessorImpl.java:0) finished in 0.414 s
25/11/18 06:18:30 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:18:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/11/18 06:18:30 INFO DAGScheduler: Job 1 finished: json at NativeMethodAccessorImpl.java:0, took 0.426527 s
25/11/18 06:18:31 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/11/18 06:18:31 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/11/18 06:18:31 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/11/18 06:18:31 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:18:31 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:18:31 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:18:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:18:31 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:18:31 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
25/11/18 06:18:31 INFO CodeGenerator: Code generated in 33.168367 ms
25/11/18 06:18:31 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 338.2 KiB, free 364.8 MiB)
25/11/18 06:18:31 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 364.8 MiB)
25/11/18 06:18:31 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 6b05748f7bac:39335 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:18:31 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:18:31 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:18:31 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:18:31 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/11/18 06:18:31 INFO DAGScheduler: Final stage: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/11/18 06:18:31 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:18:31 INFO DAGScheduler: Missing parents: List()
25/11/18 06:18:31 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/11/18 06:18:31 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 14.4 KiB, free 364.8 MiB)
25/11/18 06:18:31 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 364.8 MiB)
25/11/18 06:18:31 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 6b05748f7bac:39335 (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:18:31 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/11/18 06:18:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/11/18 06:18:31 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/11/18 06:18:31 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:18:31 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.20.0.6:40601 (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:18:32 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.20.0.6:40601 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:18:32 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 352 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:18:32 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/11/18 06:18:32 INFO DAGScheduler: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.381 s
25/11/18 06:18:32 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:18:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/11/18 06:18:32 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.388123 s
25/11/18 06:18:32 INFO CodeGenerator: Code generated in 27.495431 ms
25/11/18 06:18:32 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 1025.0 KiB, free 363.8 MiB)
25/11/18 06:18:32 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 250.0 B, free 363.8 MiB)
25/11/18 06:18:32 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 6b05748f7bac:39335 (size: 250.0 B, free: 366.2 MiB)
25/11/18 06:18:32 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:18:32 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:18:32 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:18:32 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:18:32 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 6b05748f7bac:39335 in memory (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:18:32 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.20.0.6:40601 in memory (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:18:32 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 6b05748f7bac:39335 in memory (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:18:32 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.20.0.6:40601 in memory (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:18:32 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 6b05748f7bac:39335 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/11/18 06:18:32 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.0.6:40601 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/11/18 06:18:32 INFO CodeGenerator: Code generated in 40.673047 ms
25/11/18 06:18:32 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 338.0 KiB, free 363.5 MiB)
25/11/18 06:18:32 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 6b05748f7bac:39335 in memory (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:18:32 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.20.0.6:40601 in memory (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:18:32 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 363.9 MiB)
25/11/18 06:18:32 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 6b05748f7bac:39335 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:18:32 INFO SparkContext: Created broadcast 8 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:18:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:18:32 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/11/18 06:18:32 INFO DAGScheduler: Got job 3 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:18:32 INFO DAGScheduler: Final stage: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0)
25/11/18 06:18:32 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:18:32 INFO DAGScheduler: Missing parents: List()
25/11/18 06:18:32 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:18:32 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 211.3 KiB, free 363.6 MiB)
25/11/18 06:18:32 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 75.9 KiB, free 363.6 MiB)
25/11/18 06:18:32 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 6b05748f7bac:39335 (size: 75.9 KiB, free: 366.1 MiB)
25/11/18 06:18:32 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/11/18 06:18:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:18:32 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/11/18 06:18:32 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:18:32 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.20.0.6:40601 (size: 75.9 KiB, free: 366.2 MiB)
25/11/18 06:18:32 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.20.0.6:40601 (size: 250.0 B, free: 366.2 MiB)
25/11/18 06:18:33 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.20.0.6:40601 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:18:33 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 612 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:18:33 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/11/18 06:18:33 INFO DAGScheduler: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0) finished in 0.661 s
25/11/18 06:18:33 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:18:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/11/18 06:18:33 INFO DAGScheduler: Job 3 finished: csv at NativeMethodAccessorImpl.java:0, took 0.683533 s
25/11/18 06:18:33 INFO FileFormatWriter: Start to commit write Job a30e2abd-ce5b-4e2d-aab2-8fa687d47e3d.
25/11/18 06:18:33 INFO FileFormatWriter: Write Job a30e2abd-ce5b-4e2d-aab2-8fa687d47e3d committed. Elapsed time: 93 ms.
25/11/18 06:18:33 INFO FileFormatWriter: Finished processing stats for write job a30e2abd-ce5b-4e2d-aab2-8fa687d47e3d.
25/11/18 06:18:33 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/11/18 06:18:33 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/11/18 06:18:33 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/11/18 06:18:33 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:18:33 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:18:33 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:18:33 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:18:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:18:33 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:18:33 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:18:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:18:33 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:18:33 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:18:33 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 338.2 KiB, free 363.2 MiB)
25/11/18 06:18:33 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 363.2 MiB)
25/11/18 06:18:33 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 6b05748f7bac:39335 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:18:33 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:18:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:18:33 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:18:33 INFO DAGScheduler: Got job 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/11/18 06:18:33 INFO DAGScheduler: Final stage: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/11/18 06:18:33 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:18:33 INFO DAGScheduler: Missing parents: List()
25/11/18 06:18:33 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/11/18 06:18:33 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 14.4 KiB, free 363.2 MiB)
25/11/18 06:18:33 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 363.2 MiB)
25/11/18 06:18:33 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 6b05748f7bac:39335 (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:18:33 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/11/18 06:18:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/11/18 06:18:33 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/11/18 06:18:33 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:18:33 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.20.0.6:40601 (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:18:33 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.20.0.6:40601 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:18:33 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 89 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:18:33 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/11/18 06:18:33 INFO DAGScheduler: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.103 s
25/11/18 06:18:33 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:18:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/11/18 06:18:33 INFO DAGScheduler: Job 4 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.111790 s
25/11/18 06:18:33 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 1025.0 KiB, free 362.2 MiB)
25/11/18 06:18:33 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 250.0 B, free 362.2 MiB)
25/11/18 06:18:33 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 6b05748f7bac:39335 (size: 250.0 B, free: 366.1 MiB)
25/11/18 06:18:33 INFO SparkContext: Created broadcast 12 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:18:33 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:18:33 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:18:33 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:18:33 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 338.0 KiB, free 361.9 MiB)
25/11/18 06:18:33 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 361.8 MiB)
25/11/18 06:18:33 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 6b05748f7bac:39335 (size: 32.5 KiB, free: 366.0 MiB)
25/11/18 06:18:33 INFO SparkContext: Created broadcast 13 from parquet at NativeMethodAccessorImpl.java:0
25/11/18 06:18:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:18:33 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
25/11/18 06:18:33 INFO DAGScheduler: Got job 5 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:18:33 INFO DAGScheduler: Final stage: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0)
25/11/18 06:18:33 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:18:33 INFO DAGScheduler: Missing parents: List()
25/11/18 06:18:33 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:18:33 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 211.3 KiB, free 361.6 MiB)
25/11/18 06:18:33 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 76.0 KiB, free 361.5 MiB)
25/11/18 06:18:33 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 6b05748f7bac:39335 (size: 76.0 KiB, free: 366.0 MiB)
25/11/18 06:18:33 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/11/18 06:18:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:18:33 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/11/18 06:18:33 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:18:34 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.20.0.6:40601 (size: 76.0 KiB, free: 366.0 MiB)
25/11/18 06:18:34 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.20.0.6:40601 (size: 250.0 B, free: 366.0 MiB)
25/11/18 06:18:34 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.20.0.6:40601 (size: 32.5 KiB, free: 366.0 MiB)
25/11/18 06:18:35 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 1762 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:18:35 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/11/18 06:18:35 INFO DAGScheduler: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0) finished in 1.830 s
25/11/18 06:18:35 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:18:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/11/18 06:18:35 INFO DAGScheduler: Job 5 finished: parquet at NativeMethodAccessorImpl.java:0, took 1.836332 s
25/11/18 06:18:35 INFO FileFormatWriter: Start to commit write Job ca3ad309-3957-4088-9c15-70b475e544a1.
25/11/18 06:18:35 INFO FileFormatWriter: Write Job ca3ad309-3957-4088-9c15-70b475e544a1 committed. Elapsed time: 90 ms.
25/11/18 06:18:35 INFO FileFormatWriter: Finished processing stats for write job ca3ad309-3957-4088-9c15-70b475e544a1.
Job completed for 2025-01-01
25/11/18 06:18:35 INFO SparkUI: Stopped Spark web UI at http://6b05748f7bac:4040
25/11/18 06:18:35 INFO StandaloneSchedulerBackend: Shutting down all executors
25/11/18 06:18:35 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/11/18 06:18:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/11/18 06:18:36 INFO MemoryStore: MemoryStore cleared
25/11/18 06:18:36 INFO BlockManager: BlockManager stopped
25/11/18 06:18:36 INFO BlockManagerMaster: BlockManagerMaster stopped
25/11/18 06:18:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/11/18 06:18:36 INFO SparkContext: Successfully stopped SparkContext
25/11/18 06:18:36 INFO ShutdownHookManager: Shutdown hook called
25/11/18 06:18:36 INFO ShutdownHookManager: Deleting directory /tmp/spark-82daa17e-b426-4b1a-9ab9-8098ace23ccf/pyspark-52d7d697-a39b-4aef-a697-b88151ab778f
25/11/18 06:18:36 INFO ShutdownHookManager: Deleting directory /tmp/spark-8270ae5a-f1d8-4009-a176-faaa2c223613
25/11/18 06:18:36 INFO ShutdownHookManager: Deleting directory /tmp/spark-82daa17e-b426-4b1a-9ab9-8098ace23ccf
Job completed for 2025-01-01
/mnt/c/pyspark_stack/spark-apps/cron/run_sales.sh: 1: ---: not found
Triggering sales_etl_job.py for 2025-01-01...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/11/18 06:19:10 INFO SparkContext: Running Spark version 3.2.1
25/11/18 06:19:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/11/18 06:19:10 INFO ResourceUtils: ==============================================================
25/11/18 06:19:10 INFO ResourceUtils: No custom resources configured for spark.driver.
25/11/18 06:19:10 INFO ResourceUtils: ==============================================================
25/11/18 06:19:10 INFO SparkContext: Submitted application: SalesETLJob
25/11/18 06:19:10 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/11/18 06:19:10 INFO ResourceProfile: Limiting resource is cpu
25/11/18 06:19:10 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/11/18 06:19:10 INFO SecurityManager: Changing view acls to: spark
25/11/18 06:19:10 INFO SecurityManager: Changing modify acls to: spark
25/11/18 06:19:10 INFO SecurityManager: Changing view acls groups to: 
25/11/18 06:19:10 INFO SecurityManager: Changing modify acls groups to: 
25/11/18 06:19:10 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
25/11/18 06:19:11 INFO Utils: Successfully started service 'sparkDriver' on port 39411.
25/11/18 06:19:11 INFO SparkEnv: Registering MapOutputTracker
25/11/18 06:19:11 INFO SparkEnv: Registering BlockManagerMaster
25/11/18 06:19:11 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/11/18 06:19:11 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/11/18 06:19:11 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/11/18 06:19:11 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-aec871fb-2176-448e-b988-a7952fd47de9
25/11/18 06:19:11 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/11/18 06:19:11 INFO SparkEnv: Registering OutputCommitCoordinator
25/11/18 06:19:12 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/11/18 06:19:12 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://6b05748f7bac:4040
25/11/18 06:19:12 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/11/18 06:19:12 INFO TransportClientFactory: Successfully created connection to spark-master/172.20.0.3:7077 after 71 ms (0 ms spent in bootstraps)
25/11/18 06:19:12 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20251118061912-0019
25/11/18 06:19:12 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251118061912-0019/0 on worker-20251118055626-172.20.0.6-38023 (172.20.0.6:38023) with 12 core(s)
25/11/18 06:19:12 INFO StandaloneSchedulerBackend: Granted executor ID app-20251118061912-0019/0 on hostPort 172.20.0.6:38023 with 12 core(s), 1024.0 MiB RAM
25/11/18 06:19:13 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44113.
25/11/18 06:19:13 INFO NettyBlockTransferService: Server created on 6b05748f7bac:44113
25/11/18 06:19:13 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/11/18 06:19:13 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 6b05748f7bac, 44113, None)
25/11/18 06:19:13 INFO BlockManagerMasterEndpoint: Registering block manager 6b05748f7bac:44113 with 366.3 MiB RAM, BlockManagerId(driver, 6b05748f7bac, 44113, None)
25/11/18 06:19:13 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 6b05748f7bac, 44113, None)
25/11/18 06:19:13 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 6b05748f7bac, 44113, None)
25/11/18 06:19:13 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251118061912-0019/0 is now RUNNING
25/11/18 06:19:13 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/11/18 06:19:14 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/11/18 06:19:14 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
25/11/18 06:19:18 INFO InMemoryFileIndex: It took 327 ms to list leaf files for 1 paths.
25/11/18 06:19:18 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.6:34790) with ID 0,  ResourceProfileId 0
25/11/18 06:19:18 INFO InMemoryFileIndex: It took 16 ms to list leaf files for 1 paths.
25/11/18 06:19:18 INFO BlockManagerMasterEndpoint: Registering block manager 172.20.0.6:37799 with 366.3 MiB RAM, BlockManagerId(0, 172.20.0.6, 37799, None)
25/11/18 06:19:25 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:19:25 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/11/18 06:19:25 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:19:27 INFO CodeGenerator: Code generated in 358.185411 ms
25/11/18 06:19:27 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 338.3 KiB, free 366.0 MiB)
25/11/18 06:19:27 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.9 MiB)
25/11/18 06:19:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 6b05748f7bac:44113 (size: 32.4 KiB, free: 366.3 MiB)
25/11/18 06:19:27 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:19:27 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:19:27 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/11/18 06:19:27 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:19:27 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/11/18 06:19:27 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:19:27 INFO DAGScheduler: Missing parents: List()
25/11/18 06:19:27 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:19:27 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/11/18 06:19:27 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/11/18 06:19:27 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 6b05748f7bac:44113 (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:19:27 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/11/18 06:19:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:19:27 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/11/18 06:19:27 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:19:28 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.0.6:37799 (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:19:30 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.0.6:37799 (size: 32.4 KiB, free: 366.3 MiB)
25/11/18 06:19:31 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 3969 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:19:31 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/11/18 06:19:31 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 4.121 s
25/11/18 06:19:31 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:19:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/11/18 06:19:31 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 4.191364 s
25/11/18 06:19:31 INFO CodeGenerator: Code generated in 21.164987 ms
25/11/18 06:19:31 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:19:31 INFO FileSourceStrategy: Post-Scan Filters: 
25/11/18 06:19:31 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:19:31 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 338.3 KiB, free 365.6 MiB)
25/11/18 06:19:31 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 365.6 MiB)
25/11/18 06:19:31 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 6b05748f7bac:44113 (size: 32.4 KiB, free: 366.2 MiB)
25/11/18 06:19:31 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:19:31 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:19:32 INFO InMemoryFileIndex: It took 10 ms to list leaf files for 1 paths.
25/11/18 06:19:32 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.
25/11/18 06:19:32 INFO FileSourceStrategy: Pushed Filters: 
25/11/18 06:19:32 INFO FileSourceStrategy: Post-Scan Filters: 
25/11/18 06:19:32 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/11/18 06:19:32 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 338.1 KiB, free 365.2 MiB)
25/11/18 06:19:32 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.2 MiB)
25/11/18 06:19:32 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 6b05748f7bac:44113 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:19:32 INFO SparkContext: Created broadcast 3 from json at NativeMethodAccessorImpl.java:0
25/11/18 06:19:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:19:32 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
25/11/18 06:19:32 INFO DAGScheduler: Got job 1 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:19:32 INFO DAGScheduler: Final stage: ResultStage 1 (json at NativeMethodAccessorImpl.java:0)
25/11/18 06:19:32 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:19:32 INFO DAGScheduler: Missing parents: List()
25/11/18 06:19:32 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:19:32 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 12.4 KiB, free 365.2 MiB)
25/11/18 06:19:32 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 365.2 MiB)
25/11/18 06:19:32 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 6b05748f7bac:44113 (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:19:32 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/11/18 06:19:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:19:32 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/11/18 06:19:32 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:19:32 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.0.6:37799 (size: 6.5 KiB, free: 366.3 MiB)
25/11/18 06:19:32 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.0.6:37799 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:19:32 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 283 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:19:32 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/11/18 06:19:32 INFO DAGScheduler: ResultStage 1 (json at NativeMethodAccessorImpl.java:0) finished in 0.325 s
25/11/18 06:19:32 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:19:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/11/18 06:19:32 INFO DAGScheduler: Job 1 finished: json at NativeMethodAccessorImpl.java:0, took 0.335680 s
25/11/18 06:19:33 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/11/18 06:19:33 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/11/18 06:19:33 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/11/18 06:19:33 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:19:33 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:19:33 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:19:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:19:33 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:19:33 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
25/11/18 06:19:33 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 6b05748f7bac:44113 in memory (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:19:33 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.20.0.6:37799 in memory (size: 32.5 KiB, free: 366.3 MiB)
25/11/18 06:19:33 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 6b05748f7bac:44113 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/11/18 06:19:33 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.0.6:37799 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/11/18 06:19:33 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 6b05748f7bac:44113 in memory (size: 6.5 KiB, free: 366.2 MiB)
25/11/18 06:19:33 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.20.0.6:37799 in memory (size: 6.5 KiB, free: 366.3 MiB)
25/11/18 06:19:33 INFO CodeGenerator: Code generated in 27.235629 ms
25/11/18 06:19:33 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 338.2 KiB, free 365.2 MiB)
25/11/18 06:19:33 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.2 MiB)
25/11/18 06:19:33 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 6b05748f7bac:44113 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:19:33 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:19:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:19:33 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:19:33 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/11/18 06:19:33 INFO DAGScheduler: Final stage: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/11/18 06:19:33 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:19:33 INFO DAGScheduler: Missing parents: List()
25/11/18 06:19:33 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/11/18 06:19:33 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 14.4 KiB, free 365.2 MiB)
25/11/18 06:19:33 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 365.2 MiB)
25/11/18 06:19:33 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 6b05748f7bac:44113 (size: 7.2 KiB, free: 366.2 MiB)
25/11/18 06:19:33 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/11/18 06:19:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/11/18 06:19:33 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/11/18 06:19:33 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:19:33 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.20.0.6:37799 (size: 7.2 KiB, free: 366.3 MiB)
25/11/18 06:19:34 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.20.0.6:37799 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:19:34 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 307 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:19:34 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/11/18 06:19:34 INFO DAGScheduler: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.321 s
25/11/18 06:19:34 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:19:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/11/18 06:19:34 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.329156 s
25/11/18 06:19:34 INFO CodeGenerator: Code generated in 14.130233 ms
25/11/18 06:19:34 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 1025.0 KiB, free 364.2 MiB)
25/11/18 06:19:34 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 250.0 B, free 364.2 MiB)
25/11/18 06:19:34 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 6b05748f7bac:44113 (size: 250.0 B, free: 366.2 MiB)
25/11/18 06:19:34 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:19:34 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:19:34 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:19:34 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:19:34 INFO CodeGenerator: Code generated in 32.038402 ms
25/11/18 06:19:34 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 338.0 KiB, free 363.9 MiB)
25/11/18 06:19:34 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 363.8 MiB)
25/11/18 06:19:34 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 6b05748f7bac:44113 (size: 32.5 KiB, free: 366.2 MiB)
25/11/18 06:19:34 INFO SparkContext: Created broadcast 8 from csv at NativeMethodAccessorImpl.java:0
25/11/18 06:19:34 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:19:34 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/11/18 06:19:34 INFO DAGScheduler: Got job 3 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:19:34 INFO DAGScheduler: Final stage: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0)
25/11/18 06:19:34 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:19:34 INFO DAGScheduler: Missing parents: List()
25/11/18 06:19:34 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:19:34 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 211.3 KiB, free 363.6 MiB)
25/11/18 06:19:34 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 75.9 KiB, free 363.5 MiB)
25/11/18 06:19:34 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 6b05748f7bac:44113 (size: 75.9 KiB, free: 366.1 MiB)
25/11/18 06:19:34 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/11/18 06:19:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:19:34 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/11/18 06:19:34 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:19:34 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.20.0.6:37799 (size: 75.9 KiB, free: 366.2 MiB)
25/11/18 06:19:34 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.20.0.6:37799 (size: 250.0 B, free: 366.2 MiB)
25/11/18 06:19:35 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.20.0.6:37799 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:19:35 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 604 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:19:35 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/11/18 06:19:35 INFO DAGScheduler: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0) finished in 0.654 s
25/11/18 06:19:35 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:19:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/11/18 06:19:35 INFO DAGScheduler: Job 3 finished: csv at NativeMethodAccessorImpl.java:0, took 0.661891 s
25/11/18 06:19:35 INFO FileFormatWriter: Start to commit write Job a898471e-1a5e-45d7-a4a1-1a365f836a5f.
25/11/18 06:19:35 INFO FileFormatWriter: Write Job a898471e-1a5e-45d7-a4a1-1a365f836a5f committed. Elapsed time: 97 ms.
25/11/18 06:19:35 INFO FileFormatWriter: Finished processing stats for write job a898471e-1a5e-45d7-a4a1-1a365f836a5f.
25/11/18 06:19:35 INFO FileSourceStrategy: Pushed Filters: IsNotNull(quantity),IsNotNull(product_id)
25/11/18 06:19:35 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(quantity#18),isnotnull(product_id#17)
25/11/18 06:19:35 INFO FileSourceStrategy: Output Data Schema: struct<sale_id: string, product_id: string, quantity: string ... 1 more fields>
25/11/18 06:19:35 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:19:35 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:19:35 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:19:35 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:19:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:19:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:19:35 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:19:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/11/18 06:19:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/11/18 06:19:35 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/11/18 06:19:35 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 338.2 KiB, free 363.2 MiB)
25/11/18 06:19:35 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 363.2 MiB)
25/11/18 06:19:35 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 6b05748f7bac:44113 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:19:35 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:19:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:19:35 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:19:35 INFO DAGScheduler: Got job 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/11/18 06:19:35 INFO DAGScheduler: Final stage: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/11/18 06:19:35 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:19:35 INFO DAGScheduler: Missing parents: List()
25/11/18 06:19:35 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/11/18 06:19:35 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 14.4 KiB, free 363.2 MiB)
25/11/18 06:19:35 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 363.2 MiB)
25/11/18 06:19:35 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 6b05748f7bac:44113 (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:19:35 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/11/18 06:19:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/11/18 06:19:35 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/11/18 06:19:35 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.20.0.6, executor 0, partition 0, ANY, 4880 bytes) taskResourceAssignments Map()
25/11/18 06:19:35 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.20.0.6:37799 (size: 7.2 KiB, free: 366.1 MiB)
25/11/18 06:19:35 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.20.0.6:37799 (size: 32.5 KiB, free: 366.1 MiB)
25/11/18 06:19:35 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 97 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:19:35 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/11/18 06:19:35 INFO DAGScheduler: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.112 s
25/11/18 06:19:35 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:19:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/11/18 06:19:35 INFO DAGScheduler: Job 4 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.119584 s
25/11/18 06:19:35 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 1025.0 KiB, free 362.2 MiB)
25/11/18 06:19:35 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 250.0 B, free 362.2 MiB)
25/11/18 06:19:35 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 6b05748f7bac:44113 (size: 250.0 B, free: 366.1 MiB)
25/11/18 06:19:35 INFO SparkContext: Created broadcast 12 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/11/18 06:19:35 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
25/11/18 06:19:35 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#33)
25/11/18 06:19:35 INFO FileSourceStrategy: Output Data Schema: struct<product_id: string, unit_price: bigint>
25/11/18 06:19:35 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 338.0 KiB, free 361.8 MiB)
25/11/18 06:19:35 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 361.8 MiB)
25/11/18 06:19:35 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 6b05748f7bac:44113 (size: 32.5 KiB, free: 366.0 MiB)
25/11/18 06:19:35 INFO SparkContext: Created broadcast 13 from parquet at NativeMethodAccessorImpl.java:0
25/11/18 06:19:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/11/18 06:19:35 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
25/11/18 06:19:35 INFO DAGScheduler: Got job 5 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/11/18 06:19:35 INFO DAGScheduler: Final stage: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0)
25/11/18 06:19:35 INFO DAGScheduler: Parents of final stage: List()
25/11/18 06:19:35 INFO DAGScheduler: Missing parents: List()
25/11/18 06:19:35 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/11/18 06:19:35 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 211.3 KiB, free 361.6 MiB)
25/11/18 06:19:35 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 76.0 KiB, free 361.5 MiB)
25/11/18 06:19:35 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 6b05748f7bac:44113 (size: 76.0 KiB, free: 365.9 MiB)
25/11/18 06:19:35 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/11/18 06:19:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/11/18 06:19:35 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/11/18 06:19:35 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (172.20.0.6, executor 0, partition 0, ANY, 4884 bytes) taskResourceAssignments Map()
25/11/18 06:19:35 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.20.0.6:37799 (size: 76.0 KiB, free: 366.0 MiB)
25/11/18 06:19:36 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.20.0.6:37799 (size: 250.0 B, free: 366.0 MiB)
25/11/18 06:19:36 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.20.0.6:37799 (size: 32.5 KiB, free: 366.0 MiB)
25/11/18 06:19:37 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 1391 ms on 172.20.0.6 (executor 0) (1/1)
25/11/18 06:19:37 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/11/18 06:19:37 INFO DAGScheduler: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0) finished in 1.432 s
25/11/18 06:19:37 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/11/18 06:19:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/11/18 06:19:37 INFO DAGScheduler: Job 5 finished: parquet at NativeMethodAccessorImpl.java:0, took 1.437048 s
25/11/18 06:19:37 INFO FileFormatWriter: Start to commit write Job ab6f318d-2823-4151-ab93-100fb8f265a8.
25/11/18 06:19:37 INFO FileFormatWriter: Write Job ab6f318d-2823-4151-ab93-100fb8f265a8 committed. Elapsed time: 31 ms.
25/11/18 06:19:37 INFO FileFormatWriter: Finished processing stats for write job ab6f318d-2823-4151-ab93-100fb8f265a8.
Job completed for 2025-01-01
25/11/18 06:19:37 INFO SparkUI: Stopped Spark web UI at http://6b05748f7bac:4040
25/11/18 06:19:37 INFO StandaloneSchedulerBackend: Shutting down all executors
25/11/18 06:19:37 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/11/18 06:19:37 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/11/18 06:19:37 INFO MemoryStore: MemoryStore cleared
25/11/18 06:19:37 INFO BlockManager: BlockManager stopped
25/11/18 06:19:37 INFO BlockManagerMaster: BlockManagerMaster stopped
25/11/18 06:19:37 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/11/18 06:19:37 INFO SparkContext: Successfully stopped SparkContext
25/11/18 06:19:37 INFO ShutdownHookManager: Shutdown hook called
25/11/18 06:19:37 INFO ShutdownHookManager: Deleting directory /tmp/spark-0d2682bb-3836-4e70-9ef8-7533444b65fc/pyspark-7c7ee710-0ed9-41b2-a6be-57ed6e77f1e7
25/11/18 06:19:37 INFO ShutdownHookManager: Deleting directory /tmp/spark-0d2682bb-3836-4e70-9ef8-7533444b65fc
25/11/18 06:19:37 INFO ShutdownHookManager: Deleting directory /tmp/spark-1c2a4ede-29ea-45f9-b9dd-fe89d2bd8622
Job completed for 2025-01-01
